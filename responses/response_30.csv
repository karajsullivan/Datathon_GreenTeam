,Discussion ID,Author,Body,Likes,Date,Time
0,508462,jfernandes1,"Hi@BCC_Automatizacion_Josep, you can use the task SLA feature to complete the task when no response is received.You can also use the newer feature, ""Ask"" type conditional task to get better control of what happens. Below is a screenshot. This would be the preferred method.",0,07-11-2022,08:19 PM
1,508462,BCC_Automatizacaria-labelion_Josep,"Using the manual conditional method and placing 1 minute did not work, I proved other values 3, 5, 15 minutes and didn't work neither.The box returns an error with no information. The ""Ask"" type conditional is no an option because we accept any kind of reply.",0,07-12-2022,12:31 AM
2,508462,jfernandes1,"Hi@BCC_Automatizacion_Josep, Not the prettiest solution. But it works.I used a sleep function set for 300 seconds. If the user does not reply, then the playbook will continue. If the user does, task 1 will complete task 2 as specified in the below configuration.",0,07-12-2022,08:49 PM
3,508462,Sec101,"Is that ""wait for reply"" a manual task? ",0,07-13-2022,06:36 AM
4,508462,BCC_Automatizacaria-labelion_Josep,It works perfectly! Thanks so much,0,07-14-2022,11:42 PM
5,508462,BCC_Automatizacaria-labelion_Josep,I was trying manual and didn't work,0,07-14-2022,11:44 PM
6,508462,BCC_Automatizacaria-labelion_Josep,Remember to set Await in the Details in the Sleep,0,07-15-2022,01:01 AM
7,506958,gfilippov,"Hi,Currently I can't find any script in the marketplace that can create a PDF file from a JSON, only the opposite,You may want to submit a feature request,thanks.",0,07-14-2022,10:14 AM
8,506336,gfilippov,"Hi,The integration was contributed from the community and theintegration's test functionality was not developed properly, currently it is doing nothing but to return an error, meaning that even if you provided the right credentials and all other commands are working, the test will still return an error,please try the other commands and ignore the test,thanks.",0,07-14-2022,10:12 AM
9,504235,gfilippov,"Hi,Please make sure you are using the latest version available of the integration in the market place,If you still get the error with the latest version- please submit a support case with the logs attached,as the logs contain sensitive information it is not recommended to upload it here,thanks.",0,07-14-2022,10:08 AM
10,508638,Sec101,"Hi@vidurasupun, not sure what your use case is, I can help better if I understand what exactly your trying to do.By list I'm assuming your referring to a list of values in the incident's context? Not the external list function of Cortexhttps://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-8/cortex-xsoar-admin/lists? The command setList is used for that.Try the attached playbook, it should do the trick. It uses an inbuilt conditional check and playbook looping to achieve the same outcome. You can also do this with a single automation.I had to change the extensions to xml, just change it back to yml before uploading to your server.",0,07-13-2022,06:34 AM
11,508638,jfernandes1,"Sec101 thank you for the response but I need to do the same thing on the playbook level, as Jfernandes1 mentioned he is using the setautomation to assign external IP(s) to the keyexternalIPsthen I can call it later in my playbook as an example to send a mail like below.@jfernandes1@jfernandes1",1,07-13-2022,05:52 PM
12,508638,vidurasupun,"Thank you for the solution. I added bit of stuff on top your playbook,",0,07-13-2022,10:55 PM
13,508638,vidurasupun,"Hi@lulu42, please raise a support ticket athttps://support.paloaltonetworks.com/. We would need logs and other information to verify and help with this issue. Thanks.",0,07-13-2022,10:55 PM
14,508678,jfernandes1,"Hi@alexbbryant, yes this is version dependent. Only 6.8 includes this new feature. In older version of Cortex use the below solution.Task 2: Can be any automation. Just ensure that you set the ""Stop on error"" to No.For task 4: Use the isError automation. Like below.",0,07-13-2022,05:21 PM
15,508607,jfernandes1,"Nevermind, I was using V2 which seems to be not working properly using the V3 fixed the issue",0,07-12-2022,08:02 PM
16,508402,vidurasupun,"Hello,I have encountered this Error before and can be solved relatively easily. Essentially the Grid Field ID is the Machine Name for the grid. Each field and indeed grid has a machine name and can be viewed when you access the field in the Object Setup Page. Its is essentially the name without spaces or capital letters.A grid is considered a field. It need to be defined on the Object Setup page. Just as there is Long Text and Single Select fields there is also Grid. Grid is essentially a table that you can display and interact with on the layout. It is essential to assign the Grid under field settings to the ""Type"" that you want to use the grid. When you initialise the field in point 2 essentially you are defining the field in the Context data. This is where all the information regarding inputs, outputs and content from automatons is stored. As you can see the field is an empty List [] this is where the data will be ""Set"" by the set grid task. It is mandatory to initialise the Grid as well as have the grid in place on one of your tabs in Layout in order to store information there. For reference sake look at how Dbot Similar Incidents is stored in a grid and this will help you to understand the flow.Sorry for the long winded answer. Cortex XSOAR is cutting edge an a single line explanation won't do this feature justice.",0,07-09-2022,08:43 AM
17,502984,michaelsysec242,"Thank you for the detailed response. Just to be clear if my grid_ID is NewGrid, there should be a defined field name NewGrid with the type grid?You were correct about the product being cutting edge, sometimes its hard to wrap the head around",1,06-13-2022,05:14 AM
18,502984,vidurasupun,"@vidurasupun, It should be the machine name of the field.",0,06-18-2022,07:34 AM
19,502984,jfernandes1,If anyone else is facing the same problem set a setIncident block before and then assign the grid field to [],0,06-19-2022,07:05 PM
20,502984,vidurasupun,"Hi @Isabelle –There are three important ""dbot"" fields that need to be set in order for mirroring to work correctly. Please try adding these to your mapper, similar to the screenshot below:Please give that a try and let me know if it works!",0,07-09-2022,08:10 AM
21,505785,asawyer,"A reply by:@Tomerhaimof&@ivandijkIf you install the Phishing Campaign pack, the Detect & Manage Phishing Campaigns playbook would run through the main phishing playbook. By default, if more than 3 similar incidents are found, then a Phishing Campaign incident would be opened automatically and all related incidents would be linked automatically. All are configurable through the Detect & Manage Phishing Campaigns playbook inputs.",1,07-07-2022,03:43 PM
22,508241,tsedaka,"Reply by:@Tomerhaimof&@ivandijkURL prediction is dependable automation to understand if a URL is phishing or not. Based on the results you may want to block the domain, URL, and/or the sender address. You can also hunt for emails containing that URL using Microsoft Defender or similar integrations! As for the email prediction - it depends on how well trained your model is. You can for example auto close spam email incidents when you have a good model and predicted non-malicious with a very high probability.",0,07-07-2022,08:26 AM
23,508238,tsedaka,"Reply by:@Tomerhaimof&@ivandijkThe only traceable information would probably be the external IP which is controlled by your organization. Also, we use a fresh clean browser for every rasterization which is the same as using incognito, meaning, no artifacts should be shared between each http request.",0,07-07-2022,08:20 AM
24,508235,tsedaka,"Reply by: @Tomerhaimof @IvandijkIn the model in the Docker, and then in XSOAR DB.",0,07-07-2022,08:17 AM
25,508154,tsedaka,"Reply by: @tomerhaimof @IvandijkYes, it is recommended to harden the relevant configurations. For additional guidance follow the links:Docker Hardening guide Docker Network Hardening Also, it is mentioned in the ""Rasterize"" integration documentation",0,07-06-2022,08:10 PM
26,508152,tsedaka,"Hi@anujaprasad– Are you trying to run the integration on an engine or directly on your XSOAR server? Depending on whether you are trying to run the integration on an engine or on the server, can you confirm docker is installed on the engine/server? And which operating system are you running on?",0,07-06-2022,08:05 PM
27,507635,asawyer,A reply by:  @Tomerhaimof@ivandijkYou should be able to use the SMIME integration to decrypt the email.,0,07-06-2022,05:45 PM
28,508029,tsedaka,"A reply by:  @Tomerhaimof@ivandijkIt depends, but usually ~200 for each category. Preferably 500+.",0,07-05-2022,03:25 PM
29,508026,tsedaka,"A reply by:@Tomerhaimof@ivandijkAll changes are specified in the webinar recording, but the main ones are extraction improvements, support for more integrations, usage of new fields instead of labels, the addition of phishing alerts ingestion, phishing URL prediction (ML), the new layout including email deletion through the layout and manual phishing incident creation.",0,07-05-2022,03:21 PM
30,508022,tsedaka,"Hi,Maybe you can try timing tab to set retries 0 instead of Advanced tab.",0,07-05-2022,03:16 PM
31,507841,MKececioglu,"As I have outlined in the Question, i have set the amount to 0 and have checked the ""Complete task as :No""Once saving the playbook the setting is returned to default when reentering the playbook.",0,07-04-2022,05:51 AM
32,507841,michaelsysec242,"Hi@michaelsysec242, hmm not seen this issue before.I assume you set the task like the below screenshot.From what you said, the settings are not sticking after you save the playbook. Could you send me the screenshot of your task setting, same as above. Also, could you try setting this task in a new playbook and let me know if that works.I've also attached a playbook I created with the above settings, please upload and let me know if it sticks on your server.",0,07-04-2022,06:11 AM
33,507841,jfernandes1,"Prompted to attached my license to the Demisto Server but upon refreshing the web page, it is requesting for my license again.Any help?",0,07-04-2022,04:45 PM
34,338539,HYHY6565,"Hi,This might happen when the license expired before uploading it. Open the license file (it's a normal text file), and check expiration on it. Otherwise - try restarting the server, and then upload again.If nothing works - Please check the logs for errors regarding license, and share so we can look.Gilad",0,07-22-2020,04:46 AM
35,338539,GShriki,"I am having this same issue. I can't seem to get any help anywhere to get another license file either.The log message related to license key is as follows...""2020-09-04 08:54:26.0285 info [POST] ""/license/upload"" 200 2.064315ms (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/middleware.go:90)""Attached is a screen shot of the license screen.",0,07-22-2020,09:08 AM
36,338539,MattEllisPAC20,"MattEllisPAC20, are you not able to perform any action? When the system is downgraded to Free Edition - you should be able to work with it, under the Free Edition limitations (https://start.paloaltonetworks.com/rs/531-OCS-018/images/Cortex_XSOAR_Community_Edition_FAQ.pdf)",0,09-04-2020,08:59 AM
37,338539,GShriki,"Hi,",1,09-04-2020,09:49 AM
38,338539,ben12385,"I want to install xsoar community edition offline, when I come to download the dockerdependencies,the download url is invalid.Where can I get the dockerimages?",0,11-12-2020,11:48 PM
39,338539,uxiaoqi,Your download link should look something like:https://download.demisto.works/download-params?token=<TOKEN-HERE>&email=<EMAIL-HERE>&downloadName=dockerimagesThe link works fine.,0,03-23-2021,03:14 AM
40,338539,ABurt,"But the dockerimage is too big,when I download 90%,the token is invalid.And I reapplied for the download link, but received no reply from email",0,03-23-2021,03:24 AM
41,338539,uxiaoqi,@ben12385When using the Community Edition you do not need to apply another licence. The functionality will drop to community edition. 166 executions per day.,0,03-23-2021,03:42 AM
42,338539,ABurt,"Hi@AlexandreBorgo, You cannot select the array items inside extended context. Just dump all the data to context and then use what you need. Use the command like below.!infoblox-get-ip extend-context=data=",0,03-23-2021,03:46 AM
43,507087,jfernandes1,"Hi@Blazej_Gomoluch, Seeing that the response is 404, not sure if they will change it. If you're using this command inside a playbook, I have some a workaround for you.You can ignore error and continue.If not using 6.8, you should see a toggle at the bottom of the task window called ""Stop on Error"". You can then check for an error like below.",0,06-29-2022,08:15 PM
44,506940,jfernandes1,"Hi all,Still cant find a way to select incident.linkedincident.offenseid kind of information. To link incident between them really makes it faster and simple to analyse . I dont want to rollback unlinked state , and trying to find a way to close offenses in qradar when they linked into another incident in xsoar. Any idea would be great.Regards.",0,06-29-2022,05:34 PM
45,502506,MKececioglu,"Hey@MKececioglu, indeed performing actions like mirroring and closing offenses in third party tools is not possible when you have link&close as a pre-processing rule.I would suggest a slightly different approach here instead:1. When creating the pre-processing rule, only link the incident instead of link and close.2. In the playbook used for these incidents, create a conditional task as the first task of the playbook, which will divide into the following two branches:3. You'll want to check if the new incident was linked to a previous one, so you'll check that its' linkedCount field is greater than zero, or equals 1 (since it was just created now and linked to a previous incident, the count will be 1). If this incident isn't linked to a previous one (meaning the rule doesn't apply to it), the count will remain zero.4. The branch for yes (count = 1) will have the needed actions for closing the offense in QRadar (easiest if you're using mirroring), and will close the incident.The branch for else (this is an incident that the rule didn't apply to) will simply have all the logic that you had until now for newly created incidents.Note:If for any reason you need to re-run the playbook for an older incident which will already have newer incidents that were linked to it, the selected branch will be ""yes"" - as it does have incidents linked to it.",0,06-13-2022,04:59 AM
46,502506,nkazinets,"can we not use a script and once the condition set in preprocess are met then instead of link and close , it will run the script which will have the capacity to close it both in xsoar and in qradar ? I dont see any tag of preprocess and so when I select run a script in preprocess , it doesnot reflect any script there.",0,06-14-2022,06:51 AM
47,502506,Sbanerjee6,"Hi@pottapitot, every job run creates a new incident. This cannot be stopped. There might be other work arounds available. You could looks at using a scheduled command to run the !setPlaybook command every X minutes. This would mimic the job run but consume a single incident ID.Regarding your second question, indicator extraction is enabled by default on XSOAR. As a part of best practises we recommend disabling it. You should disable it at a platform level and allow extraction on a specific task or command level. For more information refer - https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-8/cortex-xsoar-admin/manage-indicators/auto-...To disable it I would recommend adding the below server configs with the value set to 1 (Refer above link for possible values):-- reputation.calc.algorithm- reputation.calc.algorithm.fields.change- reputation.calc.algorithm.tasks- reputation.calc.algorithm.manualYou can then override the above by forcing extraction:-1. At CLI - Add auto-extract=to the end of a command2. At Task - Edit Task -> Advanced -> Indicator Extraction Mode - Refer3. At Field\Incident - Settings -> Object Setup -> Incidents -> Type -> <Incident Type> -> Indicator Extraction Rules - Refer",0,06-29-2022,02:30 AM
48,505455,jfernandes1,"Hi@abracamontesauz, From what I understand you're referring to the ""Cortex XDR - IOC"" integration. I think sync you're referring to is the ""Fetch Indicators"" function, This will pull IOCs from XDR => XSOAR - not the other way around.If you want to manually push indicators (XSOAR => XDR) you can use the ""!xdr-iocs-push indicator=<value>"" command. This command can be called in a playbook by passing a single\list of IOC to XDR.I have an example of below showing 2 methods to doing the same function. You do not require the ""Playbook Triggered"" step for method 2.",1,06-22-2022,05:53 PM
49,505043,jfernandes1,"Hi@pottapitot, you can use the extend context option to save the data to the context in theDatetimetoADTime step. Then use that context key token in the following step. Use ""data="" to dump all command output into the context key. For more informationrefer -https://xsoar.pan.dev/docs/playbooks/playbooks-extend-context",0,06-21-2022,08:05 PM
50,504495,jfernandes1,"Hi@jfernandes1,That was exactly what I was looking for.Thanks alot.Cheers",1,06-19-2022,07:34 PM
51,504495,pottapitot,"Each configured collection is just a query that is run against the local threat intel data. The query uses the same syntax as the search bar on the indicators page, so you can test your queries and use the drop-down help from that page to help write and test your queries.Generally a query based on the standard fields of the indicators (eg, type, verdict, source, etc) would be sufficient, but more advanced logic can be implemented if required by tagging indicators (either manually, or with a playbook in a job or incident) and then having the query look for those tag(s).",0,06-20-2022,09:34 AM
52,504713,chrking,can you share a screenshot of the output in the playground after you trigger this command? Thanks,0,06-19-2022,11:06 PM
53,504443,cstone,"Hi Cstone,Attached the screenshot",0,06-17-2022,06:04 AM
54,504443,JOng39,"Hi@JOng39, I don't see any issue in the code. Looks like its calling the API like the documentation suggests. You might need to check this with your debug logs onTanium Threat Response UI.You can verify the same using Postman or similar. Refer -https://developer.tanium.com/site/global/docs/how_tos/tr_alert/index.gspIf this is still an issue after verification, please contact support.",0,06-19-2022,06:25 PM
55,504443,jfernandes1,"Hi@Jersey_Mankowski,It looks like you are passing in the URL to the `file_name` input to `rasterize`. The default filename for the `rasterize` result is simply ""url.png"". Could you try leaving the`file_name` input blank or passing in a different value instead of the URL?",0,06-19-2022,07:27 PM
56,487544,asawyer,Hey@asawyerThe plan is to get the url address in the filename so that when It gets move around or exported to tickets you can tell where the image was from.Rasterize is working fine with default naming.,0,05-24-2022,05:41 PM
57,487544,Jersey_Mankowskaria-labeli,"Hey@Jersey_Mankowski– Ah, I'm tracking now. There are a couple of complications here. The first is the replacement of certain characters, as you mentioned in your original post, and the other is a restriction on filename length (on both the XSOAR and ServiceNow side).The see what XSOAR changed the filename to, download the result of rasterize and view the filename.From my testing, the maximum filename length for ServiceNow is 255 characters. So to pass in a valid file_name arg value to servicenow-upload-file:1. Replace at least the slashes with underscores, so the value is not misinterpreted as a URL (Replacetransformer)2. Truncate the value to 251 characters max to leave room for the file extension – You can do this using theRegexGroupstransformer with regex:^(.{,251})3.Concatthe "".png"" file extensionPlease give that a try and let us know if it works!",0,05-26-2022,07:18 AM
58,487544,asawyer,"Hey@asawyerI like what you are thinking, and that could be half of it, but with the new transforms I have been seeing an error in the RE.py lib, and some other errors with the replace, I did get it to go through as expected but it's still failing to upload the file and says it does not exist, even when looking up by artifact.For reference I am doing the file_name transformations in the!servicenow-upload-filetask. I have also tried a replace on the slashes to underscore directly after the rasterize, but it would never find anything.  I feel like the automatic file renaming by the system is getting these images corrupted or lost somehow, but it's hard to confirm that when I can go download the artifacts.",1,05-26-2022,02:38 PM
59,487544,Jersey_Mankowskaria-labeli,"Hey@Jersey_Mankowski– Re: your third screenshot, I get the same error if I don't pass in thefile_namearg.For the example from your last post, could you share the following so we can troubleshoot further?:1. Screenshots of the exact values and transformers you are using to create thefile_namearg, that are leading to the transformer (replace and regex) errors2. Filename of therasterizeoutput file when you download it onto your local filesystem",0,05-27-2022,09:32 AM
60,487544,asawyer,"So the regex errors are only happening occasionally. Also, I added the 'underscore to hyphen' transform after just having the 'slash to underscore' transform to try and double up and maybe get the system to realize the renaming function since it always seems to look for the file name with the slashes in it and fails the upload when it can't find the file. I also tried it only with the slash transform and was seeing the same results.",0,05-27-2022,04:56 PM
61,487544,Jersey_Mankowskaria-labeli,"Hi@Jersey_Mankowski– In your first screenshot with the error, thefile_namearg was not passed. From my testing, that arg must be passed in order for theservicenow-upload-filecommand to succeed. Could you try running the command again with thefile_namearg?",0,06-02-2022,07:07 AM
62,487544,asawyer,"I am not sure I understand. The second image shows the file_name arguments, also the upload task is looking for the file based on the filename.What am I missing?",0,06-13-2022,05:55 PM
63,487544,Jersey_Mankowskaria-labeli,"The second image shows thefile_name arg, but the first does not, indicating nofile_namearg was actually passed to that command in that first screenshot.I replicated your example and the following worked for me:First, I saved the URL to context keyurl using theSetcommand:Then I ran theservicenow-upload-filecommand, applying the transformers discussed above to thefile_namearg value, as shown in the screenshots below:!servicenow-upload-file id=<SERVICENOW_SYS_ID> file_id=<FILE_ENTRY_ID> file_name=<URL_WITH_TRANSFORMERS> using=<SERVICENOW_INSTANCE_NAME>Please give that a try and let me know if that works for you.",0,06-15-2022,08:34 AM
64,487544,asawyer,"Hi@michal.grznar, I dont think this is possible. Playbook input can be passed as a part of the context only.I would recommend this method. Configure the playbook like this.You can then send a postman request like this.",0,06-15-2022,12:31 PM
65,504092,jfernandes1,"Hi@MKececioglu,Not sure if this is possible with a conditional task. But it possible with a data collection task. Since it saves the user who fill\completed the form. You can also shorten the playbook task by adding a question based on the owner field.This might also be possible via a conditional task. But you will need to go via the API to find out which user competed the entry.TheAssignAnalystToIncidentcommand will not work for your use case.For your reference.",1,06-16-2022,10:03 PM
66,502165,jfernandes1,"@jfernandes1thanks for response i realize that when i set owner field as a data collention question , it automatically populate analyst list and based on the answer, set it as owner which is a great way 🙂 . But still curious about a mandatory ""assing to me"" selection to deploy.",0,06-09-2022,12:55 PM
67,502165,MKececioglu,"@MKececioglunot sure if this is what you are looking for, but wanted to jump in and mention that it is possible to simply run theAssignToMeButton script in a playbook (not just as a button).",0,06-10-2022,12:41 AM
68,502165,asawyer,"Hi@asawyerThis is really o solution thank you, but i need fix one more thing that this automation keeps error state until someone click ""Run automation now"" and this seems liken en error to analyst at first sight, any idea about how can i integrate this into a conditional task or clear the error state befor click.one more thing i realized that xsoar allows us to run commands in ""Completion Note"" inside a standart conditional match and if i can set a fixed command that includes ""!AssignAnalystToIncident assignBy=current"" this will work too.",0,06-13-2022,06:18 PM
69,502165,MKececioglu,"@MKececioglucorrect, theAssignToMeButtonscript does need to be executed manually, either as a button or in the playbook, so that it knows which user to assign the incident to. You could do something like this to try to structure it so the user understands what they need to do:Or as@jfernandes1suggested above, you can also have the user complete a manual task, then use the API to get that user's username, and assign the incident to them. The following API call returns the Work Plan details (replace INCIDENT_ID with the actual ID):",0,06-15-2022,04:26 AM
70,502165,asawyer,"Hi@MKececioglu, playbooks and automation can run in the background so there MUST be user interaction for the ""current"" part of command to understand who it needs to assign the ticket to.As I see it, you have only 2 options.1. Assign the owner automatically without analyst interaction - You can use the !AssignAnalystToIncidentautomation with any one of following parameters - assignBy, onCall or roles.2. Assign the owner with analyst interaction - Button as@asawyermentioned or Datacollection task. I would choose data collection over a conditional task since it easier to implement and better in every way!",0,06-15-2022,03:55 PM
71,502165,jfernandes1,"@jfernandes1@asawyerthank you very much for your support, ""!demisto-api-get uri=""/investigation/INCIDENT_ID/workplan"" works great for me after getting the user information ""setOwner"" automation handles everything.👏",0,06-15-2022,05:27 PM
72,502165,MKececioglu,"I'm a little concerned thatdemisto-api-download isn't what you're expecting. Thedemisto-api-download will download a response from the API endpoint and save it as an artifact in the war room of the current incident. It won't download the response to your browser automatically, although you can download the saved artifact manually.The only thing you have to provide for this command is the URL path. The API key is configured within the ""Demisto REST API"" integration instance.Here's an example of what that looks like. In this example we send a post request to generate a CSV export of incident data, then download the results.The end result is an entry like this:I hope that helps.",1,06-16-2022,07:36 AM
73,503236,chrking,"Hi@kbratt, I think you might need to explain your use case again and in more detail.1. Do you want to download a file that is stored somewhere (Linux filesystem) on the ""Palo Alto"" hosted XSOAR instance? to an incident? - This is not possible for a PA hosted instance. We do not give SSH access and do not allow the SSH integration.2. Do you want to download a file that is inside an incident to your system? - This is not possible since we do not have access your filesystem from the XSOAR UI.3. Do you want to download a file from an external URL and save it inside the incident? - This is possible with some simple python code like below. The automation will accept the ""URL"" as an input.Also, scenario 1 is possible if you're not using a PA Hosted XSOAR platform.Thanks.",0,06-13-2022,05:53 PM
74,503236,jfernandes1,"@jfernandes1, I can gladly explain our use case a little better. Hope this makes sense.We are trying to do #2 in your response above for the most part. We have an on-prem XSOAR environment that we are moving away from, to a hosted instance.Currently on-prem, we are able to copy a file from an incident, to a non XSOAR Server in our environment using the Shared Agent in a playbook.. Moving to the Hosted solution, the shared agents / d2 agents are depreciated, so we are looking for other ways to continue to have this functionality in the hosted solution and are exploring our options.The powershell remoting integration looks promising, but it apparently has a file size limitation on what it is able to upload from xsoar to another Server. I can upload incident files under 275k using the command !ps-remote-upload-file, but anything larger fails. This would be the ideal solution, but I am not sure there is a way around the size limitation.We found the XSOAR API integration and this also looks somewhat promising. It's a little ugly, but I was thinking about using a combination of 2 integrations to get around the limitations. Possibly use the powershell remoting integration to get around the filesystem permissions issue you highlighted to then call the XSOAR API integration GET /entry/download/entryid in a script to download the file.",0,06-13-2022,06:47 PM
75,503236,kbratt,"It sounds like you're looking for a file upload command/integration, like:SMB:https://xsoar.pan.dev/docs/reference/integrations/server-message-block-smb-v2#smb-upload orSCP:https://xsoar.pan.dev/docs/reference/integrations/remote-access-v2#copy-toUploading to a cloud file store and then syncing to your local server is also a potential option depending on what you're looking for. For that an integration like Azure File storehttps://xsoar.pan.dev/docs/reference/integrations/azure-storage-file-share#azure-storage-fileshare-f...or Google Drivehttps://xsoar.pan.dev/docs/reference/integrations/google-drive#google-drive-file-uploadwould do what you need.",0,06-14-2022,09:19 AM
76,503236,chrking,"Thanks for the responses @chrking, much apprecaited.I think the SMB upload integration is exactly what I am looking for. I was able to just upload a file from our hosted XSOAR instance to a server on our network. Will test building this into some automation now and testing, but looks promising for sure.",1,06-14-2022,05:45 PM
77,503236,kbratt,"Hi Michaelsysec242,I guess you are missing the first step of the use case (based on yoursummarize flow).The first step in the use case is receiving an email from the end-user (an email arrive to XSOAR), then using the layout button, reply to that email. When the end-user replies to the reply sent from the XSOAR, it will be part of the same incident.So, the first step isn't ""Outgoing email from demisto to user"", that actually the second step.",0,06-15-2022,09:24 AM
78,503401,YAltmann,"@YAltmann, if that is so then only mail sent by Use of the button on the Email Communication layout will allow this Pre-Process rule/script to work ! In any case the documentation states that as long as the eight digit code is included in the subject the rule will work. Is it possible to run this flow of reply from within the playbook automatically and all future replies will be added to the original mail event ?",0,06-14-2022,04:40 AM
79,503401,michaelsysec242,"For now, the use case doesn't support playbooks (as I said before, the incident should be created by our mail listener).Please see the article of the pack, and the workflow section -https://xsoar.pan.dev/docs/reference/packs/email-communication.The eight-digit code isn't enough, we also check other things like the email thread-ID (so the reply could work) and more.With that being said, we are working on a few enhancements for the pack, and it might be possible, but not sure as the email communication wasn't created for this use case (reply from within the playbook automatically).If you can, please open a-ha request for this enhancement 🙂",0,06-14-2022,07:00 AM
80,503401,YAltmann,"Hi@michaelsysec242, this function is available via our ""Email Communication"" pack. Please update your pack to get the latest version.Could you confirm if you have followed these steps1. https://xsoar.pan.dev/docs/reference/packs/email-communication#configure-the-service_mail-and-mail_s...2. https://xsoar.pan.dev/docs/reference/packs/email-communication#pre-process-ruleWith the above 2 steps you should already start seeing incoming emails with the code being processed by the script. If your still having issue, I would recommend that you start the configuration from the start. The above links have a demo video at the end.Thanks.",0,06-14-2022,07:56 AM
81,503401,jfernandes1,"While it's probably possible to get it to work the way you're describing, you're going to run into some issues like the lack of email tagging support in the O365 integrations.Your best bet is probably to create incidents for all incoming emails to the main inbox, and then:* Use a data collection/manual conditional task to get the verdict from your analyst on if the incident raised off an email is phishing or not.* Store the verdict, along with the sender/subject in the incident fields, as we'll need them later.* If it is phishing, usemsgraph-mail-move-email to move the email to the phishing inbox* Use pre-processing rules to check emails against existing incidents with duplicate sender+subject* If detected, move the new email to the phishing inbox (either with a script, or with ""Link"" then a playbook which detects the linking and self-closes once the mail is moved)This means you have to replicate some of the existing Outlook logic for email moving on the Outlook side, but it should be simpler to implement overall.",0,06-14-2022,08:45 PM
82,502529,chrking,"Hello Chrking, thank you so much for your very quick and complete answer, I deeply appreciate.",1,06-10-2022,01:59 AM
83,502529,benzer,"Hi@benzer, Please mark@chrking's answer as the solution.",0,06-10-2022,02:03 AM
84,502529,jfernandes1,"Hey Jia Kai, you could write an automation that makes an API call to delete the list - you'll need to have the Demisto REST API integration configured for this.The API method used is POST to the following endpoint: /lists/delete(if multi-tenant: /acc_<tenant_name>/lists/delete )And the request body would be:{""id"":""<list_name>""}The basic script would look something like this (add whatever is needed to print a result, set to context, etc.)listName = demisto.args().get(""list_name"")body = {""id"": listName}demisto.executeCommand(""demisto-api-post"", {""uri"":""/lists/delete"", ""body"":body})",0,06-13-2022,07:02 PM
85,501648,nkazinets,"Hi Enes,Did the server config propagate to all tenants, or is it seen only on master?",1,06-08-2022,01:50 AM
86,499871,RahulVijaydev,it's not propagated. I tried setting diagnostic.docker.service.up to false on tenants and this doesn't seem to be working either.,0,06-06-2022,11:41 AM
87,499871,EnesOzdemir,"You can use SLAs on Incident Types, or Start/Stop Timers in different places on the playbook.Check out the video 10 for SLAs & Timers in this series, it may be helpful:https://live.paloaltonetworks.com/t5/cortex-xsoar-how-to-videos/cortex-xsoar-how-to-customer-success...",0,06-06-2022,11:38 PM
88,487518,MBeauchamp2,"@MBeauchamp2thanks for response, now i am able to crate timers for each severity. But i have 56 severity level with 2 different timer in it so now i have added my playbook some conditional task and managed to start related timer. The issue is that when it comes to report creation i need to sum all 5 sla timer duration and calculate an avarege time but as these are custom sla's i cannot find a proper way to do it.",1,05-16-2022,02:55 PM
89,487518,MKececioglu,"@MKececiogluWhy 56? Are you creating multiple SLA Fields due to the SLA values per severity? If so, you can set the SLA for field by issuing the below command. The command can be called after the severity is set.Once an incident is closed you can use the `incident.openDuration` field to check the duration of the incident. You can also have an additional timer\sla that calculates the overall time. You cannot add the `sla.totalDuration` field in a report.",0,05-18-2022,06:37 AM
90,487518,jfernandes1,"Hi@jfernandes1,56 was a typo sorry, it is 5 severtiy indeed and for each severtiy i have 2 sla those are response time and resolution time. I have created 10 timer/ala based on this architecture and i am able to start these timers in playbook after test the sla condition in a conditional task. At the first response of an analyst playbook stops the response timer and after incident close by Default all timers stopped ( in this scenario resolution timer) all is Ok. But when it comes to a report to calculate these timer values for all incident in a time period i am confused about how to detect mean times based on these custom timers.",0,05-18-2022,07:37 PM
91,487518,MKececioglu,Hi@MKececiogluNot sure if you can do it for a table output. But below is how you get it for chart.,0,05-19-2022,12:16 AM
92,487518,jfernandes1,"Hi,setincident automation changes sla for a specific timer and everything is clear now.",0,05-19-2022,03:38 AM
93,487518,MKececioglu,"Hey@MKececioglu, it's a bit unclear what you're trying to achieve - what do you mean by ""response page""?Some elaboration with relevant screenshots would be helpful - but do mind that this is a public community so do not share any sensitive or confidential information.",0,06-06-2022,05:32 AM
94,483113,nkazinets,"Hi@nkazinetsit is the web page that is created for a data collection task, ""response page"" was really a bit confusing 🙂",0,05-31-2022,06:15 AM
95,483113,MKececioglu,"Hi@MKececioglu, Your looking to route client responses via an engine to the XSOAR server. This will help when the client environment is separate from XSOAR's.- You will need to setup an Engine in the client's environments first.- You can then follow this documentation to complete the configuration -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/engines/configure-engin...- You might also want to refer to the HTTPS documentation if you want to deploy the engine in the cloud. Refer - https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-2/cortex-xsoar-admin/installation/post-insta...",0,05-31-2022,06:35 AM
96,483113,jfernandes1,"Hi@michaelsysec242, Did you attach a screenshot or the error? Please re-check your post.",1,05-31-2022,08:29 PM
97,494361,jfernandes1,Error,0,05-29-2022,08:20 PM
98,494361,michaelsysec242,"Hey@michaelsysec242, this issue was identified specifically for Multi-tenant with Elastic setups and was fixed in version 6.6.0. If this is the architecture in your environment, upgrading should fix it, otherwise, I suggest that you open a support ticket with all the information and logs (though I would first try upgrading anyway).",0,05-29-2022,11:24 PM
99,494361,nkazinets,"Many thanks, unfortunately what you mentioned isn't relevant for my XSOAR Setup. I will upgrade in any case as this could solve this problem.",0,05-31-2022,06:49 AM
100,494361,michaelsysec242,"Hey@jpadro, this seems like something that you could also raise as a feature request in our Aha portal, to have such a playbook (or more likely something a bit more generic).Our R&D team is always happy to receive suggestions for playbooks and other content items.The portal ishttps://xsoar.ideas.aha.io/, make sure to be as detailed as you can, and to not share any personal information as this is a public community.",0,05-31-2022,07:49 AM
101,494361,jfernandes1,"Hi@Antanas, I'm guessing you're trying to modify the ToTable automation to save the data to a context key. I would suggest using the extent-context like thisIf you still need to get the automation working, could you send me the yml file?",0,05-31-2022,08:19 PM
102,483733,nkazinets,"Hi@jfernandes1,for some reason extend-context does not work in this case. I specifically try extend-context=NewKey=Key Including the yml code, much appreciated for any ideas.",0,05-31-2022,06:12 AM
103,491730,jfernandes1,"Hi@Antanas, I don't this you're using it right. Refer to the below screenshot. You do not need to specify a key after the ""data="".I still recommend the above method, but in case you want, I've corrected the code too.I found a couple of issues with the script.1. You cannot use 'parent' as a variable since it's a reserved word. Refer - https://www.w3schools.com/js/js_reserved.asp2. I had to change the output of your script a little. Still not sure why yours did not work.",0,05-25-2022,07:27 PM
104,491730,Antanas,"Hi@jfernandes1- your updated script works perfectly fine - thanks! BTW, you still suggested to use extend-context which works after I removed the Key variable. However (I guess) it extends the normal output (seen as piped variables), and not the EntryContext, which should be an HTML table code.",0,05-29-2022,05:09 AM
105,491730,jfernandes1,"Hi@Antanas, Just use the `!ConvertTableToHTML table=${newList} title=""HTML Table""` command. You do not need to use the extend-context option since the code pass data to context under theHTMLTable key.",0,05-29-2022,08:18 PM
106,491730,Antanas,Reply by:@RahulVijaydevThis means that there were no tasks in the playbook with input or output size greater than 10KB,0,05-30-2022,01:25 AM
107,491730,jfernandes1,"Reply by: @RahulVijaydevTypically, load times increase when the playbook becomes bulky. If an update resulted in this, I would recommend opening a support case to request assistance in understanding the root cause. ",0,05-31-2022,12:23 AM
108,494725,tsedaka,"Reply by: @RahulVijaydevYou can select the sub-playbook (at the parent), and there is a toggle at the bottom to set the context to global.",0,05-30-2022,04:44 AM
109,494723,tsedaka,Reply by: @RahulVijaydevClicking on a sub-playbook displays a toggle switch to choose either private or global context https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/incidents/incident-mana...,0,05-30-2022,04:38 AM
110,494721,tsedaka,"Reply by: @RahulVijaydevIn a live playbook, the use of DeleteContext at the beginning is not necessary since the Context starts of being empty (Unless auto-extraction was enabled on the incident type and enrichmment data was outputted). DeleteContext is typically used during development and troubleshooting to clean up context objects when the playbook is re-run multiple times in the same incident, or in a live playbook to delete context objects that do not add much value to the flow of the playbook, but are nonetheless still outputted by commands/scripts, as a context optimization strategy.",0,05-30-2022,04:33 AM
111,494715,tsedaka,"Reply by: @RahulVijaydevFields are not required to capture outputs, unless you want to explicitly map the output of a task using the 'field mapping' utility found under the Mapping tab in the task pane. https://xsoar.pan.dev/docs/playbooks/playbooks-inputs-outputs",0,05-30-2022,04:26 AM
112,494707,tsedaka,"Reply by: @RahulVijaydevIf more than 1 sub-playbook writes to the same context object, meaning they output to the same key, the results are merged for ex. DBotScore is an output common to all enrichment sub-playbooks in the Entity Enrichment playbook that is available out of the box ",1,05-30-2022,04:15 AM
113,494699,tsedaka,Reply by: @RahulVijaydevhttps://live.paloaltonetworks.com/t5/cortex-xsoar-articles/cortex-xsoar-playbook-design-guide/ta-p/4...,0,05-30-2022,04:05 AM
114,494693,tsedaka,"Reply by: @RahulVijaydevBetter is to have the sub-playbook return the outputs you require in the context of the calling playbook. Think of it as a function. You pass a and b, and the function returns c (a+b).",0,05-30-2022,03:57 AM
115,494691,tsedaka,"Reply by: @RVijay1. This will not affect the main playbook as the output is still made available to the parent. Quiet mode suppresses the 'indexing' of inputs and outputs to improve it's performance, especially if the input or output size is large. So no real impact will be observerd with regards to the flow of the playbook. 2. Older incidents are not impacted by the change. Only incidents that were ingested after the change was made are affected.",0,05-30-2022,03:50 AM
116,494680,tsedaka,"Reply by: @RahulVijaydevIt is not possible to make configuration changes to a command's instance all across the board, and has to be performed individually. Searching for the name of the script/command from the playbooks search pane will list every playbook with an occurence of the script/command, and will allow you to make changes accordingly. ex. Searching for 'Sleep' will list all playbooks implementing the Sleep operation.",0,05-30-2022,03:36 AM
117,494668,tsedaka,Reply by: @RahulVijaydevI don’t believe there is any way to unassigna playbook once one has run on the Incident.,0,05-30-2022,03:28 AM
118,494664,tsedaka,"Reply by: @RahulVijaydevThe list can be directly referenced by its name i.e ${lists.list_name}, and used as an input in your conditional along with filters and transformers. There's no real benefit from copying the list into the context when there is a possibility to read the list directly in this way, irrespective of the size of the list ",0,05-30-2022,03:24 AM
119,494649,tsedaka,"Reply by: @RahulVijaydevThe context under which this was suggested may have dictated the suggestion, however, it is certainly not bad practice to use nested sub-playbooks, especially when you need to encapsulate logic that you expect will be repeated. Nested playbooks are ubiquitous in out of the box content i.e content produced by XSOAR",0,05-30-2022,03:18 AM
120,494635,tsedaka,"Reply by: @RahulVijaydevThe maximum duration has not been measured. Iwould consider changing the approach to using jobs, or utilizing the Generic Polling playbook to periodically track the status of the machine instead of sleeping indefinitely. ",0,05-30-2022,03:05 AM
121,494632,tsedaka,"Reply by@RahulVijaydevWorkers are assigned to each automated task from a worker pool as they execute. The worker pool consists of (number of CPU cores X 16) workers for ex. 64 workers in a 4 core machine. When an automated task has to execute, it picks a worker from the pool, keeps it for the entire duration of the operation, and releases it back to the pool upon execution. When all the workers have been consumed, and the worker pool is exhausted, tasks wait until a worker is released. NOTE: Be careful while implementing parallel branches in a playbook, as too many branches can lead to workers getting tied up.",0,05-30-2022,03:00 AM
122,494622,tsedaka,Fill out the condition Left Side Equals Right Side. click the Green Check mark and the Ok button should become available.,0,05-30-2022,02:44 AM
123,494620,tsedaka,HI@cstoneThanks for the update but issue remain same which I already tested.Pls find the below details,0,05-30-2022,02:37 AM
124,492384,cstone,Are you not able to hit the green check box?,0,05-26-2022,04:59 AM
125,492384,ChinmayaNaik,So it should look something like this:,0,05-26-2022,05:07 AM
126,492384,cstone,HI @cstoneThank you so much for the quick help.Great its working fine as per your suggestion.@Chinmaya,1,05-26-2022,05:08 AM
127,492384,cstone,"Hi@EnesOzdemir, Can you see the same results in the warroom? Meaning for each screenshot above there should be corresponding ""Incident info and changes"" entries.I've not seen this behaviour before. It might be that another fieldTrigger script is running. You can check by enabling debug logs. If you still cannot find the root cause, I would suggest raising a support request since this might require investigation of the logs. Could you also confirm that the script in ending as a success? Failed fieldTrigger scripts prevent field changes.",0,05-26-2022,05:11 AM
128,492384,ChinmayaNaik,"Hi, thank you for helping me. yes I can see the results in the warroom. I believe the script isn't failing because I don't see any errors. The support told me that this issue is related to product implementation so they sent me here.",0,05-26-2022,05:15 AM
129,489327,jfernandes1,"I think I found the root cause of the problem. It's related to this part of the field. When I uncheck this all the SLAs are working properly.I had no problem with this feature on version 6.2. As I have said before I am running only the following commands to make sure it isn't my script that's causing the problem.```demisto.executeCommand(""stopTimer"", {""timerField"": ""timetoassignment""})demisto.executeCommand('startTimer', {'timerField':'responsesla'})```",0,05-22-2022,10:23 PM
130,489327,EnesOzdemir,"Hi@EnesOzdemir, I was able to locate the ticket and I think I understand the issue better now.Yes, this is limitation of the platform. To prevent a know issue with DB version synchronisation since 2 different versions of the incident are sent to DB at the same time. The limitation was document here -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-2/cortex-xsoar-admin/incidents/incident-mana....You will need to de-select the ""Run triggered script after incident is modified"" option.",0,05-22-2022,11:19 PM
131,489327,EnesOzdemir,"I don't quite understand what ""Run triggered script after incident is modified"" mean. I used to think that I wouldn't be able to access the value after the field is modified if I don't select that option(with it I thought I was forcing the script to run after that very field is changed and modifications took place). I deselected it and it's working now.Why the option worked on 6.2 I don't understand it either.> To prevent a know issue with DB version synchronisation since 2 different versions of the incident are sent to DB at the same timeCan you please elaborate on this one because this tenant is created after the upgrade?",0,05-23-2022,03:16 AM
132,489327,jfernandes1,"If the field-change triggered script were to error to any reason (and youdidn't have ""Run after"" box ticked) then the field would not be changed. This can be an issue for mirrored incidents or incidents where the data is automatically updated. To prevent this, the ""Run after..."" box can be checked to ensure that the field is updated before running the script. This ensures that the field is modified correctly even if there are errors.If your field-change-triggered script is not going to modify the incident in any way, then it's good to tick this box. This avoids any failure on updating fields and can still happily error out if it needs to. If it DOES modify the incident what happens is:- Incident is modified by the user / automated function and saved to a version (from version 1 to version 2, for example)- Field change triggered script runs and modifies part of the original incident (version 1)- Committing the changes errors because the version the script changed is earlier than the one that is ready for commit. This still results in the original change being made, but the change being made by the script is dropped.",0,05-23-2022,06:30 PM
133,489327,EnesOzdemir,Thank you very much @ABurt@jfernandes1,0,05-24-2022,01:23 AM
134,489327,ABurt,"Hi@MKececioglu,Method 1: Create a markdown field. Use the ToTables function to populate the data in the field. (Easiest + table looks nicer)Method 2: Create a GridField and use the setGridField automation to populate the data in the field. (Can be resized and sortable(I think))Method 3: If you want a graph. You can use the dynamic section with a script to populate the data.https://docs.paloaltonetworks.com/cortex/cortex-xsoar/5-5/cortex-xsoar-admin/widgets/create-a-custom...Warnings: It is not recommended to put large amount of information into a field. This will directly affect your incident load times and index sizes.Recommended Method - Use the ToTables function to send the output to the warroom. Mark the output as evidence. Ask your analyst to view this information on the evidence board.",0,05-24-2022,01:36 AM
135,489327,EnesOzdemir,"Hi@MKececioglu, If the above solution worked for you. Please mark this as solved. Thanks.",0,05-24-2022,11:33 PM
136,488196,jfernandes1,"Hi@jfernandes1,This method is worked for me, thank you for your support.Method 1:Create a markdown field. Use the ToTables function to populate the data in the field. (Easiest + table looks nicer)",0,05-18-2022,07:28 PM
137,488196,jfernandes1,"Hi@Antanas, not sure if there is a system transformer that can do a complex operation like that. You'll need to write a custom automation. Maybe something like this...",0,05-22-2022,10:26 PM
138,488196,MKececioglu,"Hi @jfernandes1, thanks, your POC code actually works! I would like to make a generic case from this. You specifically useHow can I get and use this field, if it is different next time; or there are more than 1 subkeys under Hostnames? So far I came with below code, but not sure how to handle Hostname.",0,05-23-2022,12:38 AM
139,487258,jfernandes1,"Hi@Antanas, could you try this. Save the text as yml file and upload it to the automations page. Its more flexible. you can issue the command like below.!joinListWithLookup list1=${data.data.Emails} list2=${data.data.Hostnames} matchingKey=IP",1,05-15-2022,03:22 PM
140,487258,Antanas,"Hi@jfernandes1, this worked like charm! I tested this with a bigger set of real life data, all appears as expected. For the record, I made some changes to be even more generic: added matchingKey2 in case the key name is not the same in both lists; added a ""parent"" key so I could define each time where the results would be stored in. The final code is as follows:Thanks a lot for your help!",0,05-19-2022,04:42 AM
141,487258,jfernandes1,Thanks for the info,1,05-19-2022,07:14 PM
142,487258,Antanas,Thanks for the info,0,05-22-2022,04:22 AM
143,429056,gfilippov,Thanks for the info,0,05-19-2022,10:38 AM
144,414328,gfilippov,This message is to remove it from the unanswered topics,0,05-19-2022,10:37 AM
145,381217,gfilippov,This message is to remove it from the unanswered topics,0,05-19-2022,10:37 AM
146,352906,gfilippov,This message is to remove it from the unanswered topics,0,05-19-2022,10:36 AM
147,351730,gfilippov,This message is to remove it from the unanswered topics,0,05-19-2022,10:36 AM
148,351184,gfilippov,"Hi@EnesOzdemir,Correct, CentOS 8 is no longer supported. CentOS Stream is also NOT supported. We would recommend switching to CentOS 7 or one of the other supported operating systems listed here:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/installation/system-req...",0,05-19-2022,10:36 AM
149,341858,gfilippov,"Hi@kbratt,Could you try something like this",0,05-19-2022,10:36 AM
150,487715,asawyer,"Looks so simple ! Thanks, that is working great",0,05-17-2022,05:58 PM
151,486929,jfernandes1,"Hi@AnkitKumarTCS,Refer to these articles for the configuration part.https://support.atlassian.com/opsgenie/docs/create-a-default-api-integration/https://docs.opsgenie.com/docs/api-access-managementRegarding you other question, for an integration in OpsGenie, this is something you need to check with the vendor. No integration in XSOAR will ever be able to generate API keys directly.",1,05-12-2022,06:28 PM
152,486929,kbratt,"Hi@Jersey_Mankowski, You would need to process the URLs as a list. I would recommend using a sub-playbook with the ForEach function. If you pass the URL key as a parameter, it will send 1 URL to the sub-playbook for every loop.Regarding your other question. First check the SNOW API to see it they allow it. If you find the API call create a feature request.",0,05-13-2022,08:43 AM
153,486322,jfernandes1,"Thanks@jfernandes1,How would you call a ForEach function? I am not seeing anything in the documentation.",0,05-11-2022,05:59 PM
154,485853,jfernandes1,"Hi@Jersey_Mankowski, screenshot below.",0,05-09-2022,09:33 PM
155,485853,Jersey_Mankowskaria-labeli,"Aha, only available on sub-playbooks. Thanks@jfernandes1",0,05-10-2022,07:40 AM
156,485853,jfernandes1,"Hi@EphremGezachew,You can log into the Customer Support Portal and navigate to Assets, where you can see which products your company has purchased along with expiration dates. Please let us know if that helps.",1,05-10-2022,07:25 PM
157,485853,Jersey_Mankowskaria-labeli,"Hi Antanas,You will need to create a custom automation for this. The automation will have to loop the array and dict to remove the columns. I'm attaching some code I had written that does something similar. I had to process a CSV file and save specific columns.",0,05-11-2022,07:49 AM
158,483052,asawyer,"Thanks! I definitely will try it. I also finally found a workaround for this - i import the whole thing with with parseCSV, and then use a transformer GetFields in SetAndHandeEmpty to save the selected keys. Then i can delete the the initial one. Of course, your suggested solution is more optimal.",1,05-10-2022,04:10 PM
159,485603,jfernandes1,One more thing to keep in mind is the size of the CSV file. Adding a lot of data to context might affect incident load times and also create large indexes. The script solution takes a file as input and outputs another. No indexing is performed on a file's contents.,0,05-09-2022,09:50 PM
160,485603,Antanas,"Hi@AChawale, I'm not aware of any method to force incident polling on-demand. You can only vary the incident fetch count and frequency. You can make changes to those parameters on-demand.",0,05-09-2022,10:57 PM
161,485603,jfernandes1,"Hi@MKececioglu, In both cases the command is ran in the same fashion.If 1 instance - `!command parameter=pValue using=instance1`If 2 instances -`!command parameter=pValue using=instance1``!command parameter=pValue using=instance2`After the playbook fails, check if you can run the command- by re-running the task- from the warroomIf this still fails it must an issue with the instance configuration.",1,05-09-2022,11:16 PM
162,484915,jfernandes1,"The return of demisto.execute() is a list of dicts. You can use pformat() to view the structure of the return object.I like pformat() because it prints the output with clear spacing.The results you are after are probably going to be inI would also suggest taking a look at execute_command(), it does some additional error checking for you and extracts the contents from the returned data so you don't have to do `current_unique_IDs[0][""Contents""]`, it does it for you. It's a drop in replacement for demisto.executeCommand(), so it would look likeLastly, demisto.results() is deprecated. The recommendation now is to use return_results(). Which from your example above, would just be this",0,05-09-2022,09:56 PM
163,485807,jfernandes1,"great response Tyler. Appreciate you learning my up a bit.Everything worked as expected. I will mark the response as resolved. But one more question.I searched for documentation onexecute_command(""query"" andAny chance you have a link that document the query execute_command or let me the attribute syntax for size?",0,05-09-2022,09:41 PM
164,484566,tyler_bailey,"So the parameters for ""query"" aren't going to be listed under the documentation for ""execute_command"". ""execute_command"" is just a function to call a specific command within XSOAR. The command that you are calling is ""query"". You can see the parameters that are accepted for that command in the XSOAR GUI by first clicking the ""!"" next to the cli at the bottom of the pageAnd then you can search for the command you are running, then click run.This will show you the available arguments for the command that is selected.You can also view the command arguments by viewing the integration code on the settings page, but the Commands and Scripts view via the GUI CLI is ""prettier"".In this case I believe you would want the ""limit"" argument, which defaults to 50. So the code would look like this:Also of note, the ""query"" command from the Generic SQL Integration is deprecated. Looks like it's recommended to use ""sql-command"" in place. It looks like the command arguments are the same so you should be able to just replace ""query"" with ""sql-command"".",0,05-03-2022,11:03 AM
165,484566,Tripper,"Hi@Tripper, Just to add on to@tyler_baileyresponse.Downloaded as a file. it is an odd | delimited file. - This is a markdown file.So you would need to output the response like this.You can also force the string like below.",0,05-03-2022,11:24 AM
166,484566,tyler_bailey,that's pretty Clean. Appreciate that snippet!,0,05-03-2022,12:34 PM
167,484566,jfernandes1,appreciate the depth of the response!!,0,05-03-2022,05:41 PM
168,484566,Tripper,"Hello,Are the tenants all deployed on the same host? How much disk space is allocated to the host?As per sizing requirements, for every new tenant added to a host, CPU and Memory specifications would have to be scaled up:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-multi-tenant-guide/plan-the-m...",0,05-04-2022,08:09 AM
169,484566,Tripper,"Hi@EnesOzdemir, This looks like a docker issue. I would recommend raising a support ticket.",0,05-04-2022,08:10 AM
170,483771,RahulVijaydev,"Hi Richard,Your claim details don't look right for Azure. They should look like this.Take a look at this documentation -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/users-and-roles/authent...",0,05-02-2022,11:42 AM
171,483771,jfernandes1,"Thank you very much for the reply, I have never removed the schema before and have tried it both ways. I have re-added the schema back and still get the same error. I think what I am in need of is what the entry should look like on xsoar side of things. I got the removal of the schema line by looking at the example above in the link that you gave me.Here is a screen shot of my saml response with the schemas being sent to xsoar:Any other ideas would be greatly welcomed.Richard",1,05-03-2022,05:59 PM
172,482767,jfernandes1,can you share a screenshot of your integration settings as well please,0,04-26-2022,06:36 PM
173,482767,DriveYourAceOff,"My current settings:If you want to see all of the settings, please let me know. I can take additional screen shots.",0,04-27-2022,08:10 AM
174,482767,cstone,Yes please,0,04-27-2022,09:25 AM
175,482767,DriveYourAceOff,Thank you again for assisting.Richard,0,04-27-2022,09:59 AM
176,482767,cstone,"Hi@DriveYourAceOff, it should looks like this.Also the last option should look like this. According to the documentation -Let me know if this works for your.Thanks, Jeremy. ",0,04-27-2022,10:07 AM
177,482767,DriveYourAceOff,Is there any way that you can tell me what the fields say at the end of the attributes you used.,0,04-27-2022,10:22 AM
178,482767,jfernandes1,"Thanks again, I am still getting the same error however. Here are my new settings, and I believe that they are correct. I am thinking that I may start fresh and try again, but here are my newest settings:I se the appid section and copied that value to put in below:The only field in question is the group field. I feel like that may be wrong as there are several different ways to make the group throughout the instructions. I have used the below method, and it does look like it is getting the correct group from Azure in the saml response xml.Thanks again for the help!Richard",0,04-27-2022,10:02 PM
179,482767,DriveYourAceOff,"Reply by@poverton:You have a main repo, and you can fork from it. However the forks are not main, by both design and name. For the purposes of the demo and general recommendation, it is not recommended to push to main, but rather create unique branches for each envrionment. ",0,04-28-2022,05:43 AM
180,482767,DriveYourAceOff,"Reply by@poverton:You do not have to clone using SSH, the example give was where to quickly find the SSH details to intpu into the content repository on your xsoar servers. Modifications may be required depending on where it's hosted and if ports other than 22 are used for SSH.",0,04-28-2022,01:12 PM
181,484365,tsedaka,Reply by@poverton:Dev suggested requirements are based on the number of incidents and integration ingested: https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-2/cortex-xsoar-admin/installation/system-req.... Hosted enviroments cannot be resized and have hard limits: https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-hosted-service-guide/hosted-s... If you plan to develop and test heavily on your dev environment then it we would recommend you plan for on-prem deployment and match the suggested production system requirements.,0,05-02-2022,02:21 PM
182,484360,tsedaka,"Reply by@poverton:In Gitlab, Go to Settings > General > Merge requests then Uncheck the box: Enable 'Delete source branch' option by default",0,05-02-2022,02:07 PM
183,484358,tsedaka,"Reply by@poverton:The setting shown in the webinar was UI.version.control.admin.only, and is meant to allow any role with administrators to push content. https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-1/cortex-xsoar-admin/remote-repository/edit-... It will not stop analysts for checking content and installing, which was shown in the demo. RBAC can be used to ensure only authorized users can make changes to content: https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-5/cortex-xsoar-admin/users-and-roles",0,05-02-2022,01:58 PM
184,484356,tsedaka,"Reply by@poverton:there a lot of tools you can use, but you might want to check out something like HAML Diff: https://www.yamldiff.com/ or https://eloquent-hodgkin-f52b42.netlify.app/ or https://github.com/homeport/dyff",0,05-02-2022,01:55 PM
185,484353,tsedaka,Reply by@poverton:This is a great idea. I would suggest opening a Feature Request with that suggestion: https://xsoar.ideas.aha.io/.,0,05-02-2022,01:50 PM
186,484348,tsedaka,"Reply by@poverton:Yes, you can use ansible to deploy xsoar, however, this is not supported by PAN and therefore do not provide documentation steps on how to do it; but it can be done. ",0,05-02-2022,01:41 PM
187,484344,tsedaka,"Reply by@poverton:You can try to use the JOB - XSOAR - Export Selected Custom Content pack, which is found in the Simple Dev to Prod pack: https://xsoar.pan.dev/marketplace/details/XSOARSimpleDevToProd. You also might want to use the backup the database and restore from that to ensure you capture every thing: https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/disaster-recovery-and-l... Note, you will still need to manually backup the directories noted on the KB.",0,05-02-2022,01:37 PM
188,484336,mbordach10,"Hello,Have you had a chance to look at our marketplace content and the relevant docs yet? We should have out-of-the-box integrations for this purpose.",0,05-02-2022,01:20 PM
189,484333,mbordach10,"No, I am yet to do that. I would appreciate your giving me some pointers on how to navigate to the content on your marketplace.Thank you.",0,05-02-2022,01:17 PM
190,484055,RahulVijaydev,"Here is the list of resources for learning about the marketplace:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/marketplaceAccessing the marketplace:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/marketplace/access-the-...Once you register, the content should be accessible to you from the XSOAR UI",0,05-02-2022,11:32 AM
191,484055,JideAj,"Hi@jboyd98,Can you try the `qradar-get-asset-by-id` command instead. This should list all the vulnerabilities.Thanks, Jeremy.",0,05-02-2022,11:45 AM
192,484055,RahulVijaydev,"Hi Jeremy,Thanks for the suggestion, although it looks like it returns similar data to the assets-list:I'm trying to get the Products installed; which right now the ""Products"" row shows an Id number and I don't know the corresponding qradar api to translate.And the vulnerability is just a count VS what vulnerabilities at risk...Let me know your thoughts and if you know how to query the details -Thanks again,Boyd",0,05-02-2022,11:48 AM
193,483532,jfernandes1,"Hi Byod,Integrations developed by XSOAR do NOT drop or modify data from an API call. I would suggest running the command with the `raw-response=true` parameter. This would show you all the data returned by the API call. If you find the missing information there you can use the `extend-context=` parameter. For more information refer -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/playbooks/extend-contex...If the information is still missing, it is a limitation the QRadar API. I would suggest raising a support case with them.Thanks,Jeremy.",0,04-28-2022,08:45 PM
194,483532,jboyd98,"Thanks Jeremy,You're correct. This is more a QRadar API question, but I don't have current access to post the question on IBM forum. Just was wondering if anyone had tried to get this data into XSOAR from QRadar previously.Thanks,Boyd",0,04-29-2022,06:46 AM
195,483532,jfernandes1," to reference an input in python, you would use demisto.args().get('EntryId'). Job_softwaredate_Update_Trip need to have an argument called 'EntryId' on it.",1,05-02-2022,01:41 AM
196,483532,jboyd98,"totally appreciate the response C. I think i was confused between inputs and attributes. Once i added the argument, i now see the default value. So making progress.Since I am seeing the default value for the argument instead of the value that was returned by the previous automation, i'm either not referencing the right var or it isn't set up to be returned to the next autimation.The output on the previous automation has an output -Do I need to have the file as part of the reference?",0,05-02-2022,09:10 AM
197,483868,cstone,"something i just noticed is in the warroom message for the download step, EntryID isn't in the list of outputsIt is in the output list for the download step just like the rest that are being displayed above step. However i can't reference any of the file attributes -demisto.results(demisto.args().get('size'))demisto.results(demisto.args().get('Type'))demisto.results(demisto.args())The only value in args is the default value i set for the attribute. So the values/outputs from the download step, are not being passed to the next step. Not sure what I am doing wrong or the thing to post to help you to help me . . .",0,04-29-2022,01:22 PM
198,483868,Tripper,figured out what i was missing. obviously I am new to demisto/xsoar.I had outputs and inputs/attributes listed. the piece i was missing was mapping the inputs to outputs in the pervious step.,0,05-02-2022,06:07 AM
199,483868,Tripper,"Hi@Manikandan_sam,Since there is no query\filter option inside the integration. You can drop the unwanted incidents using a pre-processor.Refer -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/incidents/incident-mana...Thanks,Jeremy.",0,05-02-2022,06:14 AM
200,483868,Tripper,the preprocessing rule using drop means it as a drop specific endpoint or details to dropbut how can i get a specific endpoint username incident that is only received in xsoar in the pre-process rule?,0,05-02-2022,08:01 AM
201,484005,jfernandes1,Have you tried using the sub-playbook for 'Context Polling'?,0,05-02-2022,01:49 AM
202,484005,Manikandan_sam,"Also, you may need to provide an index for the object in the 'Results' array. Something like 'Tanium.QuestionResult(val.Results.[0].Status !=='Complete, All Patches Applied').QuestionID",0,05-02-2022,01:55 AM
203,482577,ABurt,"Hi, I configure as what suggested. But Im getting this warning messageWarning: no ids matching the dt condition were found. Verify that the condition is correct and that all ids have finished running.Tanium:{} 2 items",0,04-26-2022,03:39 AM
204,482577,ABurt,"Hello,Rasterized images are saved under the InfoFilecontext path. Did you try referencing the entryIDs under that path?",0,04-26-2022,04:23 AM
205,482577,JOng39,That's good info Rahul.But when I try to pull from InfoFile I still am not seeing something. Do I need a separate query beforeor can I just 'get' from 'infofile' in the existingservicenow-upload-file step?,0,04-27-2022,01:31 AM
206,482404,RahulVijaydev,Can you show me how you're attempting to execute the command?InfoFile consists of all the rasterized entries. So you would run the command as follows:!servicenow-upload-file file_id=${InfoFile.EntryID},1,04-25-2022,12:50 PM
207,482404,Jersey_Mankowskaria-labeli,Here is what I just recently tried but still not pulling anything. I am only trying the filter this attempt because it was still pulling nothing without one.,0,04-25-2022,01:44 PM
208,482404,RahulVijaydev,My suspicion is that this is a race condition. the data isn't available from the previous task to pass to the servicenow upload task. just put a sleep task between them for a few seconds and see if this resolves the issue.,0,04-25-2022,02:20 PM
209,482404,Jersey_Mankowskaria-labeli,"Thanks Cstone,But the rasterize step is way earlier in the playbook. I even am uploading other items to the ticket before this step and they always get in fine.But you were right, the sleep timer got the imaged in fine, thanks a lot!",0,04-26-2022,06:46 AM
210,482404,cstone,"Hi@MKececioglu,what version of XSOAR are you running in your multi-tenant environment?You might want to check the time range for your dashboards... You can try setting it to different time ranges and see if it makes any difference. Also, does it pull any information if you select individual tenants?Thanks.",0,04-26-2022,06:52 AM
211,482404,Jersey_Mankowskaria-labeli,"Hi@AbelSantamarinait is 6.5 and even if i select for one tenant for a short period of time like 1 day, it is still loading. But if i browse into the tenant and look for the same dashboard it is populated.",0,04-26-2022,07:33 AM
212,481840,AbelSantamarina,"Hi@MKececioglu, you might want to contact support for this. This might be a memory or space issue. You will need to send them the debug log bundle and the HAR file generated while you try to load the incidents page.",0,04-22-2022,07:57 AM
213,481840,MKececioglu,"This looks like an account permissions issue. according to the api docs, you need to add the access key you are using to the allowlist to resolve this.https://help.sumologic.com/Manage/Security/Access-Keys",0,04-24-2022,11:30 PM
214,481840,jfernandes1,"Hello,maybe I understood why:after the initial trial period, during which we used the Sumo Logic Enterprise trial, we activated the Essentials version which does not accept search API requestshttps://help.sumologic.com/APIs/Troubleshooting-APIs/API-403-Error-This-operation-is-not-allowed-for...Anyway thank you very much for the suggestion thanks to which now I understand what happensRegadsFabio",0,04-25-2022,06:18 PM
215,481934,cstone,"Hello,You will want to first make sure the field (in this case a field called URL) is added to your incident type and then map the ""event info"" field to that incident type. AND then be sure you are displaying that field on your incident layout (in your case you want it to be displayed on the summary tab so that's where you would add the field.Here are some helpful links to guide you:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/incidents/incident-mana...https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/incidents/classificatio...https://docs.paloaltonetworks.com/cortex/cortex-xsoar/5-5/cortex-xsoar-admin/incidents/incidents-man...Hope this helps.",1,04-22-2022,06:08 AM
216,481934,FabioPiluso,"Ok, after a bit more of ""playing"", I have seen this. I created a new Incident Type and defined this field:The ""post processing"" using this script. I have removed this configuration and now it closes OK.Now, next question.... is... why this automation is reporting an error.. 🙂",0,04-22-2022,06:34 AM
217,481883,cstone,"Hi@miguel.tubia,Looks like an issue with docker. Did you run the post installation health check -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/installation/post-insta...If you continue to see this error, please raise a support case.Thanks,Jeremy.",1,04-22-2022,05:24 AM
218,481018,miguel.tubia,"Hi!thanks! All checks are ok, and now... I can generate a report with no error, so... Mistery!Thanks for your help!!Regards.Miguel.",1,04-19-2022,07:53 AM
219,481018,jfernandes1,You can download the list by exporting custom content if you need a backup of it? You can also set Role permissions on who can edit the list to prevent that if you need?,0,04-20-2022,04:44 PM
220,481018,miguel.tubia,"Let's clarify the problem. This is the example of my ip list and one of my playbook adds or removes from this list but i want to use a TTL for each entry as i dont want to keep these ip addresses in this list forever.1.1.1.1,2.2.2.2,3.3.3.3,12.44.55.3,5.6.6.5",0,04-21-2022,01:06 AM
221,480724,MBeauchamp2,"MKececioglu,Good morning! Can you talk a little more about your use case, please? (why the IPs are added/removed? what they are used for? is their own interaction a single playbook?)I think you are looking for some type of expiration for those IP addresses, and I have some ideas on this.",0,04-18-2022,07:43 AM
222,480724,MKececioglu,"Hi@MKececioglu,This is hard to do in a list or CSV format. You'll need to create an automation that handles both the IP and the expiry date.Another solution would be to use the indicator expiration built in to platform.- Ingest list of IPs as IOCs- Add specific tag for the IP list ingested- Set the indicator expiry at ingestion timeThanks,Jeremy.",0,04-19-2022,12:38 AM
223,480724,jwilkes,"Hi,May be you can mention the closed date in the widget query with other conditions-sample query -status:closed closed:>=""2022-01-01T00:00:00 +0800""",0,04-19-2022,04:52 AM
224,480724,jfernandes1,"Thanks, but with a line graph widget it won't plot against the day closed. The x-axis is the date occurred. I want the x-axis to be the date closed.I'd like to be able to see a line graph of the cases closed by analyst where the date on the x-axis is the date closed.",0,04-20-2022,05:12 PM
225,481107,sramesh-7,"Hi@jboyd98, this is currently not supported since it would break some platform components.- Incidents are partitioned based on the created date field. Partitions are opened and loaded into memory based on the created range.- Every incident has a created date field by design. This results in fewer dashboard and widget errors.There is a Feature Request for the same.https://xsoar.ideas.aha.io/ideas/FR-I-1117. I would recommend that you still vote and comment on it since your point about plotting field might still be valid.Thanks,Jeremy.",1,04-19-2022,10:31 PM
226,481107,jboyd98,Try adding a retry to that task under the Advanced tab. The version mismatch may be because 2 Incidents both tried to update the list at near the same time.,0,04-20-2022,08:02 AM
227,481107,jfernandes1,"Thank you@MBeauchamp2this solution should work i think, let me try and update the topic.",0,04-20-2022,03:45 PM
228,480711,MBeauchamp2,"Content pack updates do not require downtime or a snapshot, they can be downloaded and installed directly from Marketplace.If you are in a multi-tenant environment, you will need to do a sync to all the tenants to push the updated pack.There is also the option to revert back to previous versions of the pack once installed.",1,04-18-2022,07:41 AM
229,480711,MKececioglu,"@michaelsysec242Do you have access to the PaloAltoNetworks support portal? We will need to look at logs, and possibly get on a call to troubleshoot this further.",0,04-19-2022,12:34 AM
230,480746,AbelSantamarina,"Many thanks Rahul,this error was resolved through the support channel. Initially they recommended a few Permissions on the API Role in XDR. The issue was directly resolved by ensuring that the Time on the Xsoar was up to date and synchronised. ",1,04-18-2022,08:46 AM
231,480153,RahulVijaydev,Perfect! Glad you got it resolved.,0,04-13-2022,10:13 AM
232,480153,michaelsysec242,Be sure that the First fetch time is formatted in yyyy-mm-dd or yyyy-mm-ddThh:mm:ss. see my attached screenshot,0,04-14-2022,07:00 AM
233,480153,RahulVijaydev,"Thanks for your response.I have tried with ""2022-04-01T00:00:00"" and ""2022-04-01"".The test button returns OK, and from any playbook I can execute commands, so I think that the rest of the parameters are OK.",0,04-14-2022,03:54 PM
234,479988,cstone,where are you seeing this error?,0,04-12-2022,02:52 PM
235,479988,miguel.tubia,Here for example:and from the mapping Editor after selecting the instance:,0,04-12-2022,02:54 PM
236,479988,cstone,"OK, sorry, not date related issue.In line 297, this line:should be:In order to not get an error from Blueliv API.How can I send this issue to be fixed?",0,04-12-2022,02:58 PM
237,479988,miguel.tubia,,0,04-12-2022,03:01 PM
238,479988,miguel.tubia,Thanks!,0,04-12-2022,03:55 PM
239,479697,AbelSantamarina,Please follow the DEV requirements here:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/installation/system-req...It is possible you can use less than this as well.,0,04-11-2022,11:27 AM
240,479697,jboyd98,"The issue is you have ""owner"": {...}it should be like this:{""owner"":""jboyd@x.onmicrosoft.com"",""assignedTo"": ""Joshua Boyd"",""email"": ""soc@email.com"",""objectId"": null,""userPrincipalName"": null}",0,04-11-2022,01:06 PM
241,478897,jwilkes,"Also, adding a note to the above response - The JSON you are attempting to use is the result of a command execution, not the structure the mapper is expecting. To easily obtain the JSON representation of an incident, you can use this URL https://hostname/incident/load/<incident_id>for ex.https://hostname/incident/load/100.Copy the json into a file, upload it into the mapper, map the fields and then create the incident.",1,04-07-2022,04:59 AM
242,478080,cstone,Sorry my mappings have it under properties.owner.owner,0,04-04-2022,12:16 PM
243,478080,RahulVijaydev,"Thank you both, got it!",1,04-04-2022,12:20 PM
244,478080,jboyd98,Awesome! Let us know if you need more help🙂,0,04-04-2022,12:26 PM
245,478080,jboyd98,https://hostname/incident/load/<incident_id>Actually that didn't work for me; just confirming is that the correct syntax?,0,04-04-2022,02:59 PM
246,478080,RahulVijaydev,"Yup, it's this format -https://hostname/incident/load/100 where 100 is the incident id.Make sure to remove the pound sign from the url.",0,04-04-2022,03:00 PM
247,478080,jboyd98,Wierdso this returns:https://xx.xx.xx.xx/acc_CCDev01#/Custom/caseinfoid/863https://xx.xx.xx.xx/incident/load/863Returns,0,04-04-2022,03:16 PM
248,478080,RahulVijaydev,"@RahulVijaydevTrying to get this to work, any advice. Screenshot above, this command doesn't seem to be working, but it would make my life much easier if would work 🙂https://hostname/incident/load/<incident_id>Once I have that, should i be able to import using the upload json option to create the incident without any subsequent mapping?",0,04-04-2022,03:19 PM
249,478080,jboyd98,"Hi Michael, does the application return a status code or a pop-up with that message?",0,04-04-2022,03:30 PM
250,478080,jboyd98,It is a pop-up message when I access the Automation Menu. No error code is required and server logs do not show any evidence of what has gone wrong.,0,04-06-2022,10:04 AM
251,477878,RahulVijaydev,"I added an instance for CISA to my environment and it only pulled 10 items the first time. It looks like on the preceding pulls, it's not clearing the number of fetches from the first time, it's only updating the timestamp even though it didn't actually find anything new from the feed.",0,04-04-2022,09:58 AM
252,477878,michaelsysec242,@IT_LicensemanagerCan you share the error please.,0,04-05-2022,01:03 AM
253,477987,cstone,"Can you kindly share the integration instance settings? namely the query used for fetch. If set correctly, XSOAR should not be returning any incidents from the API with 'magnitudes' under threshold - used to filter 'fetch'I also suggest test query in Qradar API playground to ensure it performs as expected. If it doesn't, cross reference the search/query syntax with Qradar documentation, test again Qradar API playground, then update you integration instance in XSOAR.Hope this helps.",0,04-04-2022,09:23 AM
254,477907,cstone,"Whats confusing is if look at example incident201769, the magnitude is recorded as 5 under the incident's QRadar Offense tab.Then if I go run the following in the playground it shows a magnitude of 2.",0,04-04-2022,06:05 AM
255,476980,jgomes,"Can a user modify the magnitude of an offense?No, This is a calculation based on the Severity, Relevance and Credibility.From the details you have given so far, there is a discrepancy between Q and XSOAR. What you can do here is to use the same query in the QR interactive API guide and find out if the returned result is the same if it is this has to be raised with QR support.Query Examples :https://www.ibm.com/docs/en/qsip/7.3.3?topic=api-filter-syntaxAPI Access guide : https://www.ibm.com/docs/en/qradar-on-cloud?topic=api-accessing-interactive-documentation-page",0,03-31-2022,07:43 AM
256,476980,jboyd98,"Hi @Priyash7 ,In order to get better traction for this I've moved your post to the Cortex XSOAR discussions area.Cheers !-Kiwi.",0,03-31-2022,08:53 AM
257,476980,vidurasupun,"Hi Josh, I would need to double-check but I'm not sure if field-trigger scripts will work at all on incident closure. Once the incident is closed, most things lose the ability to execute. A field-trigger script wouldn't be triggered until after the fields are modified, therefore the incident would already be closed.This sounds more like a case for a post-processing script:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/incidents/incident-mana...Let me know if that helps.-Lance",0,04-03-2022,01:19 AM
258,476773,kiwi,"Thanks Lance -We do have our field change script working currently when closing a single instance.It even works if you choose the ""mass"" close button and only select one record.it's when you select two or more records; it's like it doesn't understand how to reference or loop through the incidents.I think I would have the same question even if I created a post processing script.The example here:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-6/cortex-xsoar-admin/incidents/incident-mana...How would I loop through for each incident since there would be more than one:",0,03-31-2022,01:33 AM
259,474096,LancePettay,"Update: I did test this, and I am able to get the field-trigger scripts to work even upon batch incident closure from the incidents page.There is no need to change the script as it doesn't run any differently when you're closing multiple incidents. It runs from the scope of each individual incident, i.e. the script will run once per incident.Perhaps there is an issue with the script logic? Maybe the concurrent runs are conflicting somehow? Would you be willing to share the script itself? Please sensor anything that would be considered sensitive to you or your organization.",1,03-17-2022,10:16 AM
260,474096,JoshBoyd,"<Update: Simplified the script>Thanks again, appreciate your helpWe have a custom field, sentinelclosereason, in our close form.There's a few reasons we have this, but ultimately when it changes and the incident is closed and the below script will set the system close reason and close the sentinel incident.This works if close an individual incident directly.Just trying to debug to see why the multiple case closures aren't setting the close reason and close notes the same.---Start of Script-----### Close Sentinel Casereturn_results(""Trying close sentinel script"")command_sentinel = ""azure-sentinel-update-incident""external_id=demisto.incidents()[0][""CustomFields""][""externalid""]sentinel_close_reason=demisto.incidents()[0][""CustomFields""].get(""sentinelclosereason"", None)sentinel_classification_comment=demisto.incidents()[0][""CustomFields""].get(""sentinelclassificationcomment"", None)demisto.executeCommand('setIncident', {'closeNotes': sentinel_classification_comment})demisto.executeCommand('setIncident', {'closeReason': ""Resolved""})----END----",0,03-17-2022,10:31 AM
261,474096,LancePettay,"Ok, I have tried various things to get this to work. I was able to reproduce what you were seeing, with it working on a single incident but not multiple. Unfortunately that may be a bug. I noticed in the war room of each respective incident, there is an entry saying the close notes were modified, but it isn't actually modified. You are welcome to report it via support.paloaltonetworks.comAs far as other options, I also tried this in a post-processing script, but fields are kind of locked into a limbo state during post-processing and can't really be changed. If you attempt to set them, they just return to what they were prior to being set.I unfortunately am not able to come up with any way to get this working as far as your current flow goes.",1,03-17-2022,10:51 AM
262,474096,JoshBoyd,"Thanks again, I'll open a ticket with support.",0,03-17-2022,11:05 AM
263,474096,LancePettay,"I received the below response from support and they recommended I re-reach out to the Live community.===Response==I synced with the team and this appears to be working as expected as the bulk close flow will post the closeNotes and closeReason to the values set during the incident closure. It performs a get args in the background and then once the script has completed, since the args are originally empty, once the incident is closed, it's wiped from context which is why it's not being populated.They have requested you open a feature request viahttp://xsoar.ideas.aha.io/ if you would like this flow altered.Some potential workarounds would be:1. Set the close reason and notes before closing multiple incidents - manually or via playbook.2. Add close reason and notes to your close layout and use a field change script on sentinelclosereason & sentinel_classification_comment to populate the close reason and notes on change.If you need assistance with these workarounds, I would suggest reaching out to the team via the live community as this then treads into implementation.======Option 2 doesn't make sense to me since I already have the field trigger script executing, though I don't have close reason and close notes on the form. Not sure if anyone could expand on that -Option 1: How would I action the suggestion into a playbook.i think of a playbook as executing once the incident is created. Can I call a button to execute a separateplay book for closing?Thanks again",1,03-17-2022,12:30 PM
264,474096,JoshBoyd,"The results of ScriptB are returned from the demisto.executeCommand function. To capture the output of ScriptB, ScriptA should look something like this:res = demisto.executeCommand(""ScriptB"", {})[0][""Contents""]return_results(res)",1,03-17-2022,12:43 PM
265,474096,jboyd98,"Thanks@tyler_baileyThat fixed the above.I used the above as a test, but really what I'm trying do is understand why the context data is not available in script B.ScriptA which is:return_results(demisto.incidents()[0])res = demisto.executeCommand('ScriptB', {})[0][""Contents""]return_results(res)ScriptB which is:return_results(""ScriptB Called"")return_results(demisto.incidents()[0])Everything is expected in War Room except my ScriptB ""demisto.incidents()[0]"" does not seem to be called or it's empty so it doesn't return anything to war room? ScriptA incident data is returned in the war room as a json as expected.When ScriptB tries to reference the incident data its like it can't find it??Does that question make sense?",0,03-24-2022,10:16 AM
266,474781,tyler_bailey,"Hi@jboyd98,I would just recommend removing the [0]['Contents'] on the end of executeCommand, and do return_results(str(res)) so that you can get an understanding of the entire entry structure. Since you have multiple return_results() in ScriptB, this means the second output would actually be under res[1][""Contents""].I hope this helps!-Lance",1,03-21-2022,01:49 PM
267,474781,jboyd98,"Hi@Manikandan_sam, is this the first time you are configuring the XSOAR integration with Splunk? If yes, you may want to change the First fetch timestamp to 2 or 3 days, to capture incidents that were created before. If not, please check if certain incidents were missed while others were created, and open a support case with screenshots and logs.",0,03-21-2022,02:15 PM
268,474781,LancePettay,"yes this is my first time integrating splunkthat sample log file is a data day (March 3) for testing so I loaded it into splunk add data and created a custom indexexample:that the log file data is only from March 3rd and how to use timestamp lookup and I already use that custom query in splunk configwhen i search xsoar cli !splunk-search query=""index=notes"" it shows index data and i can also parse the specific url and ip field in the playbookSo is this the proper method to use Splunk custom index to get all the data into xsoar?",1,03-21-2022,04:58 PM
269,472518,amore,Hello!1. Please also try encapsulating the index name as per default example when creating new instance. eg.search `notes` | expandtoken2. Reset timestamp - unless you know you have new data coming in or within the look back windows (15mins by default)3. Double check you you have latest content pack installed4. double check time on your new system (sync with NTP)5. You can debug a test fetch with:!<instance_name>-fetch debug-mode=true  reference - xsoar.pan.dev/docs/reference/articles/troubleshooting-guidePlease let us know how you go!,0,03-14-2022,02:45 PM
270,472518,Manikandan_sam,thank for the replaymy custom data is from 3rd March and time also different but i uploaded it today and 2 days ago my raw file is showing in cli command but when i changed settings again it shows empty indexhow to change my timestamp and get data,0,03-15-2022,12:51 AM
271,472518,jgomes,"The error indicates permission related to the Index or macro..I do see you have the 'first fetch' look back to 3 months which should find data otherwise. If this was the first fetch.I suggest testing the query in Splunk API directly and double check your API permissions.https://docs.splunk.com/Documentation/Splunk/8.2.5/RESTTUT/RESTsearchesDo you get same error on your original search query without using expand token?Perhaps try that again with larger window.. like 1 month+ to cover time the data datetime rangeIf XSOAR has fetched once already (the radio button for fetch in integration) then it will fetch the look back window once, then every minute (for the last minute) by default. Here you should delete instance and create a new one, so the first fetch goes back one month as configured. First use test to ensure no permission issues. Hope this helps.",0,03-15-2022,08:07 AM
272,472518,Manikandan_sam,"HiHi@Miroslaw_IwanowskiI am not sure why you would have been ignored, but if you sign up to download the Cortex XSOAR then you will get the trial version (without the limitations on reporting and commands in one day) after the 60 (I think it is) period it will revert to the community edition, this has a limit 166 commands in one day and the reporting is severely limited, other than that it is pretty much fully functional, threat feeds are limited to 100 objects though so they are more for practise and eval than anything else.Hope this helps",0,03-18-2022,05:08 AM
273,472518,jgomes,"Hey@DigitalAvenger,It's awesome to know your experience in the data analytics space. Here are my two cents on your questions:",0,03-21-2022,07:58 AM
274,474238,aurence64,"Hi@jboyd98, is this still an issue for you? Please open a support case with logs and screenshots.",0,03-18-2022,09:29 AM
275,459061,amore,"Hi,Thanks for posting to our Live Community Discussion Board. Would you be able to share the SSO Administrator role configuration in order to review?Thanks,Silviu",1,03-14-2022,03:12 PM
276,470268,amore,You can look at sample incident generators there are 2 options in marketplacehttps://xsoar.pan.dev/docs/reference/integrations/json-sample-incident-generatorhttps://xsoar.pan.dev/marketplace/details/sampleSiem,0,03-14-2022,02:48 PM
277,470984,SilviuMihailDasaria-labelcalu,"Hi,At the moment we don't have an import function / library to be imported in your scripts but as@sramesh-7mentioned in the Marketplace we have several integrations which allows you to generate random incidents. In case you're looking for Phishing samples my recommendation is to leverage the Onboarding integration available in the Marketplace. You could clone and make changes on these integrations in order to be adapted to your needs.Let us know if you got any question or concerns.Thanks,Silviu",0,03-10-2022,11:58 PM
278,470603,sramesh-7,"Hi,Thanks or posting in our Live Community Discussions. At the moment we don't support changing the column view in Cortex XSOAR as this is user specific only. Have you tried looking into the Summary View? I'm thinking you could ""enforce"" by creating some top sections with the data that you want to display to the analyst.Let me know if you have any questions or concerns!Thanks,Silviu",0,03-04-2022,10:16 AM
279,470603,SilviuMihailDasaria-labelcalu,Thanks for the quick response.Is that the same for dashboards.Can I not edit the default dashboard?Seems like i can only create a duplicate and edit it.There's not a way to push what dashboards are added to all users correct; they have to go manually add as an individual preference?,0,03-10-2022,11:55 PM
280,472062,SilviuMihailDasaria-labelcalu,"Default dashboard can't be edited however you can define the Default dashboards per role (Settings -> Users and Roles -> Roles -> select role).if you need to create custom dashboards from standard dashboards, you can definitely clone, modify and then share those with specific roles. You could share the link of each dashboard with your team and by clicking on the link that dashboard will be automatically added to their dashboard list (requires XSOAR version 6.2 minimum). However keep in mind custom dashboards will not be shown in the default dashboard list dropdown so the only way is to actually share those with your users.Let me know if you have any other questions or concerns!Thanks,Silviu",0,03-10-2022,10:04 AM
281,472062,jboyd98,"Awesome thanks for the detail.Just confirmingHave you tried looking into the Summary View? I'm thinking you could ""enforce"" by creating some top sections with the data that you want to display to the analyst.The way I would add top sections to the summary view would be to add tabs to the layout correct?",0,03-10-2022,10:14 AM
282,472062,SilviuMihailDasaria-labelcalu,In the first layout tab you're displaying you could add some top sections displaying the fields you would like to display to your analyst.,0,03-10-2022,10:44 AM
283,472062,jboyd98,"Hi,Thanks for posting into our Live Community Discussion board. You won't need a RESTAPI for changing the owner of an incident but make sure to execute the below command:!setIncident owner=""<owner_goes_in_here"" id=""<incident_id""Please let me know if that works for you.Thanks,Silviu",0,03-10-2022,10:48 AM
284,472062,SilviuMihailDasaria-labelcalu,"Silviu thanks, for some reason i totally forgot this command.Thanks",0,03-10-2022,10:51 AM
285,471956,SilviuMihailDasaria-labelcalu,"Hi Sucuncuoglu,Thanks for posting in our Live Community Discussion board. Assuming you're referring to the QRadar v3 integration. I've made a quick review and in theget_incidents_long_running_execution function I can see we're adding the range properly to the API call:See line 1561 and 1562 :range_max = offenses_per_fetch - 1 if offenses_per_fetch else MAXIMUM_OFFENSES_PER_FETCH - 1range_ = f'items=0-{range_max}'So I suppose it might be something else that cause this delay. In order to detect what might be gong wrong, would you mind opening a Customer Support Ticket in order to identify what might be the issue?Thanks,SilviuThanks,Silviu",1,03-10-2022,05:06 AM
286,471956,virzi_daman,"Hi Silviu,Thank you for the quick reply.I opened the case numbered 02119736. The problem couldn't be solved there and they recommended this place.You guessed it right, we use the Qradar V3 integration.There is no range in the query to Qradar. It could be caused by line 405.additional_headers = {'Range': range_} if not offense_id else NoneBecause the offense_id value is not entered in line 1565. In this case, range becomes None and we query for the whole range.raw_offenses = client.offenses_list(range_, filter_=filter_fetch_query, sort=ASCENDING_ID_ORDER)",0,03-10-2022,05:10 AM
287,471208,SilviuMihailDasaria-labelcalu,"Hi Silviu,I want to correct my mistake, why is the range value None when we do not enter the offense id?",0,03-08-2022,01:06 AM
288,471208,Sucuncuoglu,"Hi Silviu,We found the cause of the problem. The time is getting longer because sorting is used in the query.As a result of your guidance, we reached the solution.Thank you for your support.",0,03-08-2022,02:41 AM
289,471208,Sucuncuoglu,"Hi,Can you try using ${incident.destinationip} under Get in the condition. And see if it works?",0,03-08-2022,03:11 AM
290,471208,Sucuncuoglu,That does not change the result.,0,03-08-2022,08:20 AM
291,470200,akoppad,"Can you please try changing the False value to True and switching the condition to ""no"". And try with a private Ip as input to check if it selects the ""no"" branch.",0,03-03-2022,08:27 AM
292,470200,KevinThys,Tried but same result.,0,03-03-2022,08:41 AM
293,470200,akoppad,"Hi@KevinThys,I get the same issue when trying to use this script as a condition operator. Could you open a support case for the issue so we can get it fixed?As a workaround, you can detach or duplicate theIsRFC1918Address automation and add the tagConditionto it. Then, if you choose ""Choose automation"" as the conditional type, you should seeIsRFC1918Address in the dropdown. You can then create two branches,TrueandFalse, off the conditional task. Please let us know if that works for you.",0,03-03-2022,10:21 AM
294,470200,KevinThys,"Hi@jboyd98,To set Docker containers to run as non-root internal users, please set the server configuration docker.run.internal.asuser totrue, as per this document:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-5/cortex-xsoar-admin/docker/docker-hardening.... After setting that server config and running/reset_containers, all docker hardening checks should pass.You are seeing the user demistoin yourps -ef | grep demisto output because thedemistouser kicks off the docker process. If you havedocker.run.internal.asuserset totrue, you will see the arg--user <UID> is passed to the docker process. Otherwise, the--userarg does not get passed, so the docker container runs as root, the default behavior.XSOAR launches a docker container by running a python loop script_script_docker_python_loop.py, which you will see at the end of the line in thepsoutput. The user that_script_docker_python_loop.pyruns as will vary depending on thedocker.run.internal.asuser server config value. You can verify this by running:ps -ef | grep _script_docker_python_loop.pyThe loop script is explained in more detail here:https://xsoar.pan.dev/docs/integrations/docker#advanced-server---container-communicationHope that helps!",0,03-03-2022,11:47 AM
295,470200,asawyer,Thanks will review -,0,03-03-2022,04:25 PM
296,470261,asawyer,"Hi Jboyd,This forum is best for implementation questions, not so much for server crashes, bugs, or other unexpected behaviors.I would recommend that you open a support ticket a support.paloaltonetworks.com. Please attach your log bundle set to Debug level from the Settings>About>Troubleshooting page. There you will be met with the proper team to investigate this, along with an SLA for a response to your issue.Thanks,Lance",1,03-03-2022,02:55 PM
297,470261,jboyd98,"Thanks, I opened a support ticket as suggested.Though, I referenced the error, I really just want to better understand how max open files / file descriptors setting is inherited by xsoar containers. More of an education question.",0,03-03-2022,03:14 PM
298,470280,LancePettay,,1,03-03-2022,12:26 PM
299,470280,jboyd98,"Hi,Thanks for posting in our Live Community board. You can manage these notifications directly from the User Profile section -> Notifications tab where you can configure which notifications to receive and through which channels. Notifications are presented by categories. By default, all of the categories and channels are selected.",0,03-03-2022,12:30 PM
300,469920,amore,It worked thank you for the solution,1,03-02-2022,02:12 PM
301,469761,SilviuMihailDasaria-labelcalu,Attaching the error details,1,03-02-2022,04:17 AM
302,469761,vidurasupun,can some one help us with the working python script .,0,03-02-2022,10:52 AM
303,469043,Securado,"Hi Securado,Thanks for posting in our Live Community Discussions. In order to get assistance with your issue kindly ask to open a support ticket with our Customer Support team in order to review and fix your issue.Thanks,Silviu",0,02-27-2022,08:29 AM
304,469043,Securado,"Disregard, my re-open trigger script was set to yes for run after modification. That seems to have fixed it.",0,02-27-2022,08:30 AM
305,469043,SilviuMihailDasaria-labelcalu,Hi!Just checking where you tried to pull the EntryID from? Did you use ${File.EntryID} as the input to your task? Here's an example:For more granularity and to not fetch all of the files in the incident you can add a filter into the entry like this:That fetches the EntryID for a File with txt in the Name.I hope this helps!,0,03-02-2022,12:44 AM
306,469584,jboyd98,"Hi Doug!I solved it with a Python script. I found the commanddemisto.getFilePath(entryID), which returns a dictionary containing the file name and path. The path to the file is incident#_EntryID. So if the incident number is 12345 and the entry id is 14@23456then the path is 12345_14@23456.",0,03-01-2022,12:18 PM
307,430803,DougCouch,"Hi Thanks,Nice. and I am trying add this ""ID"" of the context data in to playbook task . but i m not able to find this. will you able to help here to identifying the same ?",0,09-01-2021,01:42 PM
308,430803,TexasHoosier,how are you trying to trigger the webhook?please note that only POST requests are allowed,0,09-01-2021,01:48 PM
309,430803,Abu_Satorp,"We are sending XML file via HTTPS from SIEM. The issue is all test from SIEM and SOAR is showing successful , But we are unable to get any incident on the SOAR consoleIs there any other way to test the integration ?",1,02-28-2022,09:11 PM
310,469007,keren,see the integration documentation for sample CURL queries you can use to trigger the webhook,0,02-27-2022,04:40 AM
311,469007,Securado,,0,02-27-2022,04:49 AM
312,469007,keren,"Hi,Please submit a support case with the logs attached. the discussion board is open to everyone and is not the right place for troubleshooting as logs and other sensitive data shouldn't be shared here,thanks.",0,02-27-2022,04:56 AM
313,469007,Securado,"Hi Michael,Thanks for posting into our Live Community Discussions!Unfortunately there is no way you can set images via setIncident command as this is used entirely for altering values on the system and custom fields! Since you have multiple images generated via the Rasterize integration these entries are available for your to consume in the warRoom! My recommendation will be to start tagging those entries and leverage layout sections with warRoom filters to display these images in the ""WarRoom entries"" section similar to the Phishing layout where we display the screenshots of the URL. The size of the image cannot be configured but the end user can click on the image an enlarge if need it.Let me know if this make sense!",0,02-27-2022,04:56 AM
314,467929,gfilippov,"Hi@michaelsysec242,The core issue here is that you cannot create a dynamic number of widgets on the dashboard. You can however, have a single widget that displays all images that you mention.You can also have a pre-defined number of widgets that display a pre-defined number of images from the warm room.As@SilviuMihailDascalusuggested, marking warroom entries may be the simplest and most efficient way here.For example; You would create a widget for each ""type"" of image you wanted to produce. Such as a GPS coords widget, URL rasterize widget, etc.. For each of those widgets you would then display warroom entries with their relevant tags (such as ""gps"" and ""url-rasterize"", as two examples). Then simply ensure that when theses commands are executed as part of a playbook, they are tagged appropriately. You can also manually tag the entries too.You still can't dynamically create widgets, but can group similar images together in pre-defined widget areas.I hope this helps somewhat.RegardsAdam",0,02-27-2022,03:02 AM
315,467850,SilviuMihailDasaria-labelcalu,"As an aside, you may not be able to set images by using setIncident, however, you can set the contents of a custom field that is of type ""HTML"" with the embedded base64 image you desire.For example, you have a field named ""HTML Output"" that is of type ""HMTL"";setIncident htmloutput=""""""<img src=""data&colon;image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEYAAAAUCAAAAAAVAxSkAAABrUlEQVQ4y+3TPUvDQBgH8OdDOGa+oUMgk2MpdHIIgpSUiqC0OKirgxYX8QVFRQRpBRF8KShqLbgIYkUEteCgFVuqUEVxEIkvJFhae3m8S2KbSkcFBw9yHP88+eXucgH8kQZ/jSm4VDaIy9RKCpKac9NKgU4uEJNwhHhK3qvPBVO8rxRWmFXPF+NSM1KVMbwriAMwhDgVcrxeMZm85GR0PhvGJAAmyozJsbsxgNEir4iEjIK0SYqGd8sOR3rJAGN2BCEkOxhxMhpd8Mk0CXtZacxi1hr20mI/rzgnxayoidevcGuHXTC/q6QuYSMt1jC+gBIiMg12v2vb5NlklChiWnhmFZpwvxDGzuUzV8kOg+N8UUvNBp64vy9q3UN7gDXhwWLY2nMC3zRDibfsY7wjEkY79CdMZhrxSqqzxf4ZRPXwzWJirMicDa5KwiPeARygHXKNMQHEy3rMopDR20XNZGbJzUtrwDC/KshlLDWyqdmhxZzCsdYmf2fWZPoxCEDyfIvdtNQH0PRkH6Q51g8rFO3Qzxh2LbItcDCOpmuOsV7ntNaERe3v/lP/zO8yn4N+yNPrekmPAAAAAElFTkSuQmCC""/>""""""RegardsAdam",0,02-23-2022,08:47 AM
316,467850,ABurt,,1,02-24-2022,02:07 AM
317,467850,ABurt,"Thanks, I see what I did wrong there...Though, oddly this returns the same thing twice:entities = demisto.executeCommand(""azure-sentinel-list-incident-entities"", {""incident_id"":external_id})entitiesRaw = demisto.executeCommand(""azure-sentinel-list-incident-entities"", {""incident_id"":external_id,""raw-response"":""true""})return_results(entities)return_results(entitiesRaw)I was expecting the raw json output similar to the following command, but return_results seems to be formatting it in human readable format; does that seem right?This gives me what I need, but I need to put it in python code:!azure-sentinel-list-incident-entities incident_id=xxxx-xxxx-xxxx raw-response=true",1,02-24-2022,02:14 AM
318,467887,jgomes,"Try this and see if it does what you are looking for.entitiesRaw = demisto.executeCommand(""azure-sentinel-list-incident-entities"", {""incident_id"":external_id})[0][""Contents""]",2,02-23-2022,10:25 AM
319,467887,JoshBoyd,"Hi,Thanks for your post in our Live Community platform! I've reviewed the code and it seems like this integration miss completely the say_hello() function hence it's failing. Please raise a support ticket with our CSP Team in order for this to be addressed properly. Would you mind checking if other commands are working properly?Thanks!",0,02-23-2022,10:49 AM
320,467887,tyler_bailey,"Hi,Thanks for advice I did not try other commands but other commands working.I will inform CSP about test on Twitter Api.Thank!",1,02-23-2022,10:53 AM
321,464766,SilviuMihailDasaria-labelcalu,"Hi@yosefnega,Please can you provide:RegardsAdam",1,02-17-2022,08:31 AM
322,464766,seckinever,"1. we prepare a report template and it was generate with time schedule and sent to us with our email addrss, but also we can click the dowenload button to generate.. but its empty after some time(like after 4 month2. they are many report , for example , daily incident, status of incident, by catagories , by playbook , top 10 incidents etc...3. version --- 6.24. no we just use the gui once we create the report template . it will send through email and also if we want we download it anytime. Thanks",0,02-23-2022,06:29 AM
323,466131,ABurt,"Hi,Thanks for posting in our Live Community. Not sure if I fully understand your issue but with regards to your first statement you will need to configure the date range as most probably the report is configured to display data in a certain date range. This date range can be applied to all the widgets or some widgets if you prefer that only some of the widgets inside the reports will show data for a different date range. For more informations about custom reports please find the documentation available athttps://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-5/cortex-xsoar-admin/reports/create-a-report...Let us know if you have any questions or concerns!",2,02-16-2022,04:35 AM
324,466131,yosefnega,"Hi,Further instructions were sent over the support case you've opened, since this discussion board is public- let's continue the discussion over the private support case, on which logs can be shared,thanks.",0,02-23-2022,03:04 AM
325,466131,SilviuMihailDasaria-labelcalu,"Hi@jboyd98,I was unable to reproduce this issue using the latest version of the Azure Sentinel content pack (1.3.1). Please make sure you have updated the pack to the latest version.",0,02-23-2022,03:12 AM
326,465607,gfilippov,"Hi,Please make sure you are running the latest pack of this integration,if you problem remains please submit a support case with the logs attached,thanks.",0,02-19-2022,12:21 PM
327,465607,asawyer,"Hi,Actually let me correct myself;since it is a community contributed integration- the development of it is on behalf of the contributor and not XSOAR R&D,You can click on the ""Supported by"" button in the pack and contact the developer,Pointing him to this page will be great,thanks.",0,02-22-2022,05:05 PM
328,465135,gfilippov,"Hi,Yes, it is possible with a use of an automation created exactly for it, please review ""CreateEmailHtmlBody"",thanks",1,02-19-2022,12:39 PM
329,465135,gfilippov,"Hi,thanks! Exactly what we need.Take care.",0,02-21-2022,10:12 AM
330,465482,gfilippov,"Hi,Unless you have a special reason to do it form the playbook then to set it in the integration instance setting would be proffered:1. You'll save resources by not executingunnecessary commands in the playbook2. You'll be able to map those Qradar custom fields using the Classification & Mapping XSOAR feature, which will also allow the optimal usage of pre-processing rules and more.In this care you I think that it all depends on the amount of custom fields, and based on that you'll know which approach is better for you.Please contact IBM regarding technical questions for Qradar's AQL, examples can be found here:https://www.ibm.com/docs/en/qsip/7.4?topic=aql-ariel-query-languagethanks.",1,02-19-2022,11:59 AM
331,465482,araka,"Hi, What aresuppressedincidents?",0,02-21-2022,04:56 AM
332,465373,gfilippov,"Are you referring to ""restricted"" incidents? In a recent update (I believe 6.2) the option for the admin account to view all incidents that are also marked as ""restricted"" was removed. From my understanding, if the incident is marked as ""restricted"" and the admin account is not an explicit team member of the incident, then the search will not return the restricted incidents.You could use something such asTeam Management Packto add the admin account to each incident that is restricted.",0,02-19-2022,12:37 PM
333,462263,gfilippov,,0,02-03-2022,08:49 AM
334,462263,ABurt,"Thanks for your response. I will take a look but I think it's more about the access control. I am looking for filtering incidents. For example, I can filter the closed incidents by status:Closed.",0,02-04-2022,02:09 AM
335,462263,tmnr0428,Please review:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-5/cortex-xsoar-admin/cortex-xsoar-overview/h...,0,02-04-2022,09:43 AM
336,462263,tmnr0428,"Hi,When querying incidents by the total duration of the timer you should use a number of the total seconds, in this case57,600 seconds,""ago"" would make sense for for a field that holds a specific date, like incidents creation date, but a duration cannot be X time ago.You can try searching by the timer'sdueDate field,more for example please review:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-5/cortex-xsoar-admin/work-with-slas/search-i...thanks.",0,02-04-2022,10:02 AM
337,462263,gfilippov,"Hi,Yes it is possible, the EWS V2 integration supports it:https://xsoar.pan.dev/docs/reference/integrations/ews-v2",0,02-19-2022,12:25 PM
338,466971,gfilippov,"Hi, Please visithttps://support.paloaltonetworks.com",0,02-19-2022,12:11 PM
339,464895,gfilippov,"Sorry, i don't have Sentinel integration up to test, but typically what is returned fromdemisto.executeCommand is a list and then you look into the ""Contents"" dictionary key inside the first value of that list to see what is returned. I would try:entities = demisto.executeCommand(""azure-sentinel-list-incident-entities"", {""incident_id"":external_id})[0]['Contents']Also might want to add some print statements just for testing",0,02-19-2022,11:54 AM
340,464497,gfilippov,"Good morning, is'http://www.w3.org/1999/xhtml' an indicator inside the PDF?",0,02-19-2022,11:51 AM
341,465060,jwilkes,Hi@jwilkesIt is not present in the file. There are 2 other domains not related to this and a couple of hashes and CVE.,1,02-11-2022,08:05 AM
342,464408,jwilkes,Do other PDFs with the same PDF version work withReadPDFFileV2?,0,02-09-2022,04:40 AM
343,464408,pottapitot,"Hi @jwilkesI tried another file, the PDF present in the below site as testing. That also failed with the same error.https://www.ncsc.gov.uk/news/indicators-of-compromise-for-malware-used-by-apt28Since I am experimenting I am using the playbook ""Phishing - Generic v3"". The ReadPDFFilev2 is present in it and it stops there with the above error.",0,02-09-2022,04:52 AM
344,464408,jwilkes,"@pottapitot,I tried that same file for my XSOAR instance (6.2) and it failed as well. Can you please create a support ticket to investigate this further? I know that ReadPDFFileV2uses the linux utility""pdftohtml"" and maybe there are some limitations.I know we have found limitations before but they were with PDF encryption:https://xsoar.ideas.aha.io/ideas/FR-I-1397",0,02-09-2022,04:54 AM
345,464408,pottapitot,@jwilkesWow! I am impressed by the speed of the resolution. I was looking through the automation script after my previous post when I noticed there was an update for the ReadPDFFileV2 script. I updated the automation and tried it again. Now it works perfectly!I am not sure how you did it but once again thanks alot!😃,0,02-09-2022,05:56 AM
346,464408,jwilkes,"Yes, this looks related. Glad to help!",0,02-09-2022,06:39 AM
347,464408,pottapitot,,0,02-09-2022,06:52 AM
348,464408,jwilkes,"OH thanks, didn't know that, for the other side, if i want to include an Image in the HTML can I stored in some XSOAR internal folder and then call with a relative path, or shall I upload it to a public web and load the image based on this public url?",0,02-09-2022,06:59 AM
349,463382,amore,,1,02-04-2022,09:37 AM
350,463382,sgonzalez,sgonzalez.You can also add images to HTML via their base64. I have worked with a customer that uses this and it works well though he HTML can get pretty long. Here is a resource for the HTML base64 image rendering:https://stackoverflow.com/questions/8499633/how-to-display-base64-images-in-html,0,02-07-2022,03:35 AM
351,463382,amore,"Oh that is great, i didn't not though about that. I will try and see if can make it work!",1,02-07-2022,09:07 AM
352,463382,jwilkes,"I have made it, but the layout seems to not being rendering it:",2,02-07-2022,09:22 AM
353,463382,sgonzalez,"Hello,I would like to create an HTML template inside XSOAR (using a list) and adding a html image to it. I would like to know, if there is any local resource in where i can save the image and then import it in XSOAR, or it has to be done in a public url.For the other side, I would also like to know if it is possible to render an HTML inside a layout.Kind regards,Sergio",0,02-08-2022,12:58 AM
354,463382,sgonzalez,Is there an error you're given? The way you're doing it works for me on a single select field.,0,02-08-2022,01:30 AM
355,463382,Luis7109,"Hi Boyd,When the incident is re-opened the Close Reason and Close Notes retain their values. Depending on how the incident is then closed again, may wipe the values. If you are using the Close Form, the Close Reason and Close Notes are requested. If they are removed from the form the values are set to None and these are saved when the incident is then re-closed.The best method to set these values (if they are not presented during a close form) is to use a script that has the tag ""post-processing"". This script (when assigned to your incident type) can then copy out the Close Reason and Close Notes from other fields and set as required.",2,02-08-2022,03:03 AM
356,464014,MBeauchamp2,"Thanks Burt, working on this this morning; appreciate the response.",0,02-07-2022,03:04 PM
357,462651,ABurt,"Hi@ABurt,I created the following post processing script:------closeReason = demisto.incidents()[0][""closeReason""]if closeReason:  return_results(closeReason)  return_results(""Close Reason is already set and will be re-set during this post processing"")  demisto.executeCommand('setIncident', {'closeReason': closeReason})-----I can see if i run the script in war room while the tickets open and ""Close Reason"" is previously set, it returns the value and also returns a message sharing that it's already set. It looks like the script itself is a success. However, when I close the ticket, the end result is the ""Close Reason"" is blanked out again.Question 1. Will post processing log out to war room; I was hoping i could see my return_results to confirm the steps,but I just see a line that shows post-processing scripts are running.Question 2. How can I identify what might be happening after the ""Close Incident"" is clicked on the Close Form? I looked at my fields/buttons and sorted by the column to show triggers; nothing seems to stand out. For the incident type there is no post processing, other than what I just added.Any additional insight is appreciated, thanks again",1,02-02-2022,01:21 AM
358,462651,jboyd98,"Hello again,By far the shortest path to a solution would be to use the ""Azure Closure Reason"" and ""Classification Comment"" in your reporting and not rely on the ""Close Notes"" or ""Close Reason"" fields at all. If you really have to use them, please read on...The problem here, it seems, is that the incident (when closed) will have already accepted the values for Close Reason and Close Notes regardless of what is in the post-processing script. i.e. They cannot be set by the post-processing script. All other fields seem to be able to be set by the script. I am unsure whether this is a bug or by design.The workaround (although a little long) is to not let the incident be closed by using the Actions -> Close Incident button but by providing your own button that closes the incident. So as a step by step (as an example):1). Set the incident type to have a post processing script and use something similar to the below:2). Edit the layout of the incident and under the ""Close"" form settings, remove all fields and sections (this prevents the user manually adding Close Notes and Close Reason that do not match up with the Azure Closure Reason and Classification Comment)3). Add a new tab called ""Case Closure"" in the incident layout.4). Add a section and place a the ""Azure Closure Reason"" and ""Classification Comment"" fields. Ensure the tab has the ""show empty fields"" set too.5). Set the script of the button to be something similar to:6). The script will then close the incident if the Azure Closure Reason and Classification Comment have already been populated. It will copy these values into the Close Reason and Close Notes of the incident during closure.7). Finally, assign a ""field-change-triggered"" script to both the ""Azure Closure Reason"" and ""Classification Comment"" fields that has something like the following:This sets the Close Reason and Close Notes based on those fields.In the above, this is what happens when a user attempt to click the Actions->Close Incident:They then have to populate the fields before using the button:Once they are populated, and the button is clicked, it will copy the values into the Close information.",0,02-02-2022,07:48 AM
359,462651,jboyd98,"Thanks again@ABurt, exploring this as an option. Will circle back and let you know the outcome. Appreciate the help.",0,02-02-2022,08:33 AM
360,462651,ABurt,"Hi,Please create a support case with the logs attached,thanks.",1,02-03-2022,04:08 AM
361,462651,jboyd98,"HelloFWPalolearner, you are correct that XSOAR Threat Intel Management (TIM) should be your path forward. We have migrated the use cases and integrations which existed in MineMeld to XSOAR TIM (including the FireWall integrations & others).",0,02-03-2022,02:30 PM
362,462091,gfilippov,"Hello@ryclough Thanks for your replyCan this TIm be purchased separately . I mean customer does not have requirement for a fullfledged XSOAR , but does XSOAR TIM will be too much for them as the requirement is only to have EDL ?",1,02-03-2022,08:22 AM
363,448640,yclough,"@FWPalolearner- There are a few third party solutions out there too, as the XSOAR product is limit to a couple of feeds. You can use an Azure function app to have self-hosted solution, and there is also new third-party product called EDL Manager (comes at small cost).",0,11-23-2021,08:24 AM
364,448640,FWPalolearner,"Araka,Good afternoon! Can you please provide some more information on what URLs are not matching the system URL indicator?Also, what information is most important from the!GetIndicatorDBotScore command?",0,11-23-2021,09:44 AM
365,448640,ML_OG,"Hi Jwilkes,thanks for answering! I appreciate it.Since the update to the URL regex, we get falsely parsed URLs from email html bodies. See this for example:https://email.bfi-stmk.at/t/t-l-cuiduyk-yuuuhkhttk-x/""><img style=""display: block;height: auto;width: 100%;border: 0;"" src=""https://i.vimeocdn.com/filter/overlay?src=http://img.youtube.com/vi/H24Iy56MM6g/0.jpg&src=https://in...This gets parsed as one URL.And about the !GetIndicatorDBotScore command, we use it to get verdicts about certain IOCs in playbooks. In some cases, for example, we use it to check if we already have the verdict of an IOC and then skip the Threat Intel tasks, if it already exists with a malicious reputation. Well, now we would like to use it with the new Indicator Type, that makes use of the working regex, but !GetIndicatorDBotScore will only ingest system level Indicator Types.",0,02-03-2022,02:06 AM
366,460927,jwilkes,"Araka,Thank you for your response. I understand what is going on much better. One other question: when getting the verdict of the IOCs in the playbook, are you looking for individual enrichment reputations or the overall reputation?",0,01-27-2022,12:00 PM
367,460927,araka,"Hi,thanks. We are looking for the overall reputation.",0,01-28-2022,07:07 AM
368,460927,jwilkes,"Araka,I investigated your HTML snippet and see how that isn't working right with the system URL indicator regular expression. Can you please put in a support case for us to investigate that further?In the meantime you probably want to investigate a more immediate fix for this. You have several options but first I wanted to ask: Have you investigated the ""GetIndicatorDBotScoreFromCache"" automation? This is used to pull the overallreputation score of an indicator from the indicator database. This also works with custom indicator types.",0,01-28-2022,08:14 AM
369,460927,araka,"Jwilkes,thanks a lot for investigating. I will do as you say and open a support case.""!GetIndicatoDBotScoreFromCache"" seems to be an option, I tested it. Thanks! We will start to change that in our playbooks.Just out of curiosity, could you tell me what the other options are?",0,01-28-2022,08:19 AM
370,460927,jwilkes,"Araka,I recommend the""!GetIndicatoDBotScoreFromCache"" automation because it is an ""out of the box"" automation and seems to meet your requirement of the overallreputation of an indicator. The other options you can pursue while support is investigating:Hope that helps. Please let me know if you have any other questions.",1,01-28-2022,12:20 PM
371,460927,araka,Thank you very much! This helped me in understanding the problem.Warm regards.,0,01-31-2022,01:20 AM
372,460927,jwilkes,"It appears that your question is around Cortex XDR, however, this discussion board is for Cortex XSOAR, i would suggest to post your question in the dedicated Cortex XDR discussion board (https://live.paloaltonetworks.com/t5/cortex-xdr-discussions/bd-p/Analytics_Discussions)if your question is about Cortex XSOAR, can you please elaborate on what exactly your issue is?",1,01-31-2022,05:04 AM
373,460927,araka,"that error usually indicates issues with the permissions in /var/lib/demisto either in partitionsdata or demistoidx, can you please verify that all the files have demisto:demisto permissions?",0,02-01-2022,12:45 AM
374,461361,OriNahir,Unfortunately all files in /var/lib/demisto have demisto:demisto permission,1,01-27-2022,10:25 AM
375,459732,brecher,have you tried deleting the cert.pem and the cert.key? XSOAR will generate a new self-sign one if there is none present under /usr/local/demisto,0,01-20-2022,03:21 AM
376,459732,arn_stoz,"yes already tried it, but same error and no cert.pem or cert.key generated",0,01-20-2022,03:37 AM
377,459732,brecher,"Hi,You are right, the downloaded tar file should have all the needed docker images,please try to downloaded it again and reload it to the system, if the problem remains open a support case with the log bundle containing the errors attached,thanks.",0,01-20-2022,03:52 AM
378,459732,arn_stoz,"We have recently added an option to download only your needed docker images, to save space and time for downloading unneeded docker images:https://xsoar.pan.dev/docs/reference/articles/download-packs-offline.",0,01-20-2022,04:04 AM
379,458049,gfilippov,"Hi,The key argument of the commandDeleteContext is expecting the context key name of what you want to delete,providing ""File"" will result with all files being deleted, you can use index=0 argument as well to delete only the first file for example,but to achieve what you want to do this command won't be enough.What I find as the best solution so far is to simply reset the File context key only with the files you wish to maintain, overwriting those you don't want;You'll need to run the ""Set"" command, with a key argument of ""File"", for its value argument you will need to use the Filters & Transformers;1. Get = File2. Filter =File.Extension ""Equals"" csvThis way the File context key will be recreated, only with csv files,thanks.",0,01-19-2022,11:03 AM
380,458049,bkatzir,"Hey Laurence,did you find out, how to upgrade?I'm having the same issue.. just found the instructions, but I cnanot find the DownloadLink..https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-0/cortex-xsoar-admin/installation/upgrade-th...",0,01-20-2022,12:23 AM
381,457225,gfilippov,"HiThe update procedure is quite straightforward to be honest the problem seems to be that the link requires a token to get the new script to download, I did originally upgrade by requesting another demo from demisto, problem is that the mechanism to request this has now changed and it is not as easy to get the download link, it is a shame that there does not appear to be an easy way to upgrade the community edition, as it kind of negates the use of having a community edition in the first place.",0,01-19-2022,11:01 AM
382,453391,MSindlinger,You should be able to use the original download link that you used initially to get the latest GA version - the download link always point to the latest published GA versionGive it a try and let us know if that works for you,0,12-29-2021,05:11 AM
383,453391,aurence64,"Hi@OriNahirUnfortunately I have lost the original link, it was a schoolboy error I am afraid, it was embedded in a script on the first instance I built, then I tore it down when the VMware host it was on started to have some issues, I do not seem to be able to locate it again",0,12-29-2021,06:16 AM
384,453391,OriNahir,"No worries, please sign up for Community Edition again, you'll get another download link",0,12-30-2021,09:45 AM
385,453391,aurence64,"I seem to be missing something here, there used to be a page where you could sign up for XSOAR and when you were approved you were emailed a link to download it from, however unless I am going insane I don't seem to be able to get back to this, the only page I can has only a link to an email address on it, is this the correct one ?",0,01-02-2022,08:58 AM
386,453391,OriNahir,"this is the pagehttps://start.paloaltonetworks.com/sign-up-for-community-edition.htmlon the right side, there should be fields to fill to request the Community Editionmaybe try to open it in an incognito browser window",0,01-03-2022,02:42 PM
387,453391,aurence64,"thank you for that, I did the incognito thing and the boxes popped up ! am on my way to updating now.",0,01-05-2022,01:44 PM
388,453391,OriNahir,@laurence64Could you please share with me the way to upgrade from version 6.2.0 to 6.5 as I didnt get from the above,1,01-05-2022,01:48 PM
389,453391,aurence64,Take a look here:https://xsoar.pan.dev/marketplace/details/Forescout,0,01-05-2022,02:03 PM
390,453391,AhmedEhab,"Hi,It is not possible today, there is an open feature request for it:https://xsoar.ideas.aha.io/ideas/FR-I-97If the email workaround works for you but the main issue is the email structure; you can easily change it:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-5/cortex-xsoar-admin/playbooks/playbook-task...Creating a configuration key of ""messages.html.formats.externalFormSubmit"" with the value: ""{{.link}}"" will send only the generated link in the email, without any HTML, logo, title etc,thanks.",0,01-13-2022,05:46 AM
391,457219,OriNahir,"Hi,This is by design,since the indicator type object is created in the master- you cannot edit it in the tenant level, this is true for any object we have like incident fields, incident types, layouts, etc.If you want a different exclusion list for every tenant you could disable the indicator type in the master and re-create the same one manually in each tenant, this way you will be able to edit it differently for each tenant,thanks.",1,01-06-2022,09:32 AM
392,456010,gfilippov,"So just to clarify, this would be more of a static map that could be referred to later? Also, what would be the elements on the map? Are these systems or stages?Unfortunately Canvas is limited to displaying the relationship or connections between incidents and indicators primarily. It's great for demonstrating the spread of an attack through your environment! If you were attempting to put together more of a static map of your environment you could configure some custom indicators for the systems and include them but that might be the extent of the capability.I hope this helps!",1,01-04-2022,05:44 AM
393,455888,gfilippov,"Hey Saul,There is no hard limit to the file size in the war room.Some things to try:",0,01-04-2022,05:37 AM
394,455736,DougCouch,"Forgot to mention this one,4. Make sure that the disk usage on your system is not maxed out.",0,12-29-2021,10:01 AM
395,450797,LancePettay,"Thanks for the reply, the problem was due to an NGINX that is in front of our XSOAR instance.",1,12-02-2021,12:59 PM
396,450797,LancePettay,"Hi@saulvargasCan I just check that this was an issue with the upload file size restrictions in NGINX ? I had a similar problem and that is what solved it for me, just wanted to get clarification that I had not missed anything.",1,12-02-2021,01:00 PM
397,450797,saulvargas,"We didn't changed the NGINX configuration as we are able to access the server directly, the NGINX is the front for other users, I cannot confirm that changing the upload limit works, but that seems to be the cause.",0,12-10-2021,11:26 AM
398,450797,aurence64,Hi@Netwerx– Improved setup instructions for the Cortex Data Lake integration are in the works and can be reviewed here: https://github.com/demisto/content/blob/master/Packs/CortexDataLake/Integrations/CortexDataLake/Cort...The changes will be reflected on the integration's Help page within XSOAR and on its documentation page soon.Let us know if you have further questions about the setup!,1,12-21-2021,07:07 AM
399,450797,saulvargas,"The github documentation also just states ""from the authentication process"".I'm trying to integrate our Cortex Data Lake instance with an on premises, community edition of Cortex XSOAR. Is this not possible or the community edition / on prem to ingest Cortex Data Lake logs?I checked with Palo Alto support on this, and they wouldn't assist as it was an implementation issue, and would require they bill us to get it working.",0,12-27-2021,08:51 AM
400,453426,asawyer,"As far as I know, this should work with the Community Edition. When logged into the HUB, do you have an activated instance of the Cortex XSOAR app? Once you have activated an instance of the Cortex XSOAR app and select it, you will get a screen where you can enter the License ID and Customer Name.",1,12-17-2021,05:05 PM
401,453426,Netwerx,"Ah, just to clarify, you need a paid for cloud / palo alto xsoar instance to be able to get your paid for cortex data lake data into your community edition, on premises cortex xsoar instance?",0,12-20-2021,05:55 AM
402,453426,asawyer,"I am just looking at the hub now, it seems that the activation of the Cortex XSOAR requires the data lake configuration before continuing,@Netwerxhave you tried entering the details there?I have to admit I have not used Data Lake up until now but the community edition of XSOAR only has a few restrictions so I would have thought this would have been permitted.",0,12-20-2021,08:40 PM
403,453426,Netwerx,"If someone came across the same issue, use the automationqradar-offense-update,To figure out the closing _reason_id and closing_reason_name issue the command!qradar-closing-reasons then pick a reason.",0,12-21-2021,05:42 AM
404,453426,aurence64,"If I understand correctly, this means mocking playbook triggers for incident types. If yes, then the answer is no. Playbook triggers for incident types are not a part of the debugger.If the question was meant to be for ""Playbook Triggered"" header to mock inputs and outputs, please reference the answer in -https://live.paloaltonetworks.com/t5/cortex-xsoar-discussions/question-from-quot-a-developer-s-guide...You can set defaults directly in the playbook triggered header.",0,12-21-2021,07:01 AM
405,452833,vidurasupun,"The delete context mentioned on the webinar is only for the debugger. Between 2 consecutive re-runs of the debugger, the context data generated is not persistent. So you do not need to use a DeleteContext task while testing.Having a DeleteContext task in the playbook should not be impacted by this feature. It should continue working as always.",0,12-14-2021,05:33 PM
406,450710,amore,"Yes, you can run a sub-playbook by itself in the playbook debugger.The Playbook Triggered header does not allow overriding inputs to a sub-playbook for testing. You can do that for individual tasks inside that playbook. You can also just set a default value while defining the playbook input itself. This will be overridden by the value passed from the parent during a complete run.",0,12-02-2021,03:05 PM
407,450711,amore,It works the same.The content type of a List does not matter when it is pulled into a playbook task. You would need to use ParseJSON transformer to convert the string obtained from the list into a valid dictionary object.Same with automation scripts.The webinar demos both these capabilities. Please feel free to check out the recording and revise.,0,12-02-2021,03:00 PM
408,450714,amore,"There isn't a command or automation to get all playbooks or incident types in demisto. However, you can use the Demisto REST Api to do an api request for both these items. If you open Developer Tools in your browser to check the https request for Playbooks (say) then you can replicate that request through the demisto-api commands.",0,12-02-2021,02:57 PM
409,450718,amore,"Currently, you cannot read lists directly in your integration code. You can however, use command arguments that could be passed the List data from a playbook task/context data.",0,12-02-2021,02:47 PM
410,450719,amore,"I have exactly the same question, in today's webinar Aneesha said that there's no limit for the number of lists that can be created, but theres a limit in the size of the lists, but I have no answer yet.",0,12-02-2021,02:44 PM
411,450720,amore,"Today I found that the size limit is near 1MB, and with this size there's a message telling that the data is too big to display it's content.",0,12-02-2021,01:46 PM
412,450715,saulvargas,"Hi all,There is no limit on the data size uploaded to lists. After 1MB you won't be able to see the data displayed in the UI, but you can still download it and read/use it in a playbook.Having said that, please monitor the % storage utilization of your demisto db. Uploading large files to Lists could lead to performance issues.Hope this helps,Aneesha",0,12-01-2021,05:58 PM
413,450715,saulvargas,"This could be done in a Playbook, or, study teh code in QRadar and create an automation script ""wrapper"" for the command. In essence, the script would perform the search and return a ScheduledCommand object. This causes it to re-schedule for the next run and when you finally do receive the results (or lack there of) you could optionally change the search criteria and perform the same script again.If you kept the option to achieve this in an automation script, the ScheduledCommand can be used (even with altered arguments) and be kept within your first defined timeout.",0,12-02-2021,09:08 AM
414,450715,amore,"I received an answer from my resident engineer. TheQRadarFullSearch sub-playbook thatI'm calling can be set up with a built-in loop to check for the presence of results. After the playbook finishes (meaning the search has completed) it can be repeated if no results were found, with X number of seconds between runs and up to N number of retries. I've only ever used the 'for-each input' loop criterion...I didn't realize you could make it so much smarter!I continue to be amazed every day at the things XSOAR can do.",0,12-02-2021,01:42 PM
415,449266,ABurt,"Hi@NTripathi1,Please review step 4.3 of the ""Configure Microsoft Azure to Authenticate to Cortex XSOAR"" documentationand check that the Reply URL (Assertion Consumer Service URL) of the Azure application is in the correct format specified in the documentation:Then, in XSOAR, please verify that all the SAML 2.0 integration parameters are set to the correct values as described here.Here is the Microsoft reference for this error.Hope that helps!",1,11-24-2021,10:26 AM
416,449266,Jeff.McGurk,"Hi@Sayit_Karakis,How are you looking to send the e-mail:Depending on your method, there are various ways it can be done. Each will require the use of the ""send-mail"" command and an integration enabled (with an instance configured) that supports the ""send-mail"" command.",2,11-29-2021,06:45 AM
417,448722,asawyer,"Hi Aburt,I have chosen the button solution in the send-mail app and also we created custom html format for our email notification needings. That works great.Thanks,Sayit",0,11-22-2021,05:37 PM
418,442876,ABurt,"Hi@jtorvald,Which integration are you working on? Some integrations allow you to set a max fetch parameter.You can check the API call being made while saving the instance configurations by opening Developer Tools on your browser and checking the Network Tab for request headers and methods.For this use case it should be a PUT request to/settings/integration with the request headers containing {""isFetch"":False}Hope this helps.",0,10-22-2021,06:33 AM
419,442876,Sayit_Karakis,"Hi @amore, thank you so much for the help. I have confirmed that your suggestions are correct. Unfortunately, I'm experiencing 2 more problems when sending the request, I hope you might be able to help me a little more.Problem 1 - When I send the PUT request using the built in http method, if the integration name and/or brand have whitespaces in them, I receive a response with StatusCode:400, detail:""Could not update integration"", and error:""No suitable module for name : <integration instance name> and brand : <integration brand>""Do you know if there is a specific way to encode the arguments in the JSON body so that XSOAR can parse the whitespaces in the PUT request correctly?Problem 2 - When I send the PUT request using an integration name and brand that do NOT contain whitespaces, I receive a response with StatusCode:400, detail:""Could not update integration"", and error:""<integration instance name> already exists (33).""It seems XSOAR will not update the integration instance because it already exists, and I cannot identify any way to signify to XSOAR in the request that I wish to update an already existing instance. Do you know how to manage this?",1,11-16-2021,02:17 AM
420,445810,amore,"Hi@jtorvald, glad to hear the suggestion helped you.Problem 1: Try by replacing the whitespaces with an underscore _Problem 2: Can you share your PUT request body with me? Please remove any api keys and related confidential information from it.",2,11-05-2021,11:23 AM
421,445810,jtorvald,"Hey@jhargrove1,Can you confirm which version of the Slack integration you are using? Is it Slack (deprecated) or Slack v2?",0,11-09-2021,03:42 AM
422,445810,amore,v2 - not the deprecated one.,0,11-09-2021,04:04 PM
423,446180,amore,"Ok awesome. Please verify what you have in the integration instance setting for parameter ""Dedicated Slack channel to receive notifications"" and whether the ""Send notifications about incidents to the dedicated channel"" checkbox is checked.",0,11-08-2021,09:28 AM
424,446180,jhargrove1,"I do not...and that's not an option or what I was asked to do. This is to send notifications from the 'cortex_xsoar' slack app to a list of designated users.My current setup is a single conditional task, with the 'Ask' radio button clicked, using the SlackV2 integration, to send a message to a list of test users. Message body is ""Please choose an option"" and the 'Reply Options' are 'Yes' and 'No'.",0,11-08-2021,09:29 AM
425,446180,amore,"Thanks for clarifying@jhargrove1. I just tested this in my instance and I am receiving private notifications from the cortex_soar app in my configured workspace, for an incident.In your list of testUsers, do you have the usernames/email separated by commas or new lines? If it is new lines, please try with comma separated values. Also verify if the type of that list is Text.",0,11-08-2021,09:34 AM
426,446180,jhargrove1,The current list is just a single user - no whitespace or delimiters.,0,11-08-2021,09:39 AM
427,446180,amore,Are you using an email or a username?,0,11-08-2021,10:10 AM
428,446180,jhargrove1,"A slack username. If I use the integration within the Playground, I can send myself messages from the cortex_xsoar slack app, so the app appears to be configured properly and does work during that test. It's only when running the playbook manually via the playbook editor UI that I encounter this issue where I get no yes/no buttons.",0,11-08-2021,10:11 AM
429,446180,amore,"Got it,I tested with username as well, it works with send-notification but not with Slack Ask. I would recommend using email instead as that worked for me. In the meantime, I will verify whether this is a bug that needs fixing, or a feature request to support usernames in Slack Ask. I'll keep you posted.",0,11-08-2021,10:12 AM
430,446180,jhargrove1,"Hi @LinsongGuo ,In order to get better traction for this, I have moved your query to the Cortex XSOAR area.I would recommend that you visit this area to see your discussion and others on Cortex XSOAR.Cheers !-Kiwi.",0,11-08-2021,10:14 AM
431,446180,amore,"Take a look at the automation script widgets here:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-2/cortex-xsoar-admin/widgets/create-a-custom...As an example for you use case (and assuming you have fields called ""True Positive"" and ""False Positive"" that are boolean (bear in mind this is pseudo code and not tested):",0,11-08-2021,10:27 AM
432,445697,kiwi,"Hi @DanielBenistiPel -Start off by going to settings and searching for the integration. From there, you can configure the integration and show the commands that are available.Also, you may get a faster response on XSOAR questions by posting to the Cortex XSOAR section.",0,11-09-2021,05:06 AM
433,445697,ABurt,Thank you!the reason i'm asking this question is that i want to know the capabilities that i will receive after that i integrate this two products.for example can i close a case on Qradar when i closed a case on Demisto.,1,11-09-2021,07:16 AM
434,330797,dfalcon,"hi,in general, all integration reference documentation is located here:https://xsoar.pan.dev/docs/reference/indexSpecifically, the IBM Qradar:https://xsoar.pan.dev/docs/reference/integrations/q-radarAlso, you can click on the ""Show command"" under the integration name to actually see the commands it is exposing once an instance is set up",0,06-02-2020,09:49 PM
435,330797,DanielBenistiPearia-labell,"HiHow about your integrate with Qradar? so far so good?Because i have problem when i closed incident in demisto and let close offense in Qradar ifthere are rule in the offense that use time to be condition in rule and it close before it cameto cold period, the next offense name will display wrong description.So, Right now i don't close the offense anymore prevent this problem happen again.Thanks,Son",0,06-02-2020,11:15 PM
436,330797,GShriki,"Hi SonCould you please elaborate with regards to the flow here? I didn't understand how does closing the incident on XSOAR affects the name of the new offense on QRadar's side, as XSOAR isn't creating the offenses just ingesting them.",2,06-03-2020,08:01 AM
437,330797,goasutlor,Information on the QRADAR integration with XSOAR is atCortex XSOAR Integration Documentation,0,01-20-2021,07:11 AM
438,330797,dbaumstein,"Hi Thomas,It is correct the platform is geared towards using integration to safely store and handle credentials. Integrations come with other features like integration context to store instance objects and methods like fetch.Yoda Speaks is a good tutorial on creating your first simple integration -https://xsoar.pan.dev/docs/tutorials/tut-integration-uiThat said, if the credentials is not very sensitive you can still leave in automation code. You can use RBAC to restrict access for less privileged users to see automation IDE and code.There is also a automation setting argument tick box called ‘sensitive’. When set, it will popup a password box at time of run for analyst to type in password, and thus not stored in code. This would be for on demand playground CLI or war room.cheers",0,01-20-2021,12:08 PM
439,330797,DUhrlaub,"I was looking at this again myself two weeks ago when using a specific endpoint in MS Graph API.It seems to be set up this way by the core design philosophy of the XSOAR platform:Therefore, there should be no need for an automation to store any credentials because they'd be stored in the integration with the external platform. The call to the external platform would have the credential usage abstracted by the integration with the automation getting the results of the API action.In practice, spinning up a whole integration to make one GET request feels a little silly but if you want to protect your creds there isn't too much choice.",0,11-09-2021,06:44 AM
440,427180,jgomes,"Hi, just checking-in on this older post that you had you question resolved.If any posts have helped you resolve your issue, please kindly accept one of the solution answers.",0,08-25-2021,06:34 AM
441,427180,NeilPalmere,Are you using Cherwell Onprem or Cloud?,0,08-25-2021,01:22 PM
442,427180,jgomes,We use onprem,0,11-08-2021,09:18 AM
443,420706,jgomes,"As per our doc guide - we officially support and tested with the Cloud SaaS Version:https://xsoar.pan.dev/docs/reference/integrations/cherwellI am aware that for on-prem Cherwell, Authentication fails. We came up with a local Integration patch.Apart from that, everything else with the integration appears to work fine.Quick fix is you can clone the integration, and make the following changes:Vendor docs here:https://help.cherwell.com/bundle/cherwell_rest_api_940_help_only/page/oxy_ex-1/content/system_admini...We already have internal GIT issue (32068) as feature enhancement for this.Unfortunately, the customer with this issue didn't raise an AHA request to drive change / improvement to our OOTB content.I recommend doing this herehttps://xsoar.ideas.aha.io/ideas/search?utf8=%E2%9C%93&query=Cherwellso other customers can upvote to support On-Premises Cherwell in our standard supported content.Let us know if this works for you!Cheers,Jason",0,07-20-2021,07:08 AM
444,420706,_buchwalder,"Hello JasonThanks for your quick and proper solution. Sadly it doesn't work on my side.I still get the same error as above.I've modified line 126, but didn't helped. The Check/Test of the new service was:First of all I've entered all the credentials we use to connect to Cherwell.Without ""Fetch incidents"" and did a test: ""Success""Then I've enabled ""Fetch Incidents"" - Test - Error above in the spoiler.If switch back to ""Do not fetch"" I do get a ""Success"" again.Thank youroger",0,07-20-2021,07:18 AM
445,420706,jgomes,"From playground, run fetch and test module in debug mode. This may provide more clarity on what fetch and test failure is doing:ref:https://xsoar.pan.dev/docs/reference/articles/troubleshooting-guideAlso on 6.2 you can select debug mode in instance settings (drop list) which saves the debug log to disk in:/var/log/demisto/integration-instance.logAlso, you may want to check the API directly with POSTMAN or with basic REST Python script.https://help.cherwell.com/bundle/cherwell_rest_api_940_help_only/page/oxy_ex-1/content/system_admini...I also assume your were using Windows auth for SSO. There also appears other options like LDAP, SAML, and 'internal' - depending on your on-premise setup. ie. for getting a token successfully appending?auth_mode=https://help.cherwell.com/bundle/cherwell_rest_api_940_help_only/page/oxy_ex-1/content/system_admini...",0,07-20-2021,02:01 PM
446,420706,_buchwalder,"Hello JgomesHere the output of the debug mode:(I've replaced instance name with <name>)To be precise: I'm able to request Cherwell through API, no problem. Only those fetch incident does not work.thanksroger",0,07-20-2021,11:02 PM
447,420706,jgomes,"Debug appear not very useful in this case. I would imagine this still has to do with being on-premise, and our content tested for Cloud Cherwell. Please raise a support ticket and/or raise AHA request for content enhancement - in order to support on-premises version of Cherwell as well. Best of luck going forward.https://xsoar.ideas.aha.io/ideas/search?utf8=%E2%9C%93&query=Cherwell",0,07-21-2021,06:40 AM
448,420706,_buchwalder,"How did you go with your support ticket?If my posts have helped you resolve your issue, please kindly accept one of the solution answers.",0,07-21-2021,11:24 PM
449,420706,jgomes,"Yes, BYOI is one way.BTW there is an good tutorial here if you like:https://xsoar.pan.dev/docs/tutorials/tut-integration-ui/It does sound like however the integration has what you need to fetch report and update group. So your ‘report parsing’ code could be converted to an automation - and do this in the playbook. Eg fetch report, taking report data from context when you run your script/automation, which create list of ips in context. Then the next playbook task the standard ‘update group’ with $ctx.key[] using existing integration commands.You could also take approach to clone OOTB integration. Modify the code with your function to run/ get api response result and additional api actions all in the customer integration code. Just add to the new command in code and yaml config.Hope that helps!",0,07-23-2021,01:39 PM
450,420706,jgomes,The way the Qualys run map report works I'd still have the same problem with the credentials. I'd have to use custom code to find the latest run of the map scan to get the report number. Not worth the trouble when I already have a working program. I'll check out the tutorial and see if it helps.,0,11-08-2021,09:16 AM
451,443908,jgomes,"How did you go? You could simply clone the integration, duplicate one of the API (Get/Post) functions, and add new command name. This way your simply adding the additional API end-point your looking for (re-using instance credentials).If this has now answered your question, please kindly accept one of the solution answers.",0,10-27-2021,02:45 PM
452,443908,sforslev,"Yes, you can self obtain Community Editionhttps://start.paloaltonetworks.com/sign-up-for-community-edition.htmlIt is fully functionally for 30days, and thereafter some limitations of feeds and daily automations counts imposed.https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-2/cortex-xsoar-admin/cortex-xsoar-overview/c...When you subscribe to a license, you're also eligible for Dev or Training licenses as part of your subscription.Good luck in your evaluation!",0,10-27-2021,02:56 PM
453,443908,jgomes,"Hello Jgomes, Thanks you for your reply.. Lets say i am already using the ""Community Edition"" for more than 30 days and specific restrictions are now imposed.So how should i now subscribe for a license - Dev or Training License is there a specific process or procedure for that ??ThanksArgha",0,11-08-2021,09:14 AM
454,442226,jgomes,"I noticed no other responses to your additional question.XSOAR will continue to run but with the license restrictions noted for community edition. This is normally adequate for Dev and training. During or soon after you evaluation, someone should reach out to you to discuss evaluation and if you require a production license. This is based on the information you filled in when obtaining the community edition.If you are an existing PAN customer, you will have an account team to reach out to - to discuss production license. If your new PAN customer, you can contact sales directlyhttps://www.paloaltonetworks.com/company/contact-salesAs noted, you are are eligible for additional dev/training license matching you production license and seat countIf this has now answered all your questions, please kindly accept one of the solution answers.",1,10-20-2021,07:54 AM
455,442226,ABhattacharya4,"Yes, you can simply delete those incidents.Depending on the integration, you will see a ‘reset time stamp’ in the instance setup page - or you can simply delete and recreate the instance.With some integration instance setup forms you can tailor the lookback time window. Or you can clone integration and modify in code if you want to go back even further for the first fetch window.If you don’t see ‘reset time stamp’ in instance config, some long running integration instances has a command in the integration to reset time stamp (Eg qradar)hope this helps",0,10-20-2021,10:47 PM
456,442226,jgomes,Thanks so much for the quick help! Deleting the incidents and resetting the timestamp in the integration worked perfectly. I really appreciate it.,0,11-08-2021,09:10 AM
457,445735,jgomes,"Hi ArghaXSOAR has integrations with all the major VM scanners such as Tenable, Qualys, Rapid7 etc. Some of the scanners support fetching data as incident, such asTenable.sc. While other scanners can be configured to run as jobsPlease review the documentation for your relevant scanner integration to validate how the integration for your scanner works.Best regardsDavid",3,11-05-2021,06:11 AM
458,445735,jtorvald,"I think you have a transform issue.Look at the following link on YouTube to MOD44'sPCSAE - Palo Alto Networks - Certification- Training- Domain 1Skip ahead to 34:15, I think this will help you. ",0,11-05-2021,07:17 AM
459,443694,dbaumstein,"@Struncethank you for your reply.This video discusses splitting data at classifier level, but I have that already applied in my classifier & mapper as per the above screenshots. No transformations are present within my classifier or mapper.I just created a complete new account with fresh installation and integration with a totally different Splunk instance and the same issue persists.Do you happen to know how data is filled into context and what controls this process? should I dig into automations for pre-processing rules?",2,10-26-2021,11:10 PM
460,437729,Strunce,"Hi@Rawabdeh, the fields you are showing (incident -> labels -> drilldown) are not being mapped. By default, each mapper has a couple of fields mapped. The rest of the fields are copied verbatim into the context data under ""labels"". This setting can be disable (if you wanted to) under the settings of the mapper under Advanced:All data under the labels will be as presented by the source technology. If you would like the data parsed, you would need to alter the Splunk incoming mapper to map that field.Do you know how you would like the data presented? As a table perhaps?RegardsAdam",0,09-30-2021,12:35 PM
461,437729,Rawabdeh,"Thank youfor your contribution@ABurtActually drill down is supposed to look like the first screenshot (I'm using it in my playbooks asDrilldown.[0].Country.[0] >> maps to: Saudi Arabia in the first screenshot)I have tried checking that box you mentioned and indeed, it stopped throwing all JSON details under incident.labels and I was able to use the custom field (mapped with drilldown values) I created. But that means I have to create a field for each value in each alert coming from Splunk and i don't think that's a feasible solution.What's confusing me is that context had drill down parsed just the way it's seen in mapper and I built my playbooks based on this format. Out of nowhere it noticed empty data in sub-playbooks and found out about this issue. No changes were applied on any account",0,10-03-2021,01:59 AM
462,437729,ABurt,"During the classification and mapping this is generally the way data is processed:It looks as if the incoming mapper in screenshot 1 is populating a field named ""drilldown"" in the incident. This would honour the transformation happening at the mapper (i.e. the parseJSON transformer). The second screenshot, when data ends up in the labels, does not undergo any mapper rules such as the parse JSON.In the first screenshot, is the ""drilldown"" appearing in the incident as its own field or is this under the same ""labels"" as in the second screenshot?",0,10-04-2021,12:57 AM
463,437729,Rawabdeh,"@ABurt This is exactly what's happening, context is not picking up this exact JSON parser.Drill down is coming under label as shown in this screenshotHere i say it again, it was all parsed before and i built my playbooks based on these values.",0,10-05-2021,07:13 AM
464,437729,ABurt,Has anything else changed since you built the playbooks. Such as updating XSOAR or any changes to Splunk?,0,10-05-2021,07:28 AM
465,437729,Rawabdeh,That's what I've been trying to find out. the only changes I've made are on playbook inputs and classification. I have no idea how context parsing started behaving like this,0,10-06-2021,04:59 AM
466,437729,ABurt,I have just created 4 fields and mapped their values to drill down details and it's working fine. I know this isn't the best practice to create custom fields for each alert coming from Splunk. This was only for testing purposes.I can confirm that this isn't related to drill down fetching or mapping. issue is narrowed down to context display i believe.,0,10-06-2021,06:05 AM
467,437729,Rawabdeh,Can you share the script you are using? There are 2 invocations of create incident. One using a single incident creation with specific fields and the other using JSON.,0,10-06-2021,07:36 AM
468,437729,Rawabdeh,"Thank you for taking the time to reply.Here is the relevant part (the script is fairly long and involved, and the rest doesn't come into play) :Prior to this, the script gathers all relevant data, either through an input Word document or by prompting the user. The data has been split into two Python dictionaries - one for the base fields and one for the custom_fields.Once this function has the data, it attaches it to the case (oTicket) via setattr. It then creates the case and saves the case number.No other fields have issues, so I think the coding is solid. It is just this one - I get conflicting hints on whether it should be playbookid or playbook_id.I'm at a loss, but need to figure this out because I want to be able to arbitrarily run playbooks when this script runs.",0,10-06-2021,08:06 AM
469,438434,ABurt,"Hi,This live community is for Cortex XSOAR, which doesn't have an agent and doesn't block anything,for Cortex XDR please refer to:https://live.paloaltonetworks.com/t5/cortex-xdr/ct-p/Cortex_XDROr submit a support case,thanks.",0,10-05-2021,01:10 AM
470,438434,twjolson,"Hi,Indeed sounds like an issue, please submit a support ticket with this explanation and logs attached,we will need our R&D involvement, and it shouldn't happen over the live community,thanks.",0,10-05-2021,06:36 AM
471,438696,gfilippov,"Hi,Please submit a support case, this issue will require our R&D involvement, and perhaps a session with you,thanks.",0,10-05-2021,01:51 AM
472,437465,gfilippov,"Hi,I would recommend you to open developer tools in your browser (F12) just before executing the batch close,as a result you will see exactly how the request looks like when you do it manually in the UI,Here is an Example (without the close reason and notes but with the other, mandatory fields):POST/incident/batchCloseall: falsedata: {}filter: {page: 0, size: 50, query: ""-status:closed -category:job"", sort: [{field: ""id"", asc: false}],""period"": {""by"": ""day"",""fromValue"": 7}}ids: [""4"", ""5""]",0,10-05-2021,01:48 AM
473,429461,gfilippov,"Hi,Please submit a support case so we can further investigate it,as an alternative I would recommend you the""Integrations & Incidents Health Check""pack, to take a look at,thanks.",0,10-05-2021,01:41 AM
474,436047,gfilippov,"Hi,Actually there is:extend-context=TheWholeAnswer=putting nothing after the ""="" will take the whole response,thanks.",0,10-04-2021,03:19 PM
475,432061,gfilippov,"Hi,What integration are we talking about? can you provide more context about what you are trying to do?thanks.",0,10-04-2021,03:13 PM
476,430426,gfilippov,"Hi,The Mapping part comes after the incident creation was executed,Please read the following article and and its link to Classification & Mapping:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/5-5/cortex-xsoar-admin/incidents/incident-life...thanks.",0,10-04-2021,03:07 PM
477,425415,gfilippov,"Hi,Please make sure the time range of the search is set correctly (and not just for the last week),If it doesn't solve the issue please submit a support case,I would recommend you to use the ""System Diagnostics and Health Check"" pack which can also give you those incidents, and much more,thanks.",0,10-04-2021,02:55 PM
478,424342,gfilippov,"Hi, Please review our documentation of the integration:https://xsoar.pan.dev/docs/reference/integrations/microsoft-365-defenderAnd if that won't be enough our support team may assist you over a support case,thanks,",0,10-04-2021,02:52 PM
479,424248,gfilippov,,0,10-04-2021,02:48 PM
480,421516,gfilippov,"First make sure the integration works with a test command in the playground, in my testing the test button wasn't always accurate for the RemoteAccess integration (try without a username/password and it'll say success but fail with commands).This was my test command in the playground:The next thing to check is to make sure you named your instance `localhost`. The automation is hardcoded with that value for the instance name. The test example above also uses `localhost` so if that fails, the instance name could be the cause. See:https://github.com/demisto/content/blob/d4a6fdd9e50a35e5218bcce7e40d87c95c7ff6c0/Packs/ServerLogs/Sc...If that's all correct, then check the user you're using for the RemoteAccess instance has read access to the log files in the automations. These are their paths (also hardcoded):/var/log/demisto/server.log/var/log/demisto/docker.logCheck with an `ls -a $PATH` while on the host.",0,10-04-2021,02:43 PM
481,433586,HackDefendr,Boom! That was the ticket. Setting the hostname and instance name to localhost resolved this for me.Thank-you!!,0,09-13-2021,11:30 AM
482,433586,balmer,"Sanaya,To learn more about XSOAR's API endpoints, you can download the Cortex XSOAR API Guide right from XSOAR itself: Settings > Integrations > API Keys > Download Cortex XSOAR API Guide (also see the screenshot below).An alternative method for determining the API endpoint and POST body syntax would be to make the desired request in a browser and use its 'Developer Tools' to view the request (see screenshot below for an example)Please let me know if this answers your question.",1,09-13-2021,08:16 PM
483,433586,HackDefendr,"This answer is insufficient. The poster asked for the API endpoint that can be used to update an incident. That information is not provided anywhere in the reply. Instead, the responder refers the poster to theCortex XSOAR API Guide which, while being quite lengthy, lacks far more helpful information than it provides. For instance, every definition example in that guide (except for numerical and boolean values, which really don't need examples) is completely useless.A better solution reply would identify the endpoint and provide a detailed example of a typical request message body that modifies an incident's required, optional, and custom fields. Bonus points for some explanations on how to avoid common ""bad request"" errors for that endpoint.",0,10-04-2021,12:33 PM
484,420446,atullo,"Use the endpoint ""/incident"" with POST data. There are some details that are worth going through though:To satisfy the above, the easiest method would be:The result should be instant.The reasoning behind the ""version"" match is that changes should be made to latest version of the incident to prevent race-conditions. If you specify a version number that is not the latest (i.e. someone else made a change just before you did) then the call will fail with the error:",0,07-30-2021,02:32 PM
485,420446,Snader,@sanayaPlease let me know if this helps in your situation.,0,09-22-2021,04:32 PM
486,420446,ABurt,"Resolved...Review field ""version"" 🙂",1,09-23-2021,05:11 AM
487,420446,ABurt,Where is the solution? Links do not appear to work.,0,09-24-2021,02:44 AM
488,420655,sanaya,"Hi Marco!This would be similar to ""Freeing up space with Dat Archiving"" as found here:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-2/cortex-xsoar-admin/manage-data/free-up-dis...XSOAR incident data is stored in folders and data files per month. If the customer only wants the most recent (or perhaps the oldest) data available you basically remove the folders you don't want and reindex. It's actually a recommended way to speed up access time and searching.Hope this helps!-Doug",0,07-22-2021,09:10 AM
489,420655,Snader,"Thanks Doug! We'll try following that, but can we say that it is official supported by Palo Alto or not?I mean, is this a workaround or an official procedure.",0,09-22-2021,03:38 PM
490,435446,DougCouch,That's an official procedure. We recommend that clients archive anything over a year's worth of data for best performance.Thanks!,2,09-21-2021,07:48 AM
491,435446,MarcoGianfico,"I thinksimilarIncidentKeys is deprecated. Try to use onlysimilarIncidentFields.And if that still not works, then usesimilarIncidentKeys=incident.vulnerabilityplugindidwith incident prefix",0,09-21-2021,08:48 AM
492,435446,DougCouch,"Hello Aazadaliyev,Thank for your reply. I tested both solution but they're not working.the issue doesn't seem to be on finding the key but during the comparaison?",1,09-21-2021,09:12 AM
493,433105,aazadaliyev,What is the type of the field? Number or string?,0,09-11-2021,11:52 AM
494,433105,AlexandreBorgo,"Hi Mark!It's not designed to work that way. If you think about how we package our integrations it could potentially create some terrible dependencies if you weren't careful. Our recommended practice would be to:a) write each of the integration calls into Playbook tasks orb) write an automation that accesses each of the integrations.The integration code should be considered more or less a black box with inputs and outputs of data from the particular third party application. If you need to send data to the app use a command to do that. If you need to fetch data from the app, same. Any intelligence around what you do with the data is better managed outside in either a playbook or an automation to allow you the flexibility to make adjustments to it.Thanks!-Doug",0,09-14-2021,09:18 AM
495,433105,aazadaliyev,Hi Dougthanks for the response. The use case here is that we are intending to replace our SIEM over the next year so I wanted to decouple the backend SIEM integration logic from the front-end commands used by the playbooks. That way when the time comes we can simply replace the backend integration without updating each playbook.I take your point about the dependency issues though it wasn't really clear to me why the same doesn't apply to automations which do provide this abiiity via the demisto.executeCommand() method. I've more or less resigned myself to using automation wrappers (your option b) but this is less desirable because once we replace the backend I will have a bunch of automations to update rather than a single integration. Still we only have handful of these compared with 200+ playbooks so it definitely helps.Thanks for the response. I have marked this as the correct solution.Mark,0,09-19-2021,12:38 AM
496,434139,DougCouch,"Extracting domains is a difficult task. If you consider that a domain can almost be anything separated by a ""."" it gets very difficult to design a regular expression that can extract that without getting a lot of false positives.Typically the way things are handled by XSOAR out of the box is that we first identify either email addresses (email@domain) or a URL (http://domain/otherstuff) and pull the domains out of those. If you are able to identify a regular expression that could effectively grab a domain out of a normal email without catching other stuff as well you can create a custom regex in the domain indicator type.I'm not sure there's a great solution here I just wanted to help identify why it's a tricky problem!I hope that helps!",1,09-15-2021,08:16 AM
497,434139,xsoardude,"I do have here an example:There is no ""no specific threat"" written, even no inidcator what Hybrid Analysis found - only 2nd party verdicts...Task Results tab:Task outputs tab:If you visit Hybrid Analysis Website, you'll see:where is Hybrid Analysis' Verdict in that Task?thanksroger",0,09-15-2021,09:24 AM
498,431148,DougCouch,"HelloI run into the same problem, as I would avoid that XSOAR Playbook scans URLs, which XSOAR already did.The dockerize hindering me too to store already scanned urls.So I've build an own Integration which use FTP as a store.My solution for the FTP: it runs on the demisto machine, with vsfdpd...regardsroger",0,09-02-2021,11:41 AM
499,430094,_buchwalder,"Hello Roger,The problem here is the same, we want to get the EntryID of the file so we can execute other tasks in XSOAR to analyze the file.How do you access the file from an incident when it is stored in the FTP server?Reagrds,Alejandro Bracamonte.",0,09-02-2021,06:20 AM
500,430385,_buchwalder,"Hi! So the easy way to get the EntryID of the file is using the variable ${File.EntryID}If you want to get more specific and insure you are getting a certain file you'll need to add a filter into the query, otherwise you'll bring back all of the files.It sounds like several of you are experimenting with writing your own Automation to do something specific with the contents of a file. If you want a good example of how we do that take a look at the ReadFile automation. It simply reads the contents of a file and dumps it into a context value.Let me know if that helps or you are still missing something on this.Thanks!-Doug",0,08-31-2021,06:32 AM
501,430385,abracamontesauz,"Hi Doug!Thank you for your response. Our problem here is not to get the EntryID from the context. We are downloading a file using requests library in a automation and we want to store that file in the incident adding the information to the context. We don't know how to do this in the same automation.Regards,Alejandro.",0,09-01-2021,12:47 AM
502,430385,DougCouch,"Hi AlejandroJust found it out.If you email it withmail-sender-new:AttachedID is <id>@<ticketnumber> -> 31@1234attachNames is the name of the attachment, you would like to see in the Mail Attachment -> ""picture.png""attachCIDs is the name in the war room, in the ""command""-Part of the entry 31 -> ""picture""You need all three entries. You may put more than one attachment, just put a coma in between -> ""31@1234,45@1234"" etcFinally I've got it working 🙂greetsroger",0,09-01-2021,11:57 AM
503,430385,abracamontesauz,If you are running into issues/errors with integrations it is best to reachout to our customer support portal. They can help you troubleshoot or point you in the right direction.,0,09-01-2021,11:24 PM
504,430385,_buchwalder,HelloDid you tried to use ExportToCsv task?https://xsoar.pan.dev/docs/reference/scripts/export-to-csvregardsroger,0,09-02-2021,05:02 AM
505,418085,JosephCosgrove,"Thanks for the reply, yes I used the export-to-csv task to get the data into a csv format, but that's about all the task seems to do. Now that I have the file in csv format, I need a way to send it in a post request to another api.",0,09-01-2021,06:37 AM
506,430403,_buchwalder,"HiI do see you problem, you need first to donwload the file to continue the work/tasks.I did a little test on my side and saw following:The download link is cutted in different sections...so the url is like this, if you would use it in an other task:https://demisto/entry/Download/${File.EntryID}Be carefull, you migth not use the URL above if you send it in an E-Mail, because you need to login first into demisto...Could you please try it out?regardsroger",0,08-31-2021,06:38 AM
507,430403,TexasHoosier,The issue with sending the download URL is that a team will be using the file that does not have access to XSOAR. So I need to be able to send the csv directly.,0,08-31-2021,06:42 AM
508,430403,_buchwalder,"I understand that port 8080 isn't in the output of that command. Just to verify, after adding the server config and the d1 config, users are still unable toaccess forms sent out in communication tasks, correct?",0,08-31-2021,06:58 AM
509,430403,TexasHoosier,"AtulloAs far as I untersood is, that I need first a running communication Task, before I may use it in any Playbook.And I don't think, that this communication-Port is the same port as demisto for admin is running on it (https/443)So I choose a different Port.And no, that port (8080) is not in the open ports list of ""ss"", looks like, demisto is not opening it.thanksroger",0,08-31-2021,07:20 AM
510,415815,atullo,Please verify that there's a colon in front of the port number. Let me know if I should further explain any of the following commandsDisplay current confReplace line in confVerify new conf Restart XSOAR engine service Verify listening port ,0,07-20-2021,10:53 AM
511,415815,_buchwalder,"Hello AtulloIndeed, I did not hat the colon in the config - could you please take care, that this little info gets into the document in my thead opening?How ever, I did all your steps, but system could not find d1.service, I tried first with demisto.service then with a reboot - still no port 8080(btw, I like the -tulpen, use it since years 🙂 )regardsroger",1,07-21-2021,05:12 AM
512,415815,atullo,"Roger, Are you able to restart demisto like you have in the past? How are you verifying that demisto is running? Could you share the commands you're using and their output (please redact anything sensitive)?Thanks",0,07-26-2021,10:27 AM
513,415815,_buchwalder,"Hello AtulloI'll enter the following command:After that I do see Logs from Demisto and wait until I see:After that I do a:And check, If there is:thanksrogerPS: I just saw, that the one Demisto-Service is still in a shutdown prodecere, and is traped in a loop:I'm going to reboot the machine.",0,08-25-2021,03:45 AM
514,415815,atullo,"reboot was done, but still no port 8080:",0,08-25-2021,05:26 AM
515,415815,_buchwalder,"You'll need torestart the XSOAR engine service on your engine (not the demisto service on your app server; my apologies, I did not word my previous questions correctly).For engines running a Debian based distro the command would beMore info for starting & restarting the XSOAR engine service can be found here:Install a Cortex XSOAR Engine.",0,08-26-2021,08:04 AM
516,415815,_buchwalder,"AtulloI do not have an d1 installation here. Since I'm not able to install d1-Service on Demisto machine.""Failed - Cannot install engine along with Cortex XSOAR server""Do I need an Engine to use those Communication Task?If so, I need first to setup a new machine.Thanksroger",0,08-26-2021,08:28 AM
517,415815,atullo,"If I understand correctly, you'd like for an input field like '1,2,3,""jon,doe"",5,6,7' to be transformed into just 'jon,doe' and XSOAR's implementation of regex does not include the positive look ahead operator.Perhaps this could do what you're looking for:Second, use the 'Tostring' transformer with one double quote for the 'to' valueWhen its done it should look something like this:From string (from: "")To string (to: "")Hope this helps",0,08-26-2021,10:03 AM
518,415815,_buchwalder,"Hello AtulloThe solution sounds fine, but Wildfire's syslog has more than one field with ""-s in it.And I would like to use it in a mapper, so there are 78 mappings for each Syslog-Entry. And this is only for Wildfire-Mapping.is there no easier way?I think that this is a ""normal"" syslog behavior, that commas are present in the comments inside of "".thanksroger",0,08-30-2021,02:35 AM
519,416776,atullo,"Roger,Thanks for providing thatsimplified syslog output in your originalpost. Could you provide an actual syslog message? Please redact anything sensitive of course.Thanks",0,07-20-2021,10:42 AM
520,416776,_buchwalder,"Hello AtulloSo, here one example:I've replaced some stuff with <> and modified IP's, vlans etc.regardsroger",0,08-27-2021,02:43 AM
521,416776,atullo,"Hi,Please submit a support case for this.Thank you",0,08-27-2021,04:13 AM
522,416776,_buchwalder,"Hi,Thanks for the reply and yes I tried submitting a support case for the same but For Cortex Technology, there was no dropdown to select XSOAR .",0,08-30-2021,02:02 AM
523,429081,mbordach10,"Hi,You can also reach out to your account team regarding your specific license details. The notification about ""New License required to add Additional users"" comes up when you reach your user limit but it shouldn't stop you from working or come up as an error.Regarding opening a support case for XSOAR this is what needs to be filled in Technology:Hope this helps!",1,08-27-2021,06:25 AM
524,429081,SDash6,"Hi @Anass_Baalal ,In order to get better traction for this, I have moved it to the Cortex XSOAR area.I would recommend that you visit the Cortex XSOAR discussions area to see your discussion and others there and to create any other new discussions on the topic there.Cheers,-Kiwi.",0,08-27-2021,06:29 AM
525,429081,mbordach10,This Email Communication pack enables security teams to reply to an email as part of an incident. The SOC team is able to communicate directly through the Cortex XSOAR platform as part of the remediation process.,0,08-29-2021,04:41 AM
526,424403,kiwi,@OCabreraHere is a documentation on how to configure Cortex XSOAR and how to reach it via http request to the serverhttps://xsoar.pan.dev/docs/reference/integrations/taxii-serverLet me know if you have further questions.,1,08-05-2021,07:55 AM
527,424403,jamessmith1234,"Perhaps you could try using the ad-searchcommand to filter on the computer's OU and then the ad-add-to-group commandto add the missing computers to the group:Active Directory Query v2Integration DocumentationUse the!ad-searchcommand to run a query for Active Directory objects (users, contacts, computers, and so on). This command enables you to determine which data fields should be returned for the objects.. . .Add or remove a computer from a group using the following commands:ad-add-to-group",1,08-09-2021,11:40 PM
528,425079,aazadaliyev,That could be a way to do it. I'll check the documentation and see if I can do what I need.Thanks for the hint 😉,0,08-08-2021,12:10 PM
529,423173,atullo,"Hi@atullo,FYI, I have been able to achieve what I wanted to do with the information you gave me.I used the!ad-searchcommand filtering with LDAP query format.Thanks for pointing me out in the right direction.",1,07-29-2021,12:30 PM
530,423173,MartinCimone,Happy to help and thanks for marking as a solution.,0,07-30-2021,04:57 AM
531,423173,MartinCimone,"You first want to call CommandResults to build the result you want to pass to return_results:https://xsoar.pan.dev/docs/integrations/code-conventions#commandresultsExample:emails = ""email1,email2,email3""output = emails.split("","")result = CommandResults(outputs_prefix=""MyCustomEmails"",outputs=output,readable_output=tableToMarkdown(""My Custom Emails"", output, headers=[""Emails""]))return_results(result)Your outputs in the automation would by defined as ""MyCustomEmails""ContextYou can reference the CommandResults in the Script Helper as well.",1,08-03-2021,09:34 AM
532,423173,atullo,Looks like this was brought up here:https://github.com/demisto/etc/issues/23229and purportedly resolved here:https://github.com/demisto/content/pull/5849If PR 5849 hasn't resolved bug ID#23229 it may be worth re-opoening the GitHub issue.,0,08-03-2021,01:20 PM
533,424232,MBeauchamp2,"Apologies, I don't think you have access to those links I referenced.I'll check if it makes sense to reopen this issue.",1,08-03-2021,12:58 PM
534,417684,atullo,just an update: I reopened our internal issue for this,0,07-27-2021,01:57 PM
535,417684,atullo,The XSOAR team is currently working on a fix for this issue.,0,07-28-2021,04:58 AM
536,417684,atullo,"Since TLSv1.0 has been deprecated, not being able to login was by-design - RFC 8996: Deprecating TLS 1.0 and TLS 1.1I'm logged into an XSOAR 6.2 instance via Chrome and went to settings (3 dots) > More tools > Developer tools > Security > Overview and was able to verify that mybrowser is connected via TLSv1.3:",0,07-29-2021,11:52 AM
537,417684,atullo,"This is true@atulloand for very good reason as well, the issue in this case is more that I was trying to work out why the client hello was in tls1.1 as it seemed odd, and I was far from convinced that the XSOAR server would haev been requesting the downgrade, however I think the blame can be squarely aimed at a chrome/windows 10 moment of stupidity.A rebbot did not fix it but with no action taken on the XSOAR server I could log in as if nothing had happened th following day.",1,08-02-2021,05:50 AM
538,423343,atullo,You can find the error in the logs. Navigate to Settings->Troubleshooting>About and download logs.Look for _fetch-incidents: Timeout in the logs,0,07-30-2021,01:21 PM
539,423343,aurence64,"As well as@aazadaliyevsuggestion you could try and look through the error message on the integration instance itself, when you hit test that wil give you a reason why the test has failed.",0,07-31-2021,04:21 AM
540,422017,aazadaliyev,You just return incidents array as JSON string.,1,07-26-2021,12:54 PM
541,422017,aurence64,"Yes, EWSv2 expects the usual item-id to mark the item/email as junk. If this has been removed/deleted from the inbox already it's likely you will see that error (https://docs.microsoft.com/en-us/dotnet/api/microsoft.exchange.webservices.data.exchangeservice.mark...) . Can you validate if the email still exists in the mailbox ? I would also double check the instance you run this command from in case you have multiple instances of EWSv2 setup in XSOAR. (As best practice you can specify the instance with the ""using"" argument to make sure it runs the command on the right mailbox)",0,07-30-2021,12:41 AM
542,422275,aazadaliyev,"Hi,Please review the following articles:https://docs.paloaltonetworks.com/search.html#q=PAN-OS%20EDL&sort=relevancy&layout=card&numberOfResu...]thanks.",0,07-29-2021,10:43 AM
543,414497,vbharadwaj,"Hello GfilippovThanks for your answer.But I can't find any info, what to do on Panorama and what to do on XSOAR.Right now, I do it via syslog...thanksroger",0,07-20-2021,09:41 AM
544,409120,gfilippov,"Hey@r_buchwalder, We are currently working on a solution to ingest WF events/threat logs of PANOS to Cortex XSOAR as incidents. We are working our way through that, as we are limited to the number of logs we can get using the export API, contrary to syslog.for reference: https://github.com/demisto/etc/issues/16695",0,06-15-2021,02:40 AM
545,409120,_buchwalder,Hello@bkatzirI'm not able to follow your github link - I do get a 404 message...thanks for the Info anyway. Will have an eye on oncoming release notes.thanksroger,0,07-02-2021,04:44 AM
546,409120,bkatzir,"It is hard to dive into that without the logs.I suggest deleting all of the current MS integrations instances, and try re create new ones with *different* instance names.please visit here for further explanation on the auth process and suggestions:https://xsoar.pan.dev/docs/reference/articles/microsoft-integrations---authentication",0,07-04-2021,12:15 AM
547,409120,_buchwalder,"Hi,Please submit a support case with the logs attached,thanks.",1,07-13-2021,05:04 AM
548,415023,bkatzir,ThanksWe solved the problem by reinstalling the RSA server.,0,07-04-2021,12:19 AM
549,406382,gfilippov,"My first response when someone describe a potential UI anomaly I recommend that you refresh your browser window, clear the browser cache and try again. If it still isn't there it's worth taking a screenshot and submitting a support ticket.",0,06-15-2021,01:25 AM
550,406382,ESTEVAOLPE,,0,06-29-2021,04:37 AM
551,415436,DougCouch,"Hi,I see that the integration is following the vendor's API codumentation:https://docs.tenable.com/tenablesc/api/Scan.htmplease submit a support case and we will clarify it with the vendor if required,thanks.",0,06-28-2021,01:49 PM
552,415436,aurence64,"Hi,Please submit a support case,I think that the issue may be only in the pre-proc rules test functionality, and the rule will work as expected with real incidents, please try to test with existing incidents as well,thanks.",0,06-28-2021,11:37 PM
553,360604,gfilippov,"Hi,By design the classification is done by a single field,please submit a feature request for it.As a workaround you can create a new transformer script that gets the whole incoming incident json as an input and takes into consideration any fields you want, then returns the desired incident type based on the script logic, that will be mapped to the right incident type in the classification wizard,thanks.",0,06-15-2021,02:24 AM
554,379815,gfilippov,"Hi,By default if you query for something that wasn't found- it won't be written to the context, it is like this in pretty much all the integrations,theCherwell result shouldinclude the host name which you can use to verify if you got anything back regarding that host,for example if you have an input of 10 hosts, but only some returned data fromCherwell; you can have a task\playbook that will loop the input host names one by one, and will check if it exists in theCherwell response, if so it will write the data to the other DB, if not it will continue to the next one,thanks.",0,06-15-2021,02:12 AM
555,384349,gfilippov,"Hi,Currently it is only possible topermanently delete files that were uploaded manually by you in the war-room,please submit a feature request for it.As a workaround you can use theRemoteAccess (SSH) integration to connect to the XSOAR server's OS and have a job that will retrieve the file details from the server, and remove files older than X days,it is possible but it may require some scripting,thanks.",0,06-15-2021,01:59 AM
556,386099,gfilippov,"Hi,Please submit a support case with the logs attached,thanks.",0,06-15-2021,01:51 AM
557,404858,gfilippov,"Hi,You can contribute this content via the marketplace, it will be reviewed by our content development team and merged to our content if approved,thanks.",0,06-15-2021,01:40 AM
558,406225,gfilippov,The XSOAR server does support both IPv4 and IPv6. It listens on port 443 of both networks and will respond. It also recognizes IPv6 network addresses as an indicator type and can submit it to compatible integrations to enrich with reputation data. The caveat being that the specific integration has to be able to support the request and the API call. I was unable to find documentation directly addressing that question either. My information comes from internal (Customer Success) discussions with the Software Engineers.Let me know if that addresses your questions or if you have something specific you need!,0,06-15-2021,01:33 AM
559,409164,gfilippov,"Hey Martin!I think the part that is creating an issue is the way the list is returning the values. Basically the list can store a chunk of data in almost any format. You can comma separate it or use newlines or whatever you want. You may have to parse the output though. Our commands can usually iterate over lists but it's going to expect something more like a json or python style list being handed to it. Use the Split transformer to break up the output to the command before it processes it. Here's an example:Created the list as a comma separated valueIf I try to print it out now you get basically a single string with all of the values. You can tell because our Print statement processed it in one command instead of iterating through each of them.If you create a small playbook, add in the command you want to run and use a transformer like this: Then your output will break up into an actual list and process each item individually. I hope that helps!",0,06-15-2021,01:23 AM
560,410788,DougCouch,"Hi@DougCouch,Thanks for your help here. I fixed my problem a couple of weeks ago using the exact same method using a transformer ""Split"" and using a comma as a delimiter.Thanks for having taken the time to help me out.Have a great day !",0,06-14-2021,02:57 PM
561,406847,DougCouch,Have you looked at the docshttps://xsoar.pan.dev/docs/reference/scripts/set-grid-field?There is an example for how to use.,1,06-14-2021,10:54 AM
562,406847,MartinCimone,"HiThere appears to be a permissions issue with docker, what do you get if you run ls -alh/var/lib/docker/overlay2/ | grep53bc122All the directories should be root root in that dir",0,06-14-2021,01:56 PM
563,410699,aazadaliyev,HelloWith the grep command I do not see any output. If I remove that grep command I get lots of dirs - all of them got root root permission.thanksr,0,06-06-2021,01:00 PM
564,385570,aurence64,You have 2 options to do that:1. Rasterize url returns file - check if File exists with name url.png in the context - if not then rasterize was not successful2. Use extend-context to return the message from rasterize command to the context. If the rasterize will fail you will see in the context message likeThere is nothing to render. This can occur when there is a refused connection. Please check your URL.,0,05-05-2021,01:32 AM
565,385570,_buchwalder,"I can see it in the roombut i'm not able to get it in the context, could tell me the path?",0,05-25-2021,03:37 AM
566,407515,aazadaliyev,You forgot to add extend-context.To your command add appendextend-context=foo=.,1,05-18-2021,11:58 PM
567,407515,MarcoGianfico,"Could you clarify a bit? I'm not sure I understand what you mean by ""everything in one row"". If you have a CSV file in the warroom it will display only a certain number of columns in the warroom (you can change that using a server setting) and a certain number of rows (also adjustable). Once you click View Full Table in a new tab or View full artifact in a new tab you should get the whole table as expected. Here's an example using a randomly generated csv file.Here's the warroom entry:And here's what you get when you click through to View full artifact:(Note the scrolly bars on the right)Were you expecting something else? If so, you might consider mocking up what you are looking for and putting in a feature request on our Aha! portal. If I misunderstood the request or you are seeing something different let me know and it may be that something isn't displaying correctly for you.Thanks!",0,05-19-2021,08:09 AM
568,407515,aazadaliyev,Ah! Sorry I just reread it after finishing my coffee. It sounds like you want to flip the table sideways! Follow up with the Aha! portal like I mentioned. Check to see if anyone else has requested that and if not put in the request!,1,05-19-2021,02:20 PM
569,386104,DougCouch,Hello@DougCouchThank you for your Input! I've just done an entry about:War room: Flip content in | Cortex XSOAR Customer Feature Request (aha.io)Regardsroger,0,02-26-2021,07:29 AM
570,386104,DougCouch,I believe that currently the only way to use Cortex XQL is through the GUI.,1,02-26-2021,07:38 AM
571,386104,_buchwalder,The XQL integration is on the roadmap (the API is not public yet). I believe it should be released by the end of the Q3 2021 (CY),0,05-04-2021,05:08 AM
572,398396,RGonzalez Abundis,"So we're utilizing XDR Prevent (not Pro) here. Appears to be all the preparation on PAN's site is carefully equipped towards the Proform, and Github hasn't been exceptionally productiveI'm contemplating whether anybody has any playbooks or work processes or (crosses fingers) contents they're utilizing to cooperate with XDR here?Hello smyakent ,if you find anything related playbooks or work proccesses please share here.",0,04-29-2021,06:29 PM
573,398396,aazadaliyev,"Hi @JuDiaz,The from and to dates can be extracted from the input arguments.demisto.args() provides a dictionary containing the keys ""to"" and ""from"".If not provided in the dashboard (such as using ""all times"") then they have default values (as far as I remember) of 1970-01-01.RegardsAdam",0,05-02-2021,12:41 AM
574,378902,jonsrnangerang4aria-label20,is there anywhere where this is documented? I can't seem to get the date data flowing,0,04-23-2021,06:54 AM
575,398971,ABurt,is there anywhere where this is documented? I can't seem to get the date data flowing,0,04-18-2021,06:29 AM
576,398971,JuDiaz,Tryherein the admin guide.,0,04-20-2021,06:05 AM
577,398971,ABurt,"Hi@abhilash_eNo, I haven't.Please file an issue with all the details. We will try to assist.Thanks,Anar",0,04-21-2021,05:51 AM
578,398348,aazadaliyev,@abhilash_eIs this the latest version of the pack?. Are you using the out of the box query for fetching? and if not can you please provide the query that your are using?,0,04-17-2021,11:22 AM
579,398348,dbaumstein,"Hi@abhilash_eNo, I haven't.Please file an issue with all the details. We will try to assist.Thanks,AnarHow and where do I file for an issue?",0,04-17-2021,11:18 PM
580,398348,abhilash_e,"HiPlease find my response inline@abhilash_eIs this the latest version of the pack?A:- Yes, 2.0.1Are you using the out of the box query for fetching? and if not can you please provide the query that your are using?A:- I didn't try any query, I was just testing out the new instance from settings -> Integrations -> Servers & Services",0,04-19-2021,03:47 AM
581,398348,abhilash_e,,0,04-19-2021,03:55 AM
582,395552,jgomes,"Interesting, as I've noticed some differences between XSOAR and that guide.For instance, that guide lists tables as extended (not basic), but XSOAR does support Markdown tables.Also, that guide is sometimes vague. For instance, it notes that some Markdown applications support some HTML tags. I'd rather not engage in trial-and-error to figure out which ones I can use. Is there a comprehensive guide to the Markdown used in XSOAR?",0,04-02-2021,09:46 AM
583,395552,DZerkle,"As@jgomesstated Markdown basic syntax is supported and some of the extended syntax, see herehttps://www.markdownguide.org/extended-syntax.Supported:- Tables- Fenced code blocks- Emojis",0,04-02-2021,12:16 PM
584,395552,aazadaliyev,"Hello,I assume this a field-change-triggered script? What do you have selected for the """"Run triggered script after incident is modified""?You will not need to specify the ""CustomFields"" in the setIncident command either. You can use the system name for the field. In your case it would (most likely) be:RegardsAdam",0,04-02-2021,01:22 PM
585,389281,ABurt,I don't even have that checkbox. Where is it? We're running 6.0.,1,03-05-2021,01:46 AM
586,389281,DZerkle,"It looks like the checkbox is only there for version 6.1.The workaround is to leaveout the'id':child_case_id in the setIncident command and leave out the""incidentId"":child_case_id in the linkIncidents command. This will default to using the current incident.It may be that you have to use the ID, as is the case with the linkIncidents command.In this case, triggered scripts need to usedemisto.investigation()['id'] to get the incident ID. They can't usedemisto.incidents()[0]['id'].",0,03-05-2021,07:40 AM
587,389281,DZerkle,"The solution above turns out to be only partial. Leaving out the incidentId field for the linkIncidents command causes the command to do nothing. Putting it back in re-generates the DB version errors. Running the trigger script from the command line works perfectly.So, I don't have a way to modify linked cases in a triggered script in 6.0. Anyone know?",0,03-05-2021,11:28 AM
588,389281,DZerkle,"If you leave out the ""id"" field in the setIncident command, it will execute within the current incident (it assumes the current incident is the id).Is the script executing from within an existing incident, or is the script attemping to update a different incident?",0,03-05-2021,04:45 PM
589,389281,ABurt,"We just upgraded to 6.1, so I revisited this matter. It's not much better.The DB Version errors no longer appear.If I leave ""Run triggered script after case is modified"" unchecked, the triggered script correctly updates other fields with the setIncident command.If I check that box, the other fields do not update, even though the war room says that they're updated.Whether I check that box or not, and no matter how it is called, the linkIncidents command does nothing when run from a triggered script. It works as expected if run from a script launched by a button or the command line.Can you confirm the above? The docs mention nothing about linking incidents from triggered scripts.",0,03-08-2021,12:58 AM
590,389281,DZerkle,"The automatoin script that you have created to link the incidents, can you confirm who it is running as? By default it's ""limited user"".This may be affecting the outcome.",0,03-16-2021,06:03 PM
591,389281,ABurt,"It was set to ""limited user"". I tried setting it to ""DBot"". No change in behavior resulted.I have the exact same script triggered by a button and triggered by a field change. It works fine when triggered by the button.",0,03-17-2021,03:03 AM
592,389281,DZerkle,Can you post the contents of the script?,0,03-17-2021,09:22 AM
593,389281,ABurt,"Like I said, I am a beginner and when I discussed it with a coworker he pointed out to an automation that didn't take into account the recursion. This topic can thus be considered closed.",0,03-17-2021,09:46 AM
594,393415,EVanderhasselt,"Hi Sean,In your current mapper, do you map any unmapped fields into the labels in the context data?RegardsAdam",0,03-24-2021,09:29 AM
595,389470,ABurt,Yes we do,0,03-05-2021,02:41 PM
596,389470,Sean_L,"You could export an existing incident and make the labels the main fields on the incident and use this JSON as a file input into the mapping.For example, create an automation script called ""exportIncidentLabels"" and use the following code:Then execute it from the war room of the desired incident that contains the relevant labels. When the results show, download them as a file:Then open the mapper and use:However you get the data out, the mapper JSON input file expects a JSON list of dictionaries. Each array entry is considered a new incident and the JSON dictionary is considered the ""rawJSON"" input into an incident.[{  ""incident1_field1"": ""value1"",  ""incident1_field2"": ""value2""},{  ""incident2_field1"": ""value1"",  ""incident2_field2"": ""value2""}]",0,03-07-2021,10:14 AM
597,389470,ABurt,"So I finally got around to it and I added the script. It outputs the labels nicely. I ran them though CyberChef to make sure everything was correct, and there were no formatting issue, but when I upload in the Mapping Editor I get this:Error parsing requestThis is the same message I get when I export from Splunk as JSON as well.",2,03-08-2021,04:19 AM
598,389470,Sean_L,I figured out. The JSON needs top be enclosed in '[' and ']' for it to work.Adding this to the start and end of the file after the export from the script worked!Thanks!,0,03-11-2021,10:04 AM
599,389470,Sean_L,You can find instruction on how to configure QRadar with XSOAR herehttps://xsoar.pan.dev/docs/reference/integrations/q-radar-v2ThanksOri,1,03-11-2021,10:09 AM
600,390261,OriNahir,"To be clear, I'm not picky about how this gets done. It doesn't have to be part of a layout. If it happens in some sort of sub-playbook, that's fine. The possible options could (and probably should) be loaded from a pre-calculated list, instead of a real-time search.All that's important is that the user is given the opportunity to select values that need to be calculated and that the selection can be used as an argument to an automation.",1,03-11-2021,08:45 AM
601,387945,DZerkle,"Hi! So if I understand the ask correctly, you'd like to be able to interact with / ask your users or analysts questions based off other information during the investigation. Let's say this is part of your Playbook workflow.The first thing you need is the question part. Take a look at the Data Collection Task. This will let you create a questionnaire as a task in your playbook. If you are interested in having the user select a single item from a list use a Single Select question. I believe in this case you are looking for ""Parent Ticket"" from a list of similar incidents, correct? (You can do this with multi-select too if you want to create a list of items selected from a larger list of items). It should look something like this:Here's How the question will look:What you are doing here is selecting from the list of id's in the context from the search in the prior step but you can do it from any context entry that has multiple items in it.So out of my set of AMAZING test data that I was able to create on the fly:When you run the playbook the task will ask for input based on the previous task:Hope this helps!!",0,02-25-2021,04:42 PM
602,387945,DougCouch,"Fantastic! Thank you!On experimenting with this, I see that the choices can come from the Context or Lists data, and that it's possible to apply filters and a transformation. Very nice.Where is the documentation for this functionality for populating the choices? I looked around, but I don't see anything about it in the document you linked.I think this will work as I want in a playbook kicked off by a button on the layout. Great! Is it possible to use this method (of dynamically populating choices) elsewhere? In particular, can it be used for a field on a layout? I tried setting up a new field like this and didn't see the ""{}"" marker in the box for the choices. It looked like I had to just type in some fixed choices.At the HTML level, each item of a select object can display one string but return an arbitrary value not necessarily visible to the user. Is that possible here? It seems to just take a flat list of values.",1,02-25-2021,07:05 PM
603,387945,DZerkle,"Hmm. The idea here is that, at any time, the analyst should be able to click on something to mark the incident as a false positive and select its parent incident. It should also be possible to un-mark the incident. This shouldn't affect the processing of the main playbook.A colleague of mine just told me that running another playbook on the incident (to ask the user for the parent) would create a new incident each time the user clicked on the button. That seems like a pretty heavyweight action just to get the answer to a question. Automations kicked off by buttons are much more lightweight, but they also can't pop up a single-select GUI element with custom choices, right?",0,02-26-2021,01:02 PM
604,387945,DZerkle,"Hmm again.I'm exploring, and I keep running into roadblocks. My users may change their minds or need to re-assign incidents to different false positive parent incidents. So, putting this process in the main playbook seems like it wouldn't work. Playbooks seem to be set up to complete a task, move on, and never go back.Also, it looks like a button on the layout can kick off a script/automation (they're the same thing, aren't they?), but I didn't find any way for it to launch a fresh playbook that would collect information from the user.So, I have to ask again: Is what I'm asking for even possible?",0,02-26-2021,03:27 PM
605,387945,DZerkle,"If I understand correctly, the following may help:1. Create a new field that will be used as the selection drop down for the user and give it some default values:2. Create a new automation script (yes automations = scripts and scripts = automations) and ensure it has the ""field-display"" tag:In the above script, the returned list options assumes that the field named ""monitored_field"" is available in the incident and that it is a list. It will also only display options for the field if it is part of an existing incident and not in the ""create / new"" incident form.3. Assign the field-display script to the field:4. Create a new ""field-change-triggered"" script and make sure to assign the ""field-change-triggered"" tag:In the above script, if the selection has changed then the script runs the playbook again by simply setting the playbook. When setting with no parameters, it re-runs the existing playbook on the existing incident.5. Edit the field again and this time assign the field change parameters:This means that each incident will have a field (that you can place in the incident layout) that will contain dynamic content based on the incident fields, lists or context and when changed will execute a command (in this case the playbook re-run).A small demo:(view in My Videos)In your use case, the field-display script would pull a list of parent incidents. The field-change script would then re-assign the current incident to that parent incident.I hope this helps.RegardsAdam",0,02-26-2021,05:12 PM
606,387945,ABurt,"Thanks, again, so much for your help. I am impressed by the depth of your assistance and grateful for it.Re-running the playbook on field value change is interesting. When re-running the playbook, I'm thinking that there should be a decision point at the very beginning that will detect that the incident has been marked as a false positive with a parent, then branch off to the end, with all tasks completed. Then, it's just a matter of waiting for someone to clean up the mess (tracking that in the parent) and closing the incident. Is that a reasonable approach?Also, can you confirm that the ""field-display"" tag means that the script will run and the options will be re-calculated every time a user pulls up the incident and looks at the field?  The script runs and populates the selections when the user clicks on a dropdown icon.",1,02-27-2021,01:14 AM
607,387945,DZerkle,"Note to future developers trying to do this: Once I knew what to look for, Google found the relevant documentation for me: Here it is.",0,03-01-2021,11:04 AM
608,387945,DZerkle,"On experimenting with this, I found a glitch. In particular, it's not clear what data the field configuration script can access.I want the user to pick from a list of false positive parent case names, and this is what I have so far:The SearchIncidentsV2 command is supposed to put its results in the incident context, but it doesn't do that. The context is unchanged. Running demisto.log() causes the script to fail, so I don't have any way to see what's coming back from the demisto.executeCommand(). (The documentation for the return value is ""Union[dict, list]: Command execution response wrapped in Demisto entry object"", which is uniquely uninformative.)The display with this script does correctly load up the test options in the demisto.results() call, so it's just a matter of getting the list of parent tickets from somewhere.",0,03-01-2021,02:32 PM
609,387945,DZerkle,Hi Alejandro!It's important to remember that we intentionally containerize all of the Integration and Automation code using Docker. The purpose of this is to keep that code from accessing files on the server filesystem. So even if you actually had the actual file path you can't actually use it because you'd just be attempting to access the non-existent path in the container. (Just an FYI: in most cases it should be in /var/lib/demisto/attachments where it is stored with a hash filename)What we do provide for you is a filehandle. This enables you to pass the filehandle any time you would normally want to use a file without having to know the exact location on the server. So if you are using it to sandbox a file for instance you don't have to give it the full path to the file you just pass the filehandle and XSOAR will provide the file.I hope this helps!,0,03-01-2021,06:22 PM
610,386556,DougCouch,"Hi!Thank you for your reply.I have been testing with the information you have provided but I have not been able to upload the file.I am working with the API's owner to solve the problem by his side reading the extension from the file's metadata, but it would be very useful to have a way to access a file using the actual name or path.Thank you for your help!Alejandro.",1,02-18-2021,07:39 AM
611,386556,abracamontesauz,"Hi@abracamontesauz,If I understand correctly, you would like to check that a file uploaded into an incident has a specific file extension BEFORE uploading it? I'll try and cover all scenarios.Firstly, when referencing a files path in an automation or integration, one can use the `demisto.getFilePath(<entryID>)` command to retrieve the data. This will give you the path (that you can use, for example, with Python `open()` command and also the filename (including extension).When uploading a file to the incident as part of the incident creation, there isn't way to specifically check the extension prior to uploading the file. The file will be included, however, you can make it subject to pre-processing rules. This would involve creating a new pre-processing rule that matched the incident type you are creating:You can choose here to either simply drop the incident, or perhaps, run and automation script. Dropping the incident could happen when the attachment criteria are met:Above is an example.Using an automation script could give you more control over what happens but is a little more advanced.You could also choose to handle the incident (depending on it's attachments) at the playbook level. This could also involve automatically closing the incident if attachment criteria are not met.Example above.I hope this helps.",0,02-22-2021,02:41 AM
612,386556,ABurt,"Hello@ABurt,Thank you for your response, that information will be very useful for me in the future.Although, my problem is not to check the file extension at Demisto's level. The problem is that the external API which I am using, receives the file like ""<_io.BufferedReader name='71_313@71'>"" using python open() method, and checks that name to read the extension. I need that name to be something like ""myfile.xls"" so the API could read it properly and recognize the file to store it.I hope it's is clearer now.Thank's in advance,Alejandro.",0,02-22-2021,03:46 AM
613,386556,abracamontesauz,"Are you referring to the XSOAR API, if so, which endpoint?RegardsAdam",0,02-22-2021,04:13 AM
614,386556,ABurt,"Hi,No, I am using an external API that I have implemented.Regards.",0,02-22-2021,04:44 AM
615,386556,abracamontesauz,So you have an integration that is using an API from a 3rd party product and you would like to pass it an absolute file path?,0,02-22-2021,04:47 AM
616,386556,ABurt,"That's exactly the point, sorry for my explanations.",0,02-22-2021,05:14 AM
617,386556,abracamontesauz,"OK, I understand.In your integration, call the ""demisto.getFilePath(<entryID>)"" providing the entryID (which is the 123@123reference). This will return a JSON dictionary with the key names ""name"" and ""path"". The name is the original filename and the path is the absolute path that can be used in opening a file handle.For example:273@6cf5026f-8199-45ab-80fc-199ddf3291ab is a zip file in my playground. When using demisto.getFilePath(""273@6cf5026f-8199-45ab-80fc-199ddf3291ab"")I receive:{  ""name"": ""view-x64.zip"",  ""path"": ""6cf5026f-8199-45ab-80fc-199ddf3291ab_273@6cf5026f-8199-45ab-80fc-199ddf3291ab""}If I assigned the return value to ""res"" (for example), I can then use:with open(res.get('path'), ""rb"") as fp:  print(f""I have opened {res.get('name')} at {fp})RegardsAdam",0,02-22-2021,05:22 AM
618,386556,ABurt,"Thank you for asking this question, I also have the same question...",0,02-22-2021,07:03 AM
619,376904,jamesdon,Hey Roger.I was able to query panorama logs successfully.Where did you define the `Device Group`?It should be defined in the instance configuration.Bar.,0,02-19-2021,08:44 PM
620,383586,bkatzir,"Hello BkatzirI've defined the Device Group in the Integrations (where all the settings are defined for Panorama)It's name is:Device group - Panorama instances only (write shared for Shared location)and there is ""shared"" in it...Thank youroger",0,02-04-2021,05:39 AM
621,383586,_buchwalder,Can you upload some screenshots or send them to me?I'm interested in knowing that you are indeed running the commands/Playbooks from the correctly configured instance.bkatzir@paloaltonetworks.com,0,02-04-2021,06:21 AM
622,383586,bkatzir,Hello bkatzirI've send you just now an E-MailThank youroger,0,02-04-2021,07:25 AM
623,383586,_buchwalder,"For future reference:After a correct configuration of the integration instance we have been encountering```calling panorama_get_traffic_logs(‘32936’,)Query logs failed. Reason is: Query timed out```This error comes from the pan-os. the search query job which we are creating is timing out.I talked with the pan-os team - there is no way to lengthen the TTL of the job via the API.A case was created to the pan-os team:01731887",0,02-04-2021,07:47 AM
624,383586,bkatzir,I can confirm the same issue when entering an invalid API key.I've made a code change to make sure that this shouldn't happen again. I'll post again once it is implemented.,0,02-14-2021,04:37 AM
625,383866,ABurt,The fix has been merged and you should see an updated pack in the Markplace soon.,0,02-05-2021,03:22 AM
626,383866,ABurt,"Hi,Best would be to use an external authentication mechanism that supports MFA. For example any SAML service (like Okta) usually supports MFA for authenticating users for the services.Gilad",1,02-05-2021,03:35 AM
627,376681,GShriki,@GShrikiIs gsuite supported?Can you point to a how-to article?TNX,0,12-30-2020,11:20 AM
628,376681,OZamir,HiThe XSOAR community edition does have a DUO integration that can be specifically used to provide 2fa authentication for admin logins to the portal.Just go to settings>integrations and either scroll down or type duo into the search bar at the top.Hope this helps.,0,12-31-2020,06:53 AM
629,376681,aurence64,"Hi,Any standard SAML IdP is supported.We do not have specific document for gsuite, but you can see the Okta example:https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-0/cortex-xsoar-admin/users-and-roles/authent...There are also guides from google on how to use gsuite as SAML IdP...Gilad",0,01-05-2021,12:51 PM
630,376681,GShriki,I want to ask if we can have any other federation (PingID) integrated with XSOAR for MFA?,0,01-06-2021,07:07 PM
631,376681,awaneet.chhabra,"You can use Ping for SAML auth, MFA would then enforced on the login with Ping.https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-0/cortex-xsoar-admin/users-and-roles/authent...While we list Okta, AzureAD, ADFS, you can certainly use other SAML providers like Ping.",0,01-15-2021,08:12 AM
632,376681,MBeauchamp2,"Thanks for the quick response.We have already tested SAML integration with PingID and it works fine. How do I force it to use Ping, is that something which needs to be configured on Ping side or XSOAR side?",0,01-15-2021,08:16 AM
633,376681,awaneet.chhabra,"When you go to login to your XSOAR server, you will see a button ""Log in with your Identity Provider (SSO/SAML)"". If you have previously setup local accounts in XSOAR, you can disable them, or change the passwords to force users to login with SSO going forward.",0,01-15-2021,08:32 AM
634,376681,MBeauchamp2,Bit late in the day but further to my previous reply I have actually just done a video on my channel about this very thing if you want to take a look it is athttps://youtu.be/NvDdTz2CMi4,0,01-15-2021,08:45 AM
635,376681,aurence64,Please follow this guidehttps://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-0/cortex-xsoar-admin/users-and-roles/authent...that explains how to configure both the ADFS server and the XSOAR side to enable thatOri,0,02-05-2021,01:45 AM
636,383855,OriNahir,"Hello OriWe followed this document already and we use ADFS 3.0 but on w2012r2. w2016 uses ADSF 4.0, but we do not use them.Thank youroger",0,02-04-2021,08:45 AM
637,383855,_buchwalder,"Is the service not starting?You might want to check the logs under /var/log/demisto/server.log and check the errors there, to better understand what prevents the service from startingOri",0,02-04-2021,11:16 PM
638,378005,OriNahir,"HiThank you for the reply, I have checked there and can't find any reference to the http server, I will have a more through look and post what I see, but yes it does seem that the change in certificate is stopping the service from starting.",0,01-05-2021,01:23 PM
639,378005,aurence64,This article describes how to use a signed certificate for the HttpS communication with the XSOAR consolehttps://docs.paloaltonetworks.com/cortex/cortex-xsoar/5-5/cortex-xsoar-admin/installation/post-insta...Please note that XSOAR web server is part other XSOAR service.,0,01-05-2021,01:41 PM
640,378005,OriNahir,"Apologies for the massive delay in getting back to you, I did follow the guide in the link and still it was overwriting the certificates on reboot, I still haven't found a way to make it work.",0,01-05-2021,01:48 PM
641,378005,aurence64,Did you check the server logs under `/var/log/demisto/server.log` right after the server restarts?DId you find any errors or mention to the certificate there?,0,01-14-2021,10:01 AM
642,378005,OriNahir,"HiPlease accept my apologies for the delay in getting back to you, I appreciate the help just been really busy, there is no mention of anything that looks like the webserver in the logs, I have a lot of telemetry errors but that is just about it.I will generate the cert again and have a look right after as opposed to retrospectively and post the results.",0,01-20-2021,02:26 PM
643,378005,aurence64,"You can get the args passed in like this:$value = $demisto.Args().value$demisto.Results($value)If you create a new automation script, and switch the type to Powershell, there is some example code provided.",0,02-04-2021,02:48 PM
644,381906,MBeauchamp2,Thank you MBeauchampThat helped me. My script is now runinng 🙂cheersroger,0,01-25-2021,07:01 AM
645,381906,_buchwalder,Hi RogerYou can run the command with `extend-context` common argument (https://xsoar.pan.dev/docs/playbooks/playbooks-extend-context#extending-context) to get more information populated to the context to be used later in the playbookThanksOri,0,01-26-2021,01:52 AM
646,381521,OriNahir,"Hello OriThank you for your response.I still struggeling to get my output.If I grab the output with raw-response=""true"" I do see the output I need.Then enter it to theExtend context as ""johndoe=root.issues.fields.customfield_10602""But don't see it in the output...Do you have any hints about?thanksroger",0,01-22-2021,09:33 AM
647,381521,_buchwalder,"Could you try and remove the ""root"" from the output:johndoe=issues.fields.customfield_10602",0,01-25-2021,02:01 AM
648,381521,ABurt,"Hello ABurtThank you for your reply.I tried it, but see it only in the ""Input"" as ""extend-context"" but don't see it in Output nor Results (also with view full table)regardsroger",0,01-25-2021,02:04 AM
649,381521,_buchwalder,"Hello allIt's my fault, I was expecting the result in the Results.As I could not found it there, I was looking into the outputs from Jira (Ticket.johndoe or so)But the outcome of the extend context is a seperate output. I saw it after looking for a keyword in context-data...My request in Jira:!jira-issue-query query=""ID = <tickett-ID>"" raw-response=""true""I would like to see here ""root.issues.0.fields.creator.timeZone""Extend Context is:Ticket_Details=issues.fieldsto get that timeZoneyou need to ask in the next Task:Ticket_Details.creator.timeZoneThanks all for help!roger",0,01-25-2021,02:11 AM
650,381521,_buchwalder,"Hi RogerYou can try to run your command with the `extend-context` common argument (https://xsoar.pan.dev/docs/playbooks/playbooks-extend-context#extending-context) to get more information to the context, and see if you get the details data thereThanksOri",0,01-25-2021,04:50 AM
651,381565,OriNahir,"Hello OriI didn't realize, that I've asked twice the same question...well, I think we continue on my other thread:LIVEcommunity - Re: jira-issue-query (jira-v2) dosen't show all info in output - LIVEcommunity - 381...And, thank you for your responseroger",0,01-22-2021,09:31 AM
652,381565,_buchwalder,"Hi Roger!Yes, that's quite a problem! It looks like Cron doesn't have a good way to identify specifically which week it's running in. The recommendation would be to run the job weekly but have the first section of your playbook determine if it's within the first 7 days. You can do that with the GetTime task with the dateFormat = Day. Something like the following will accomplish that for you:I hope that helps!Thanks!-Doug",0,01-25-2021,02:47 AM
653,362110,DougCouch,"As a quick follow up my task is slightly misnamed and should have been ""Day of Month""!",2,11-17-2020,04:46 PM
654,362110,DougCouch,"HelloYes, I did it exaclty that way and it works.Thanksroger",0,11-17-2020,04:49 PM
655,362110,_buchwalder,"Make sure your playbook is closing the incident (add a task at the end to with the closeInvesitiation commandAlternatively, or make sure the job queue is configured correctlyhttps://xsoar.pan.dev/docs/incidents/incident-jobs",0,01-21-2021,07:05 AM
656,362589,OriNahir,"HelloYes, I've found it with ""closeInvestigation (Builtin)""Have to read first your link.Thank you!roger",1,11-17-2020,04:35 PM
657,362589,_buchwalder,"According to this article -https://docs.paloaltonetworks.com/cortex/cortex-xsoar/6-0/cortex-xsoar-admin/installation/system-req...you need to addstorage.googleapis.com and xsoar.pan.dev as allowed urls and make sure they are reachable from the browser, otherwise you cannot access the Marketplace.",0,01-21-2021,07:03 AM
658,379289,amore,Hithanks for the reply - the issue was one of the firewalls was blocking the google-base application - we now have XSOAR working and connected to the Marketplace.Thanks,0,01-13-2021,11:22 AM
659,379289,spandor,"Yes, some customers classify their incidents in playbook. Usually in the case you mentioned, that you don't have enough context in the incident creation time, but only during the playbook execution time.",0,01-14-2021,01:36 AM
660,379303,aazadaliyev,"I think the problem you are having is related to the new limitation Docker introducedhttps://www.docker.com/increase-rate-limits#:~:text=Anonymous%20and%20Free%20Docker%20Hub,%3A%20toom....They limited the pull rate to 100 pulls per 6 hours, meaning if you will try to install your pack now, you should not get that warning.",0,01-12-2021,02:19 PM
661,376694,aazadaliyev,"Hello,Thank you for your message!I do not think this is related to the newly introduced pull rate limit.If I manually try to pull the latest image of one of the outdated images, I get following:[user@xsoar ~]$ sudo docker pull demisto/fetch-dataUsing default tag: latestError response from daemon: manifest for demisto/fetch-data:latest not found: manifest unknown: manifest unknownIf I for instance pull a debian image, it is fetched normally.If I try from the xSOAR Marketplace to update the Base pack, I get following warnings in the UI:",0,12-30-2020,04:36 AM
662,376694,antjar,"There is no latest tag, every docker has special version taghttps://hub.docker.com/r/demisto/fetch-data/tags?page=1&ordering=last_updatedTo pull docker image manually you should rundocker pull demisto/fetch-data:1.0.0.14842",0,01-11-2021,07:03 AM
663,376694,aazadaliyev,"Is this an .sh installer, or the OVA machine?Can you check if you see in the server.log(/var/log/demisto) the following line:info Listening on 0.0.0.0:443 (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3588)Gilad",0,01-11-2021,11:54 AM
664,368493,GShriki,"Hi Gilad,this is an .sh installer, not an OVAAnd yes, I can see similar lines in the log file:/home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3298)2020-12-07 21:26:58.4503 info Listening on 0.0.0.0:443 (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3298)2020-12-08 22:31:31.9763 info Listening on 0.0.0.0:443 (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3588)2020-12-08 22:45:04.7332 info Listening on 0.0.0.0:443 (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3588)2020-12-08 23:19:27.6428 info Listening on 0.0.0.0:443 (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3588)2020-12-08 23:35:48.5214 info Listening on 0.0.0.0:443 (source: /home/circleci/.go_workspace/src/github.com/demisto/server/web/router.go:3588)Regards,  Andreas",0,12-08-2020,03:36 PM
665,368493,delconsulting,Seems like server keeps restarting. can you please upload the full server.log?,0,12-08-2020,04:24 PM
666,368493,GShriki,It's possible the server has a local firewall blocking it. This is common in Fedora/Centos/Redhat.,0,12-08-2020,06:06 PM
667,368493,JohnLeon,"Hi John,great, thanks for that.Not sure why I didn't think about the firewall 🙂Disabling the firewall solved the issue.Regards,  Andreas",0,12-10-2020,09:06 AM
668,368493,delconsulting,"Hey@aborgo,Thanks for engaging with the SBOW integration with Cortex XSOAR.it does seem that we have an issue with the template parameter(which we will fix).Have you tried to fire the command with the `template` argument instead?e.g -",0,12-11-2020,04:54 AM
669,365203,bkatzir,"Hello @bkatzir, thanks for the reply.When trying to create from the playground and using the following command: !servicenow-create-ticket ticket_type=sc_req_item template=""Vulnerability management"".We always get the following error : Reason Unexpected error: Incorrect template name.We're 100% sure that the name is correct and we tried other things like allias, id... same error.",0,11-24-2020,10:56 PM
670,365203,aborgoENGIE,"Hello @bkatzir, thanks for the reply.When trying to create from the playground and using the following command: !servicenow-create-ticket ticket_type=sc_req_item template=""Vulnerability management"".We always get the following error : Reason Unexpected error: Incorrect template name.We're 100% sure that the name is correct and we tried other things like allias, id... same error.",0,12-03-2020,03:28 AM
671,365203,bkatzir,Does the template correlates with the ticket *type*?,0,12-07-2020,01:53 AM
672,365203,aborgoENGIE,"Hello,We found the solution to our problem. Actually, it wasn't a template but an item (linked to Request item) the right automation to create an item request was ""servicenow-create-item-order"" and not ""servicenow-create-ticket"".The problem come from my poor knowledge of Service Now and XSOAR integration. It's working well now.Thank you for your time @bkatzir.Best regards,Alexandre Borgo",1,12-09-2020,07:25 AM
673,329260,GShriki,"You will need to use an integration that returns the domain age. Look at ""DomainTools Iris"" which does that exactly. The integration also allow you to set a ""young"" domain threshold so anything created within that time will be marked as suspicious.This is done using the ""domain"" command which is the generic command to enrich domains. That command is already used by the built-in playbook Domain Enrichment - Generic v2, so you can simply use that playbook with the integration for that use case",3,05-21-2020,05:31 PM
674,329260,dbaumstein,Have a look at this recently released playbooksThese are TIM playbooks but can be easily modified for non TIM use casehttps://xsoar.pan.dev/docs/reference/playbooks/tim---process-domain-age-with-whoishttps://xsoar.pan.dev/docs/reference/playbooks/tim---process-domain-registrant-with-whoishttps://xsoar.pan.dev/docs/reference/playbooks/tim---process-domains-with-whois,1,07-08-2020,01:20 AM
675,329260,Abbeyy,Scrapebox has a nice domain availability checker built it. It can check 500 domains in about 2 minutes.,0,12-06-2020,08:25 PM
676,367030,OriNahir,"Alexandre BorgoThank you for reaching out, we do have a gap here, however what you can try is the following:Create the layout in one of the tenants - this will allow you to create the filter in the tenant playground, and to use this filter in the layout builderonce the layout is ready, you can export it from the tenant and import it to the main account, and than sync it to the rest of the tenantsgive it a go, and let us know if that works for youOri",0,12-03-2020,10:32 AM
677,367030,aborgoENGIE,"Hello Ori,The solution worked well, thank you for the help.Best regards",0,12-03-2020,11:47 PM
678,365254,GShriki,"Hi@batd2We are not familiar with specific issues with Global Protect.Can you please open a support case on this issue, and attach client HAR files?How to capture HAR file:https://knowledgebase.paloaltonetworks.com/KCSArticleDetail?id=kA10g000000PNiJCAWGilad",0,11-24-2020,09:16 PM
679,361293,dbaumstein,Hello SergioAre you are referring to the EWS O365 integration?Does the doc you are referring to provide the API call in order to create the blacklist?Best regards,0,11-17-2020,10:50 PM
680,361293,Sergio_Gonzalez,"Hello thanks for the response.Yes I've seen the 0365 doc (https://docs.microsoft.com/en-US/microsoft-365/security/office-365-security/create-block-sender-list...) and I've seen that is possible to do, but I don't know if there is something already coded in XSOAR or should I duplicate the integration and figure out how to do this part, seems kind of tricky.KR",0,11-19-2020,02:51 AM
681,361293,GShriki,"Looking on the EWS v2 integration, I do not see the option to create or modify a blacklist.You can file in a feature request athttps://xsoar.ideas.aha.io/ so our engineering team can see if this can be added.Gilad",0,11-19-2020,08:45 AM
682,361293,jgomes,"Hi Sergio,My understanding (unless changed recently) is the Microsoft Web based API still does not support updating the global O365 email sender block lists - as seen in the Admin Centre UI. This can be done via Mail transport rules API, but is only available via Power Shell module e.g. ExchangeOnlineManagementXSOAR supports Powershell Core on Linux. The is a few Power shell docker images in Demisto/XSOAR Docker Hub (e.g.demisto/powershell-ubuntu:7.0.3.12001). However non of these have the ExchangeOnlineManagement pre-installed. So a custom Docker image required.Microsoft has a docket container registry and powershell image e.g.mcr.microsoft.com/powershell - however this also does not have the module installed (I just checked). So needs some docker customizations - or see workaround below.So I think your options are:1/ Manual task to have analyst login Exchange Online Admin centre and add the email/s manully.2/ Run Custom Linux Docker for Powershell with the right modules loaded, and run a pre-tested script3/ Run Windows Engine (with modules installed) and with custom automation to run your own powershell .ps scripts on engine.3/ Use 'remote' SSH shell command use case to any windows to run dynamic BAT/Powershell scripts. Messing, but the benefit is service Authentication can be done in a way that Domain connected device is trusted and doesn't need to stor credentials to disk.e script credentials.My suggestion to try is:1/ Create new docker based on powershell e.g. /docker_image_create base=demisto/powershell-ubuntu:7.0.3.12001 name=new_powershelldemisto/powershell-ubuntu:7.0.3.120012/ In you Automation script - add 'Import-Module ExchangeOnlineManagement' at top of script. This will import module before running the rest of script. Also is invoked every time new docker in spawned (added only a couple seconds delay)3/ The of the script is tricky. You should to build your power shell credentials object from a password variable from XSOAR Vault. You will also need to write script, or have an account, that does not use MFA. Microsoft has articles on this.e.g.Import-Module ExchangeOnlineManagement$User = ""Domain01\ServiceAccount01"" or ""srvacc01@home.com""$password = <from XSOAR key vault>$PWord = ConvertTo-SecureString -String ""P@sSwOrd"" -AsPlainText -Force$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $User, $PWordConnect-ExchangeOnline -UserPrincipalName <name> -ShowProgress $false .... etc...When selecting 'new' Automation and selecting Powershell (instead of default Python) - this will give you example on how to handle powershell object rendering to war room etc. Powershell $demisto namespace is the same as python I think e.g. like 'set' context etc.Good luck!..",1,11-19-2020,09:45 AM
683,361293,jgomes,"oops, someone just highlighted a typo in my suggestions:To install module from script:Install-Module -Name ExchangeOnlineManagement",0,11-19-2020,09:59 AM
684,361293,aazadaliyev,We have it on our roadmap to release new integration in PowerShell that will allow to block senders globally.It should be release by the end of this quarter.,0,11-19-2020,01:46 PM
685,361293,Sergio_Gonzalez,"Hello,In relation with that I suppose that this new integration will work in a way of when I block a sender, it affects to all the company right?KR.",0,11-20-2020,12:59 AM
686,361293,Sergio_Gonzalez,Thank you very much for the response. I will try to test it and see if it works!Kind Regards.,0,11-20-2020,01:00 AM
687,361293,aazadaliyev,correct,0,11-21-2020,12:25 AM
688,354841,GShriki,"MP,Community Edition process usually takes less than a week.1. It requires an enterprise email address (gmail, yahoo, etc. mail accounts will not be not approved)2. sometimes these emails fall in the spam folder, so please also check there3. In case you still didn't get it - please ping me on Slack DFIR workspace (@shriki)Gilad",0,10-26-2020,02:39 PM
689,354841,ten4you,"hi,thanks for the replay.it is a corporate mail adres info@ten4you.nlMartijn",0,10-27-2020,12:24 AM
690,354841,GShriki,"Martijn,Understood we got this resolved. Let us know if you have any other questions.Gilad",0,10-28-2020,09:19 AM
691,342628,GShriki,"Hi,You can configure different level of notifications on your profile settings section (click on the avatar on the lower left side of the sceen). Then move the notification tab, where you can control the different notifications. As long as you have email sender integration configured - you will get the configured notifications.Shriki",0,08-07-2020,10:07 AM
692,342628,YeswanthKumar,"Hi@GShriki,Thanks for the update, but here the notifications will be send when we do the Configuration on server withmodule.health.notification.users -- user name.My exact requirement whenever the sources which are been integrated with demisto fails to report\fetch incidents is there any way to notify the administrator?Except the above configurationRegards,Yeswanth M.",0,08-12-2020,09:33 PM
693,336556,GShriki,"Hi,This is how all integrations implement the ingestion mechanism. When you set up a new integration instance that ""fetch"" incidents - it will mostly look for last 10 minutes, and fetch only ""alerts"" from that timeframe. Then, once an incident is ""fetched"", the system will maintain that id, and in the next cycle it will start searching from that point onward.Specifically for QRadar - it will start ingesting incidents from the moment you configured the instance, so you will only get QRadar Offenses that are created after the integration is activated. The query parameter that you can set up in the integration configuration will be applied on top of this time frame consideration (and not as a substitute)Gilad",1,07-03-2020,01:21 PM
